{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import pickle\n",
    "import qplib as qp\n",
    "from qplib import log, na, nk, num\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import qplib as qp\n",
    "from qplib import log\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "log('trace: this is a trace message')\n",
    "log('debug: this is a debug message')\n",
    "log('info: this is an info message')\n",
    "log('warning: this is a warning message')\n",
    "log('error: this is an error message')\n",
    "\n",
    "log(str(a))\n",
    "log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd_query  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_38536\\2234162938.py:937: UserWarning: registration of accessor <class '__main__.DataFrameQuery'> under name 'q' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_38536\\2234162938.py:954: UserWarning: registration of accessor <class '__main__.DataFrameQueryInteractiveMode'> under name 'qi' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('qi')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4614d_row0_col0, #T_4614d_row0_col1, #T_4614d_row0_col2, #T_4614d_row0_col3 {\n",
       "  background-color: #c0e7b0;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4614d\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4614d_level0_row0\" class=\"row_heading level0 row0\" >49</th>\n",
       "      <td id=\"T_4614d_row0_col0\" class=\"data row0 col0\" >df was checked. no problems found</td>\n",
       "      <td id=\"T_4614d_row0_col1\" class=\"data row0 col1\" >qp.pd_util._check_df</td>\n",
       "      <td id=\"T_4614d_row0_col2\" class=\"data row0 col2\" >info</td>\n",
       "      <td id=\"T_4614d_row0_col3\" class=\"data row0 col3\" >2024-09-16 10:45:21.949474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2514430b3e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['name'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frank miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grace TAYLOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harry Clark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IVY GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JAck Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eva white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>john Doe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name\n",
       "2   Alice Johnson\n",
       "3       Bob Brown\n",
       "5    Frank miller\n",
       "6    Grace TAYLOR\n",
       "7     Harry Clark\n",
       "8       IVY GREEN\n",
       "9   JAck Williams\n",
       "1      Jane Smith\n",
       "0        John Doe\n",
       "4       eva white\n",
       "10       john Doe"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interactive_output, HBox, VBox, fixed, Layout, interact_manual\n",
    "\n",
    "from qplib.util import log\n",
    "from qplib.types import _int, _float, _num, _bool, _datetime, _date, _na, _nk, _yn, qpDict\n",
    "from qplib.pd_util import _check_df, _diff, _format_df, indexQpExtension, seriesQpExtension, dfQpExtension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Symbol:\n",
    "    \"\"\"\n",
    "    A Symbol used in the query languages syntax.\n",
    "    \"\"\"\n",
    "    def __init__(self, symbol, name, description, unary=None, binary=None, **kwargs):\n",
    "        self.symbol = symbol\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.unary = unary\n",
    "        self.binary = binary\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name} (symbol: \"{self.symbol}\" description: \"{self.description})\"'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.name} (symbol: \"{self.symbol}\" description: \"{self.description})\"'\n",
    "\n",
    "class Symbols:\n",
    "    \"\"\"\n",
    "    Multiple Symbols of the same category are collected in a Symbols object.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, *symbols):\n",
    "        self.name = name\n",
    "        self.by_name = {symbol.name: symbol for symbol in symbols}\n",
    "        self.by_symbol = {symbol.symbol: symbol for symbol in symbols}\n",
    "        for symbol in symbols:\n",
    "            setattr(self, symbol.name, symbol)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key in self.by_symbol:\n",
    "            return self.by_symbol[key]\n",
    "        elif key in self.by_name:\n",
    "            return self.by_name[key]\n",
    "        else:\n",
    "            log(f'error: symbol \"{key}\" not found in \"{self.name}\"', 'qp.qlang.Symbols.__getitem__', 3)\n",
    "            return None\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.by_name.values())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name}:\\n' + '\\n\\t'.join([str(val) for key,val in self.by_name.items()])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.name}:\\n' + '\\n\\t'.join([str(val) for key,val in self.by_name.items()])\n",
    "\n",
    "\n",
    "\n",
    "COMMENT = Symbol('#', 'COMMENT', 'comments out the rest of the line')\n",
    "ESCAPE = Symbol('`', 'ESCAPE', 'escape the next character')\n",
    "\n",
    "CONNECTORS = Symbols('CONNECTORS',\n",
    "    Symbol('', 'RESET', 'only the current condition must be fulfilled'),\n",
    "    Symbol('&', 'AND', 'this condition and the previous condition/s must be fulfilled'),\n",
    "    Symbol('/', 'OR', 'this condition or the previous condition/s must be fulfilled'),\n",
    "    )\n",
    "\n",
    "SCOPES = Symbols('SCOPES',\n",
    "    Symbol('any', 'ANY', 'any of the currently selected columns must fulfill the condition'),\n",
    "    Symbol('all', 'ALL', 'all of the currently selected columns must fulfill the condition'),\n",
    "    Symbol('idx', 'IDX', 'the index of the dataframe must fulfill the condition'),\n",
    "    )\n",
    "\n",
    "NEGATIONS = Symbols('NEGATIONS',\n",
    "    Symbol('', 'FALSE', 'dont negate the condition'),\n",
    "    Symbol('!', 'TRUE', 'negate the condition'),\n",
    "    )\n",
    "\n",
    "OPERATORS = Symbols('OPERATORS',\n",
    "    #for changing settings\n",
    "    Symbol('verbosity=', 'SET_VERBOSITY', 'change the verbosity level'),\n",
    "    Symbol('diff=', 'SET_DIFF', 'change the diff setting'),\n",
    "\n",
    "\n",
    "    #for filtering\n",
    "    Symbol('>=', 'BIGGER_EQUAL', 'bigger or equal', binary=True),\n",
    "    Symbol('<=', 'SMALLER_EQUAL', 'smaller or equal', binary=True),\n",
    "    Symbol('>', 'BIGGER', 'bigger', binary=True),\n",
    "    Symbol('<', 'SMALLER', 'smaller', binary=True),\n",
    "\n",
    "    Symbol('==', 'STRICT_EQUAL', 'equal to (case sensitive)', binary=True),\n",
    "    Symbol('=', 'EQUAL', 'equal to', binary=True),\n",
    "\n",
    "    Symbol('??', 'STRICT_CONTAINS', 'contains a string (case sensitive)', binary=True),\n",
    "    Symbol('?', 'CONTAINS', 'contains a string (not case sensitive)', binary=True),\n",
    "\n",
    "    Symbol('r=', 'MATCHES_REGEX', 'matches a regex', binary=True),\n",
    "    Symbol('r?', 'CONTAINS_REGEX', 'contains a regex', binary=True),\n",
    "\n",
    "    Symbol('~', 'EVAL', 'select values by evaluating a python expression on each value', binary=True),\n",
    "    Symbol('col~', 'COL_EVAL', 'select rows by evaluating a python expression on a whole column', binary=True),\n",
    "\n",
    "    Symbol('@', 'LOAD_SELECTION', 'load a saved selection from a boolean column', binary=True),\n",
    "\n",
    "    Symbol('is any', 'IS_ANY', 'is any value', unary=True),\n",
    "    Symbol('is str', 'IS_STR', 'is string', unary=True),\n",
    "    Symbol('is int', 'IS_INT', 'is integer', unary=True),\n",
    "    Symbol('is float', 'IS_FLOAT', 'is float', unary=True),\n",
    "    Symbol('is num', 'IS_NUM', 'is number', unary=True),\n",
    "    Symbol('is bool', 'IS_BOOL', 'is boolean', unary=True),\n",
    "    Symbol('is datetime', 'IS_DATETIME', 'is datetime', unary=True),\n",
    "    Symbol('is date', 'IS_DATE', 'is date', unary=True),\n",
    "    Symbol('is na', 'IS_NA', 'is missing value', unary=True),\n",
    "    Symbol('is nk', 'IS_NK', 'is not known value', unary=True),\n",
    "    Symbol('is yn', 'IS_YN', 'is yes or no value', unary=True),\n",
    "    Symbol('is yes', 'IS_YES', 'is yes value', unary=True),\n",
    "    Symbol('is no', 'IS_NO', 'is no value', unary=True),\n",
    "    Symbol('is unique', 'IS_UNIQUE', 'is a unique value', unary=True),\n",
    "    Symbol('is first', 'IS_FIRST', 'is the first value (of multiple values)', unary=True),\n",
    "    Symbol('is last', 'IS_LAST', 'is the last value (of multiple values)', unary=True),\n",
    "\n",
    "\n",
    "    #for modifying values and headers\n",
    "    Symbol('=', 'SET_VAL', 'replace value with the given string'),\n",
    "    Symbol('+=', 'ADD_VAL', 'append a string to the value (coerce to string if needed)'),\n",
    "\n",
    "    Symbol('~', 'SET_EVAL', 'replace value by evaluating a python expression for each selected value/header'),\n",
    "    Symbol('col~', 'SET_COL_EVAL', 'replace value by evaluating a python expression for each selected column'),\n",
    "    \n",
    "    Symbol('sort', 'SORT', 'sort values based on the selected column(s)', unary=True),\n",
    "\n",
    "    Symbol('to str', 'TO_STR', 'convert to string', unary=True),\n",
    "    Symbol('to int', 'TO_INT', 'convert to integer', unary=True),\n",
    "    Symbol('to float', 'TO_FLOAT', 'convert to float', unary=True),\n",
    "    Symbol('to num', 'TO_NUM', 'convert to number', unary=True),\n",
    "    Symbol('to bool', 'TO_BOOL', 'convert to boolean', unary=True),\n",
    "    Symbol('to datetime', 'TO_DATETIME', 'convert to datetime', unary=True),\n",
    "    Symbol('to date', 'TO_DATE', 'convert to date', unary=True),\n",
    "    Symbol('to na', 'TO_NA', 'convert to missing value', unary=True),\n",
    "    Symbol('to nk', 'TO_NK', 'convert to not known value', unary=True),\n",
    "    Symbol('to yn', 'TO_YN', 'convert to yes or no value', unary=True),\n",
    "\n",
    "\n",
    "    #for adding new columns\n",
    "    Symbol('=', 'STR_COL', 'add new column, fill it with the given string and select it', binary=True),\n",
    "    Symbol('~', 'EVAL_COL', 'add new column, fill it by evaluating a python expression and select it', binary=True),\n",
    "    Symbol('@', 'SAVE_SELECTION', 'add a new boolean column with the given name and select it. all currently selected rows are set to True, the rest to False', binary=True),\n",
    "    \n",
    "    \n",
    "    #for modifying metadata (part of miscellaneous instructions)\n",
    "    Symbol('=', 'SET_METADATA', 'set contents of the columnn named \"meta\" to the given string', binary=True),\n",
    "    Symbol('+=', 'ADD_METADATA', 'append the given string to the contents of the column named \"meta\"', binary=True),\n",
    "    Symbol('@', 'TAG_METADATA', 'add a tag of the currently selected column(s) in the form of \"<value>@<selected col>;\" to the column named \"meta\"', binary=True),\n",
    "    Symbol('~', 'SET_METADATA_EVAL', 'set contents of the column named \"meta\" by evaluating a python expression for each selected value in the metadata', binary=True),\n",
    "    Symbol('col~', 'SET_METADATA_COL_EVAL', 'set contents of the column named \"meta\" by evaluating a python expression on the whole metadata column', binary=True),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _modify_settings(instruction, df_new, rows, cols, diff, verbosity):\n",
    "    \"\"\"\n",
    "    An instruction to change the settings for the query.\n",
    "    \"\"\"\n",
    "\n",
    "    operator = instruction.operator\n",
    "    value = instruction.value\n",
    "    \n",
    "    if operator == OPERATORS.SET_VERBOSITY:\n",
    "        if value in ['0', '1', '2', '3', '4', '5']:\n",
    "            verbosity = int(value)\n",
    "        else:\n",
    "            log(f'warning: verbosity must be an integer between 0 and 5. \"{value}\" is not valid',\n",
    "                'qp.qlang._modify_settings', verbosity)\n",
    "    \n",
    "    elif operator == OPERATORS.SET_DIFF:\n",
    "        if value.lower() in ['none', '0', 'false']:\n",
    "            diff = None\n",
    "        elif value.lower() in ['mix', 'new', 'old', 'new+']:\n",
    "            diff = value.lower()\n",
    "        else:\n",
    "            log(f'warning: diff must be one of [None, \"mix\", \"old\", \"new\", \"new+\"]. \"{value}\" is not valid',\n",
    "                'qp.qlang._modify_settings', verbosity)\n",
    "\n",
    "    return df_new, rows, cols, diff, verbosity\n",
    "\n",
    "\n",
    "\n",
    "def _select_cols(instruction, df_new, rows, cols, diff, verbosity):\n",
    "    \"\"\"\n",
    "    An Instruction to select columns fulfilling a condition.\n",
    "    \"\"\"\n",
    "\n",
    "    connector = instruction.connector\n",
    "    negation = instruction.negation\n",
    "    operator = instruction.operator\n",
    "    value = instruction.value\n",
    "\n",
    "    cols_all = df_new.columns.to_series()\n",
    "\n",
    "    cols_new = _filter_series(cols_all, negation, operator, value, verbosity, df_new)\n",
    "\n",
    "    if cols_new.any() == False:\n",
    "        log(f'warning: no columns fulfill the condition in \"{instruction.str}\"',\n",
    "            'qp.qlang._select_cols', verbosity)\n",
    "\n",
    "    cols = _update_selection(cols, cols_new, connector)\n",
    "\n",
    "    if cols.any() == False and connector == CONNECTORS.AND:\n",
    "        log(f'warning: no columns fulfill the condition in \"{instruction.str}\" and the previous conditions',\n",
    "            'qp.qlang._select_cols', verbosity)\n",
    "\n",
    "    return df_new, rows, cols, diff, verbosity\n",
    "\n",
    "\n",
    "\n",
    "def _select_rows(instruction, df_new, rows, cols, diff, verbosity):\n",
    "    \"\"\"\n",
    "    An Instruction to select rows fulfilling a condition.\n",
    "    \"\"\"\n",
    "\n",
    "    connector = instruction.connector\n",
    "    scope = instruction.scope\n",
    "    negation = instruction.negation\n",
    "    operator = instruction.operator\n",
    "    value = instruction.value\n",
    "    rows_all = df_new.index.to_series()\n",
    "        \n",
    "    if value.startswith('@'):\n",
    "        column = value[1:]\n",
    "        if column in df_new.columns:\n",
    "            value = df_new[column]\n",
    "        else:\n",
    "            log(f'error: column \"{column}\" not found in dataframe. cannot use \"@{column}\" as value for row selection',\n",
    "                'qp.qlang._select_rows', verbosity)\n",
    "\n",
    "\n",
    "    if cols.any() == False:\n",
    "        log(f'warning: row filter cannot be applied when no columns where selected', 'qp.qlang._select_rows', verbosity)\n",
    "        rows = pd.Series(False, index=rows_all.index)\n",
    "        return df_new, rows, cols, diff, verbosity\n",
    "            \n",
    "    if scope == SCOPES.IDX:\n",
    "        rows_new = _filter_series(rows_all, negation, operator, value, verbosity, df_new)\n",
    "        rows = _update_selection(rows, rows_new, connector)\n",
    "\n",
    "    else:\n",
    "        rows_temp = None\n",
    "        for col in df_new.columns[cols]:\n",
    "            rows_new = _filter_series(df_new[col], negation, operator, value, verbosity, df_new)\n",
    "            rows_temp = _update_selection(rows_temp, rows_new, scope)\n",
    "        rows = _update_selection(rows, rows_temp, connector)\n",
    "\n",
    "        if rows_temp.any() == False:\n",
    "            log(f'warning: no rows fulfill the condition in \"{instruction}\"', 'qp.qlang._select_rows', verbosity)\n",
    "\n",
    "    return df_new, rows, cols, diff, verbosity\n",
    "\n",
    "\n",
    "def _modify_vals(instruction, df_new, rows, cols, diff, verbosity):\n",
    "    \"\"\"\n",
    "    An Instruction to modify the selected values.\n",
    "    \"\"\"\n",
    "\n",
    "    operator = instruction.operator\n",
    "    value = instruction.value\n",
    "\n",
    "    #data modification  \n",
    "    if operator == OPERATORS.SET_VAL:\n",
    "        df_new.loc[rows, cols] = value\n",
    "    elif operator == OPERATORS.ADD_VAL:\n",
    "        df_new.loc[rows, cols] = df_new.loc[rows, cols].astype(str) + value\n",
    "    elif operator == OPERATORS.SET_COL_EVAL:\n",
    "        df_new.loc[:, cols] = df_new.loc[:, cols].apply(lambda x: eval(value, {'col': x, 'df': df_new, 'pd': pd, 'np': np, 'qp': qp, 're': re}), axis=0)\n",
    "    elif operator == OPERATORS.SORT:\n",
    "        display(df_new.columns[cols])\n",
    "        df_new.sort_values(by=list(df.columns[cols]), axis=0, inplace=True)\n",
    "        rows.index = df_new.index\n",
    "\n",
    "    elif pd.__version__ >= '2.1.0':  #map was called applymap before 2.1.0\n",
    "        #data modification\n",
    "        if operator == OPERATORS.SET_EVAL:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(lambda x: eval(value, {'x': x, 'df': df_new, 'pd': pd, 'np': np, 'qp': qp, 're': re}))\n",
    "\n",
    "\n",
    "        #type conversion\n",
    "        elif operator == OPERATORS.TO_STR:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(str)\n",
    "        elif operator == OPERATORS.TO_INT:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(_int)\n",
    "        elif operator == OPERATORS.TO_FLOAT:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(_float)\n",
    "        elif operator == OPERATORS.TO_NUM:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(_num)\n",
    "        elif operator == OPERATORS.TO_BOOL:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(_bool)\n",
    "        \n",
    "        elif operator == OPERATORS.TO_DATETIME:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(_datetime)\n",
    "        elif operator == OPERATORS.TO_DATE:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(_date)\n",
    "\n",
    "        elif operator == OPERATORS.TO_NA:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(_na)\n",
    "        elif operator == OPERATORS.TO_NK:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(_nk)\n",
    "        elif operator == OPERATORS.TO_YN:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].map(_yn)\n",
    "\n",
    "    else:\n",
    "        #data modification\n",
    "        if operator == OPERATORS.SET_EVAL:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(lambda x: eval(value, {'x': x, 'df': df_new, 'pd': pd, 'np': np, 'qp': qp, 're': re}))\n",
    "\n",
    "        #type conversion\n",
    "        elif operator == OPERATORS.TO_STR:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(str)\n",
    "        elif operator == OPERATORS.TO_INT:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(_int)\n",
    "        elif operator == OPERATORS.TO_FLOAT:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(_float)\n",
    "        elif operator == OPERATORS.TO_NUM:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(_num)\n",
    "        elif operator == OPERATORS.TO_BOOL:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(_bool)\n",
    "        \n",
    "        elif operator == OPERATORS.TO_DATETIME:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(_datetime)\n",
    "        elif operator == OPERATORS.TO_DATE:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(_date)\n",
    "\n",
    "        elif operator == OPERATORS.TO_NA:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(_na)\n",
    "        elif operator == OPERATORS.TO_NK:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(_nk)\n",
    "        elif operator == OPERATORS.TO_YN:\n",
    "            df_new.loc[rows, cols] = df_new.loc[rows, cols].applymap(_yn)\n",
    "\n",
    "    return df_new, rows, cols, diff, verbosity\n",
    "\n",
    "\n",
    "def _modify_headers(instruction, df_new, rows, cols, diff, verbosity):\n",
    "    \"\"\"\n",
    "    An Instruction to modify the headers of the selected column(s).\n",
    "    \"\"\"\n",
    "\n",
    "    operator = instruction.operator\n",
    "    value = instruction.value\n",
    "\n",
    "    if operator == OPERATORS.SET_VAL:\n",
    "        df_new.rename(columns={col: value for col in df_new.columns[cols]}, inplace=True)\n",
    "        cols.index = df_new.columns\n",
    "\n",
    "    if operator == OPERATORS.ADD_VAL:\n",
    "        df_new.rename(columns={col: col + value for col in df_new.columns[cols]}, inplace=True)\n",
    "        cols.index = df_new.columns\n",
    "\n",
    "    if operator == OPERATORS.SET_EVAL:\n",
    "        df_new.rename(\n",
    "            columns={\n",
    "                col: eval(value, {'x': col, 'df': df_new, 'pd': pd, 'np': np, 'qp': qp})\n",
    "                for col in df_new.columns[cols]\n",
    "                },\n",
    "            inplace=True\n",
    "            )\n",
    "        cols.index = df_new.columns\n",
    "\n",
    "    return df_new, rows, cols, diff, verbosity\n",
    "\n",
    "\n",
    "def _new_col(instruction, df_new, rows, cols, diff, verbosity):\n",
    "    \"\"\"\n",
    "    An Instruction to add a new column.\n",
    "    \"\"\"\n",
    "\n",
    "    operator = instruction.operator\n",
    "    value = instruction.value\n",
    "\n",
    "    if operator == OPERATORS.STR_COL:\n",
    "        for i in range(1, 1001):\n",
    "            if i == 1000:\n",
    "                log(f'warning: could not add new column. too many columns named \"new<x>\"',\n",
    "                    'qp.qlang._new_col', verbosity)\n",
    "                break\n",
    "\n",
    "            header = 'new' + str(i)\n",
    "            if header not in df_new.columns:\n",
    "                df_new[header] = ''\n",
    "                df_new.loc[rows, header] = value\n",
    "                cols = pd.Series([True if col == header else False for col in df_new.columns])\n",
    "                cols.index = df_new.columns\n",
    "                break\n",
    "    \n",
    "    elif operator == OPERATORS.EVAL_COL:\n",
    "        for i in range(1, 1001):\n",
    "            if i == 1000:\n",
    "                log(f'warning: could not add new column. too many columns named \"new<x>\"',\n",
    "                    'qp.qlang._new_col', verbosity)\n",
    "                break\n",
    "\n",
    "            header = 'new' + str(i)\n",
    "            if header not in df_new.columns: \n",
    "                value = eval(value, {'df': df_new, 'pd': pd, 'np': np, 'qp': qp})\n",
    "                if isinstance(value, pd.Series):\n",
    "                    df_new[header] = value\n",
    "                else:\n",
    "                    df_new[header] = pd.NA\n",
    "                    df_new.loc[rows, header] = value\n",
    "                cols = pd.Series([True if col == header else False for col in df_new.columns])\n",
    "                cols.index = df_new.columns\n",
    "                break\n",
    "    \n",
    "\n",
    "    elif operator == OPERATORS.SAVE_SELECTION:\n",
    "        if value in df_new.columns:\n",
    "            log(f'warning: column \"{value}\" already exists in dataframe. selecting existing col and resetting values',\n",
    "                'qp.qlang._new_col', verbosity)\n",
    "        df_new[value] = rows\n",
    "        cols = pd.Series([True if col == value else False for col in df_new.columns])\n",
    "        cols.index = df_new.columns\n",
    "\n",
    "    return df_new, rows, cols, diff, verbosity\n",
    "\n",
    "\n",
    "def _miscellaneous(instruction, df_new, rows, cols, diff, verbosity):\n",
    "    \"\"\"\n",
    "    An Instruction for miscellaneous tasks, for example, modifying metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    operator = instruction.operator\n",
    "    value = instruction.value\n",
    "    \n",
    "    operators_metadata = [\n",
    "        OPERATORS.SET_METADATA,\n",
    "        OPERATORS.ADD_METADATA,\n",
    "        OPERATORS.TAG_METADATA,\n",
    "        OPERATORS.SET_METADATA_EVAL,\n",
    "        OPERATORS.SET_METADATA_COL_EVAL,\n",
    "        ]\n",
    "    if operator in operators_metadata and 'meta' not in df_new.columns:\n",
    "        log(f'info: no metadata column found in dataframe. creating new column named \"meta',\n",
    "            'qp.qlang.Miscellaneous.apply', verbosity)\n",
    "        df_new['meta'] = ''\n",
    "        cols = pd.concat([cols, pd.Series([False])])\n",
    "        cols.index = df_new.columns\n",
    "    \n",
    "\n",
    "    #modify metadata\n",
    "    if operator == OPERATORS.SET_METADATA:\n",
    "        df_new.loc[rows, 'meta'] = value\n",
    "\n",
    "    elif operator == OPERATORS.ADD_METADATA:\n",
    "        df_new.loc[rows, 'meta'] += value\n",
    "\n",
    "    elif operator == OPERATORS.TAG_METADATA:\n",
    "        tag = ''\n",
    "        for col in df_new.columns[cols]:\n",
    "            tag += f'{value}@{col};'\n",
    "        df_new.loc[rows, 'meta'] += tag\n",
    "\n",
    "    elif operator == OPERATORS.SET_METADATA_EVAL:\n",
    "        if pd.__version__ >= '2.1.0':  #map was called applymap before 2.1.0\n",
    "            df_new.loc[rows, 'meta'] = df_new.loc[rows, 'meta'].map(lambda x: eval(value, {'x': x, 'df': df_new, 'pd': pd, 'np': np, 'qp': qp, 're': re}))\n",
    "        else:\n",
    "            df_new.loc[rows, 'meta'] = df_new.loc[rows, 'meta'].applymap(lambda x: eval(value, {'x': x, 'df': df_new, 'pd': pd, 'np': np, 'qp': qp, 're': re}))\n",
    "        \n",
    "    elif operator == OPERATORS.SET_METADATA_COL_EVAL:\n",
    "        df_new.loc[rows, 'meta'] = df_new.loc[rows, 'meta'].apply(lambda x: eval(value, {'col': x, 'df': df_new, 'pd': pd, 'np': np, 'qp': qp, 're': re}))\n",
    "\n",
    "    return df_new, rows, cols, diff, verbosity\n",
    "\n",
    "\n",
    "INSTRUCTIONS = Symbols('INSTRUCTIONS',\n",
    "                       \n",
    "    Symbol('´c', 'SELECT_COLS', 'select columns fulfilling a condition',\n",
    "        connectors=[\n",
    "            CONNECTORS.RESET,#default\n",
    "            CONNECTORS.AND,\n",
    "            CONNECTORS.OR\n",
    "            ],\n",
    "        negations=[\n",
    "            NEGATIONS.FALSE, #default\n",
    "            NEGATIONS.TRUE\n",
    "            ],\n",
    "        operators=[\n",
    "            OPERATORS.EQUAL, #default\n",
    "\n",
    "            #binary\n",
    "            OPERATORS.BIGGER_EQUAL, OPERATORS.SMALLER_EQUAL, OPERATORS.BIGGER, OPERATORS.SMALLER,\n",
    "            OPERATORS.STRICT_EQUAL, OPERATORS.EQUAL,\n",
    "            OPERATORS.STRICT_CONTAINS, OPERATORS.CONTAINS,\n",
    "            OPERATORS.MATCHES_REGEX, OPERATORS.CONTAINS_REGEX,\n",
    "            OPERATORS.EVAL,\n",
    "            OPERATORS.LOAD_SELECTION,\n",
    "        \n",
    "            #unary\n",
    "            OPERATORS.IS_ANY,\n",
    "            OPERATORS.IS_UNIQUE,\n",
    "            OPERATORS.IS_NA, OPERATORS.IS_NK,\n",
    "            OPERATORS.IS_STR, OPERATORS.IS_INT, OPERATORS.IS_FLOAT, OPERATORS.IS_NUM, OPERATORS.IS_BOOL,\n",
    "            OPERATORS.IS_DATE, OPERATORS.IS_DATETIME,\n",
    "            OPERATORS.IS_YN, OPERATORS.IS_YES, OPERATORS.IS_NO,\n",
    "            ],\n",
    "        apply=_select_cols,\n",
    "        ),\n",
    "\n",
    "\n",
    "    Symbol('´r', 'SELECT_ROWS', 'select rows fulfilling a condition',\n",
    "        connectors=[\n",
    "            CONNECTORS.RESET,#default\n",
    "            CONNECTORS.AND,\n",
    "            CONNECTORS.OR\n",
    "            ],\n",
    "        scopes=[\n",
    "            SCOPES.ANY, #default\n",
    "            SCOPES.ALL,\n",
    "            SCOPES.IDX\n",
    "            ],\n",
    "        negations=[\n",
    "            NEGATIONS.FALSE, #default\n",
    "            NEGATIONS.TRUE\n",
    "            ],\n",
    "        operators=[\n",
    "            OPERATORS.EQUAL, #default\n",
    "\n",
    "            #binary\n",
    "            OPERATORS.BIGGER_EQUAL, OPERATORS.SMALLER_EQUAL, OPERATORS.BIGGER, OPERATORS.SMALLER,\n",
    "            OPERATORS.STRICT_EQUAL, OPERATORS.EQUAL,\n",
    "            OPERATORS.STRICT_CONTAINS, OPERATORS.CONTAINS,\n",
    "            OPERATORS.MATCHES_REGEX, OPERATORS.CONTAINS_REGEX,\n",
    "            OPERATORS.EVAL, OPERATORS.COL_EVAL,\n",
    "            OPERATORS.LOAD_SELECTION,\n",
    "        \n",
    "            #unary\n",
    "            OPERATORS.IS_ANY,\n",
    "            OPERATORS.IS_UNIQUE, OPERATORS.IS_FIRST, OPERATORS.IS_LAST,\n",
    "            OPERATORS.IS_NA, OPERATORS.IS_NK,\n",
    "            OPERATORS.IS_STR, OPERATORS.IS_INT, OPERATORS.IS_FLOAT, OPERATORS.IS_NUM, OPERATORS.IS_BOOL,\n",
    "            OPERATORS.IS_DATE, OPERATORS.IS_DATETIME,\n",
    "            OPERATORS.IS_YN, OPERATORS.IS_YES, OPERATORS.IS_NO,\n",
    "            ],\n",
    "        apply=_select_rows,\n",
    "        ),\n",
    "\n",
    "\n",
    "    Symbol('´v', 'MODIFY_VALS', 'modify the selected values',\n",
    "        connectors=[\n",
    "            CONNECTORS.RESET,#default\n",
    "            CONNECTORS.AND,\n",
    "            CONNECTORS.OR\n",
    "            ],\n",
    "        operators=[\n",
    "            OPERATORS.SET_VAL, #default\n",
    "            OPERATORS.ADD_VAL,\n",
    "            OPERATORS.SET_EVAL, OPERATORS.SET_COL_EVAL,\n",
    "            OPERATORS.SORT,\n",
    "            OPERATORS.TO_STR, OPERATORS.TO_INT, OPERATORS.TO_FLOAT, OPERATORS.TO_NUM, OPERATORS.TO_BOOL,\n",
    "            OPERATORS.TO_DATE, OPERATORS.TO_DATETIME, OPERATORS.TO_NA, OPERATORS.TO_NK, OPERATORS.TO_YN,\n",
    "            ],\n",
    "        apply=_modify_vals,\n",
    "        ),\n",
    "\n",
    "    Symbol('´h', 'MODIFY_HEADERS', 'modify headers of the selected columns',\n",
    "        connectors=[\n",
    "            CONNECTORS.RESET,#default\n",
    "            CONNECTORS.AND,\n",
    "            CONNECTORS.OR\n",
    "            ],\n",
    "        operators=[\n",
    "            OPERATORS.SET_VAL, #default\n",
    "            OPERATORS.ADD_VAL,\n",
    "            OPERATORS.SET_EVAL,\n",
    "            ],\n",
    "        apply=_modify_headers,\n",
    "        ),\n",
    "\n",
    "    Symbol('´n', 'NEW_COL', 'add new column',\n",
    "        connectors=[\n",
    "            CONNECTORS.RESET,#default\n",
    "            CONNECTORS.AND,\n",
    "            CONNECTORS.OR\n",
    "            ],\n",
    "        operators=[\n",
    "            OPERATORS.STR_COL, #default\n",
    "            OPERATORS.EVAL_COL,\n",
    "            OPERATORS.SAVE_SELECTION,\n",
    "            ],\n",
    "        apply=_new_col,\n",
    "        ),\n",
    "\n",
    "    Symbol('´m', 'MISCELLANEOUS', 'miscellaneous instructions',\n",
    "        connectors=[\n",
    "            CONNECTORS.RESET,#default\n",
    "            CONNECTORS.AND,\n",
    "            CONNECTORS.OR\n",
    "            ],\n",
    "        operators=[\n",
    "            OPERATORS.SET_METADATA, #default\n",
    "            OPERATORS.ADD_METADATA,\n",
    "            OPERATORS.TAG_METADATA,\n",
    "            OPERATORS.SET_METADATA_EVAL,\n",
    "            OPERATORS.SET_METADATA_COL_EVAL,\n",
    "            ],\n",
    "        apply=_miscellaneous,\n",
    "        ),\n",
    "\n",
    "    Symbol('´s', 'MODIFY_SETTINGS', 'change query settings',\n",
    "        connectors=[\n",
    "            CONNECTORS.RESET,#default\n",
    "            CONNECTORS.AND,\n",
    "            CONNECTORS.OR\n",
    "            ],\n",
    "        operators=[\n",
    "            OPERATORS.SET_VERBOSITY, #default\n",
    "            OPERATORS.SET_DIFF\n",
    "            ],\n",
    "        apply=_modify_settings,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def query(df_old, code=''):\n",
    "    \"\"\"\n",
    "    A query language for pandas data exploration/analysis/modification.\n",
    "\n",
    "    examples:\n",
    "    df.q('id')  #selects the column 'id'\n",
    "    df.q('id  ´r > 100)  #selects col \"id\" and rows where the value is greater than 100\n",
    "    df.q('´c = id  ´r > 100) #same as above but more explicit\n",
    "    df.q('id  ´r > 100  ´c / name  ´r ? john')  #selects col \"id\" and\n",
    "        #rows where the value is greater than 100 or col \"name\" and rows where the value contains \"john\"\n",
    "    \"\"\"\n",
    "\n",
    "    #setup\n",
    "\n",
    "    _check_df(df_old)\n",
    "    df_new = df_old.copy()\n",
    "    diff = None\n",
    "    verbosity = 3\n",
    "    cols = pd.Series([True for col in df_new.columns])\n",
    "    cols.index = df_new.columns\n",
    "    rows = pd.Series([True for row in df_new.index])\n",
    "    rows.index = df_new.index\n",
    "\n",
    "\n",
    "    #parse and apply instructions\n",
    "\n",
    "    lines, instruction_strs = _tokenize_code(code, verbosity)\n",
    "\n",
    "    for instruction_str in instruction_strs:\n",
    "        instruction = _parse_instruction(instruction_str, verbosity)\n",
    "        df_new, rows, cols, diff, verbosity  = instruction.apply(instruction, df_new, rows, cols, diff, verbosity)\n",
    "\n",
    "\n",
    "\n",
    "    #results\n",
    "\n",
    "    df_filtered = df_new.loc[rows, cols]\n",
    "\n",
    "    if diff is None:\n",
    "        return df_filtered \n",
    "    else:\n",
    "        #show difference before and after filtering\n",
    "        if 'meta' in df_old.columns and 'meta' not in df_filtered.columns:\n",
    "            df_filtered.insert(0, 'meta', df_old.loc[rows, 'meta'])\n",
    "\n",
    "        result = _diff(\n",
    "            df_filtered, df_old,\n",
    "            mode=diff,\n",
    "            verbosity=verbosity\n",
    "            )  \n",
    "        return result\n",
    "\n",
    "def _tokenize_code(code, verbosity):\n",
    "    \"\"\"\n",
    "    Turns the plain text input string into a list of instructions for the query parser.\n",
    "    \"\"\"\n",
    "\n",
    "    lines = []\n",
    "    instructions_all = []\n",
    "\n",
    "    #get lines and instruction blocks\n",
    "    for line_num, line in enumerate(code.split('\\n')):\n",
    "        line = line.strip()\n",
    "        lines.append([line_num, line])\n",
    "        line = line.split(COMMENT.symbol)[0].strip()\n",
    "        instructions = []\n",
    "    \n",
    "        if line == '':\n",
    "            continue\n",
    "\n",
    "\n",
    "        escape = False\n",
    "        chars_in_instruction = 0\n",
    "        instruction_type = INSTRUCTIONS.SELECT_COLS.symbol  #default\n",
    "\n",
    "        for i, char in enumerate(line):\n",
    "            if escape:\n",
    "                instructions[-1] += char\n",
    "                chars_in_instruction += 1\n",
    "                escape = False\n",
    "                continue\n",
    "            elif char == ESCAPE.symbol:\n",
    "                escape = True\n",
    "                continue\n",
    "\n",
    "            if char == '´':\n",
    "                instruction_type = char + line[i+1]\n",
    "                instructions.append(char)\n",
    "                chars_in_instruction = 1\n",
    "            elif char in [CONNECTORS.AND.symbol, CONNECTORS.OR.symbol]:\n",
    "                if chars_in_instruction >= 3:\n",
    "                    instructions.append(f'{instruction_type} {char}')\n",
    "                    chars_in_instruction = 3\n",
    "                elif i == 0:\n",
    "                    instructions.append(f'{instruction_type} {char}')\n",
    "                    chars_in_instruction = 3\n",
    "                else:\n",
    "                    instructions[-1] += char\n",
    "                    chars_in_instruction += 1\n",
    "            elif i == 0:\n",
    "                instructions.append(f'{instruction_type} {char}')\n",
    "                chars_in_instruction = 3\n",
    "            elif char == ' ':\n",
    "                instructions[-1] += char\n",
    "            else:\n",
    "                instructions[-1] += char\n",
    "                chars_in_instruction += 1\n",
    "\n",
    "        log(f'debug: parsed line \"{line}\" into instruction strings: {instructions}',\n",
    "            'qp.qlang._tokenize', verbosity)\n",
    "        \n",
    "        instructions_all += instructions\n",
    "\n",
    "    return lines, instructions_all\n",
    "\n",
    "\n",
    "\n",
    "def _parse_instruction(instruction_str, verbosity):\n",
    "    \"\"\"\n",
    "    Parses an instruction string into an instruction object.\n",
    "    \"\"\"\n",
    "\n",
    "    instruction, text = _extract_symbol(instruction_str, symbols=[x for x in INSTRUCTIONS], verbosity=verbosity)\n",
    "    instruction.str = instruction_str\n",
    "    instruction.repr = f'{instruction.name}:\\n'\n",
    "\n",
    "    instruction.connector, text = _extract_symbol(text, symbols=instruction.connectors, verbosity=verbosity)\n",
    "    instruction.repr += f'\\tconnector: {instruction.connector}\\n'\n",
    "\n",
    "    if hasattr(instruction, 'scopes'):\n",
    "        instruction.scope, text = _extract_symbol(text, symbols=instruction.scopes, verbosity=verbosity)\n",
    "        instruction.repr += f'\\tscope: {instruction.scope}\\n'\n",
    "\n",
    "    if hasattr(instruction, 'negations'):\n",
    "        instruction.negation, text = _extract_symbol(text, symbols=instruction.negations, verbosity=verbosity)\n",
    "        instruction.repr += f'\\tnegation: {instruction.negation}\\n'\n",
    "\n",
    "    instruction.operator, text = _extract_symbol(text, symbols=instruction.operators, verbosity=verbosity)\n",
    "    instruction.repr += f'\\toperator: {instruction.operator}\\n'\n",
    "\n",
    "    instruction.value = text.strip()\n",
    "    instruction.repr += f'\\tvalue: {instruction.value}\\n'\n",
    "\n",
    "    if instruction.operator.unary and len(instruction.value)>0:\n",
    "        log(f'warning: unary operator \"{instruction.operator}\" cannot use a value. value \"{instruction.value}\" will be ignored',\n",
    "            'qp.qlang._parse_instruction', verbosity)\n",
    "        instruction.value = ''\n",
    "\n",
    "    log(f'debug: parsed \"{instruction.str}\" as instruction:\\n{instruction.repr}',\n",
    "        'qp.qlang._parse_instruction', verbosity)\n",
    "\n",
    "    return instruction\n",
    "\n",
    "\n",
    "def _extract_symbol(string, symbols, verbosity):\n",
    "    \"\"\"\n",
    "    Looks for expected syntax symbols at the beginning of an instruction string.\n",
    "    \"\"\"\n",
    "\n",
    "    string = string.strip()\n",
    "\n",
    "    if len(symbols) == 0:\n",
    "        return None, string\n",
    "    elif len(symbols) == 1:\n",
    "        symbol = symbols[0]\n",
    "        return symbol, string[len(symbol.symbol):].strip()\n",
    "    else:\n",
    "        default = symbols[0]\n",
    "        symbols = symbols[1:]\n",
    "\n",
    "    for symbol in symbols:\n",
    "        if string.startswith(symbol.symbol):\n",
    "            log(f'trace: found symbol \"{symbol}\" in string \"{string}\"', 'qp.qlang._extract_symbol', verbosity)\n",
    "            return symbol, string[len(symbol.symbol):].strip()\n",
    "    \n",
    "    if string.startswith(default.symbol):\n",
    "        return default, string[len(default.symbol):].strip()\n",
    "    else:\n",
    "        log(f'trace: no symbol found in string \"{string}\". using default \"{default}\"', 'qp.qlang._extract_symbol', verbosity)\n",
    "        return default, string\n",
    "\n",
    "\n",
    "def _filter_series(series, negation, operator, value, verbosity, df_new=None):\n",
    "    \"\"\"\n",
    "    Filters a pandas series according to the given instruction.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #numeric comparison\n",
    "    if operator == OPERATORS.BIGGER_EQUAL:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') >= pd.to_numeric(value)\n",
    "    elif operator == OPERATORS.SMALLER_EQUAL:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') <= pd.to_numeric(value)\n",
    "    elif operator == OPERATORS.BIGGER:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') > pd.to_numeric(value)\n",
    "    elif operator == OPERATORS.SMALLER:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') < pd.to_numeric(value)\n",
    "\n",
    "\n",
    "    #string equality comparison\n",
    "    elif operator == OPERATORS.STRICT_EQUAL:\n",
    "        filtered = series.astype(str) == value\n",
    "    elif operator == OPERATORS.EQUAL:\n",
    "        value_lenient = [value]\n",
    "        try:\n",
    "            value_lenient.append(str(float(value)))\n",
    "            value_lenient.append(str(int(float(value))))\n",
    "        except:\n",
    "            value_lenient.append(value.lower())\n",
    "        filtered = series.astype(str).str.lower().isin(value_lenient)\n",
    "\n",
    "\n",
    "    #substring comparison\n",
    "    elif operator == OPERATORS.STRICT_CONTAINS:\n",
    "        filtered = series.astype(str).str.contains(value, case=True, regex=False)\n",
    "    elif operator == OPERATORS.CONTAINS:\n",
    "        filtered = series.astype(str).str.contains(value, case=False, regex=False)\n",
    "\n",
    "\n",
    "    #regex comparison\n",
    "    elif operator == OPERATORS.MATCHES_REGEX:\n",
    "        filtered = series.astype(str).str.fullmatch(value) \n",
    "    elif operator == OPERATORS.CONTAINS_REGEX:\n",
    "        filtered = series.astype(str).str.contains(value)\n",
    "\n",
    "\n",
    "    #lambda function\n",
    "    elif operator == OPERATORS.EVAL:\n",
    "        filtered = series.apply(lambda x: eval(value, {'x': x, 'col': series, 'df': df_new, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "    elif operator == OPERATORS.COL_EVAL:\n",
    "        filtered = eval(value, {'col': series, 'df': df_new, 'pd': pd, 'np': np, 'qp': qp})\n",
    "\n",
    "    #load saved selection\n",
    "    elif operator == OPERATORS.LOAD_SELECTION:\n",
    "        if value in df_new.columns:\n",
    "            filtered = df_new[value]\n",
    "        else:\n",
    "            log(f'error: column \"{value}\" does not exist in dataframe. cannot load selection',\n",
    "                'qp.qlang._filter_series', verbosity)\n",
    "\n",
    "\n",
    "    #type checks\n",
    "    elif operator == OPERATORS.IS_STR:\n",
    "        filtered = series.apply(lambda x: isinstance(x, str))\n",
    "    elif operator == OPERATORS.IS_INT:\n",
    "        filtered = series.apply(lambda x: isinstance(x, int))\n",
    "    elif operator == OPERATORS.IS_FLOAT:\n",
    "        filtered = series.apply(lambda x: isinstance(x, float))\n",
    "    elif operator == OPERATORS.IS_NUM:\n",
    "        filtered = series.apply(lambda x: _num(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_BOOL:\n",
    "        filtered = series.apply(lambda x: isinstance(x, bool))\n",
    "\n",
    "    elif operator == OPERATORS.IS_DATETIME:\n",
    "        filtered = series.apply(lambda x: _datetime(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_DATE:\n",
    "        filtered = series.apply(lambda x: _date(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "    elif operator == OPERATORS.IS_ANY:\n",
    "        filtered = series.apply(lambda x: True)\n",
    "    elif operator == OPERATORS.IS_NA:\n",
    "        filtered = series.apply(lambda x: _na(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_NK:\n",
    "        filtered = series.apply(lambda x: _nk(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_YN:\n",
    "        filtered = series.apply(lambda x: _yn(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_YES:\n",
    "        filtered = series.apply(lambda x: _yn(x, errors='ERROR', yes=1)) == 1\n",
    "    elif operator == OPERATORS.IS_NO:\n",
    "        filtered = series.apply(lambda x: _yn(x, errors='ERROR', no=0)) == 0\n",
    "        \n",
    "    elif operator == OPERATORS.IS_UNIQUE:\n",
    "        filtered = series.duplicated(keep=False) == False\n",
    "    elif operator == OPERATORS.IS_FIRST:\n",
    "        filtered = series.duplicated(keep='first') == False\n",
    "    elif operator == OPERATORS.IS_LAST:\n",
    "        filtered = series.duplicated(keep='last') == False\n",
    "\n",
    "    else:\n",
    "        log(f'error: operator \"{operator}\" is not implemented', 'qp.qlang._filter_series', verbosity)\n",
    "        filtered = None\n",
    "\n",
    "\n",
    "    if negation == NEGATIONS.TRUE:\n",
    "        filtered = ~filtered\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def _update_selection(values, values_new, connector):\n",
    "    \"\"\"\n",
    "    Updates the previously selected rows or columns based on the new selection.\n",
    "    \"\"\"\n",
    "    if values is None:\n",
    "        values = values_new\n",
    "    elif connector == CONNECTORS.RESET:\n",
    "        values = values_new\n",
    "    elif connector in [CONNECTORS.AND, SCOPES.ALL]:\n",
    "        values &= values_new\n",
    "    elif connector in [CONNECTORS.OR, SCOPES.ANY]:\n",
    "        values |= values_new\n",
    "    return values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('q')\n",
    "class DataFrameQuery:\n",
    "    \"\"\"\n",
    "    A wrapper for the qp.query function implemented as a dataframe accessor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():\\n' + self.__doc__\n",
    "    \n",
    "    def __call__(self, code=''):\n",
    "        return query(self.df, code)\n",
    "\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('qi')\n",
    "class DataFrameQueryInteractiveMode:\n",
    "    \"\"\"\n",
    "    Wrapper for qp.qlang.query for interactive use in Jupyter notebooks.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __call__(self):\n",
    "        kwargs = {'df': fixed(self.df), 'code': ''}\n",
    "\n",
    "        #code input\n",
    "        ui_code = widgets.Textarea(\n",
    "            value='´s verbosity=3\\n´s diff=None\\n\\n',\n",
    "            placeholder='Enter query code here',\n",
    "            layout=Layout(width='99%', height='97%')\n",
    "            )\n",
    "\n",
    "\n",
    "        #query builder\n",
    "\n",
    "        instruction = INSTRUCTIONS.SELECT_COLS\n",
    "\n",
    "        i_type = widgets.Dropdown(\n",
    "            options=[(s.description, s.symbol) for s in INSTRUCTIONS],\n",
    "            value=instruction.symbol,\n",
    "            )\n",
    "        \n",
    "        i_scope = widgets.Dropdown(\n",
    "            disabled=True,\n",
    "            options=[''],\n",
    "            value='',\n",
    "            )\n",
    "\n",
    "        i_negate = widgets.ToggleButtons(\n",
    "            options=[('dont negate condition', ''), ('negate condition', '!')],\n",
    "            value='',\n",
    "            )\n",
    "\n",
    "        i_operator = widgets.Dropdown(\n",
    "            options=[(f'{s.symbol}: {s.description}', s.symbol) for s in instruction.operators],\n",
    "            value=instruction.operators[0].symbol,\n",
    "            )\n",
    "        \n",
    "        i_value = widgets.Text(\n",
    "            value='',\n",
    "            )\n",
    "        \n",
    "\n",
    "        i_text = widgets.Text(\n",
    "            value=f'\\n{i_type.value} {i_scope.value} {i_negate.value}{i_operator.value} {i_value.value}',\n",
    "            disabled=True,\n",
    "            )\n",
    "        \n",
    "\n",
    "        def update_options(*args):\n",
    "            instruction = INSTRUCTIONS[i_type.value]\n",
    "\n",
    "            if hasattr(instruction, 'scopes'):\n",
    "                i_scope.disabled = False\n",
    "                i_scope.options = [(f'{s.symbol}: {s.description}', s.symbol) for s in instruction.scopes]\n",
    "            else:\n",
    "                i_scope.disabled = True\n",
    "                i_scope.options = ['']\n",
    "\n",
    "            if hasattr(instruction, 'negations'):\n",
    "                i_negate.disabled = False\n",
    "                i_negate.options = [('dont negate condition', ''), ('negate condition', '!')]\n",
    "            else:\n",
    "                i_negate.disabled = True\n",
    "                i_negate.options = ['', '']\n",
    "\n",
    "            i_operator.options = [(f'{s.symbol}: {s.description}', s.symbol) for s in instruction.operators]\n",
    "            i_operator.value = instruction.operators[0].symbol\n",
    "\n",
    "        def update_text(*args):\n",
    "            i_text.value = f'{i_type.value} {i_scope.value} {i_negate.value}{i_operator.value} {i_value.value}\\n'\n",
    "\n",
    "        i_type.observe(update_options, 'value')\n",
    "        i_type.observe(update_text, 'value')\n",
    "        i_scope.observe(update_text, 'value')\n",
    "        i_negate.observe(update_text, 'value')\n",
    "        i_operator.observe(update_text, 'value')\n",
    "        i_value.observe(update_text, 'value')\n",
    "\n",
    "        \n",
    "        ui_add_instruction = widgets.Button(\n",
    "            button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='adds the selected instruction to the query code',\n",
    "            icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    "            )\n",
    "\n",
    "        def add_instruction(ui_code, i_text):\n",
    "            if i_text.value.startswith('´c'):\n",
    "                ui_code.value += f'\\n{i_text.value}'\n",
    "            else:\n",
    "                ui_code.value += f'   {i_text.value}'\n",
    "\n",
    "        ui_add_instruction.on_click(lambda b: add_instruction(ui_code, i_text))\n",
    "\n",
    "        ui_input = VBox([\n",
    "            widgets.HTML(value='<b>query builder:</b>'),\n",
    "            i_text,\n",
    "            i_type,\n",
    "            i_scope,\n",
    "            i_negate,\n",
    "            i_operator,\n",
    "            i_value,\n",
    "            ui_add_instruction,\n",
    "            ])\n",
    "\n",
    "        \n",
    "        #some general info and statistics about the df\n",
    "        mem_usage = self.df.memory_usage().sum() / 1024\n",
    "        ui_details = widgets.HTML(\n",
    "            value=f\"\"\"\n",
    "            <b>shape:</b> {self.df.shape}<br>\n",
    "            <b>memory usage:</b> {mem_usage:,.3f}kb<br>\n",
    "            <b>unique values:</b> {self.df.nunique().sum()}<br>\n",
    "            <b>missing values:</b> {self.df.isna().sum().sum()}<br>\n",
    "            <b>columns:</b><br> {'<br>'.join([f'{col} ({dtype})' for col, dtype in list(zip(self.df.columns, self.df.dtypes))])}<br>\n",
    "            \"\"\"\n",
    "            ) \n",
    "\n",
    "        ui_tabs = widgets.Tab(\n",
    "            children=[\n",
    "                ui_code,\n",
    "                ui_details,\n",
    "                widgets.HTML(value=query.__doc__.replace('\\n', '<br>').replace('    ', '&emsp;')),\n",
    "                ],\n",
    "            titles=['code', 'details', 'readme'],\n",
    "            layout=Layout(width='50%', height='95%')\n",
    "            )\n",
    "        \n",
    "\n",
    "        \n",
    "        ui = HBox([ui_tabs, ui_input], layout=Layout(width='100%', height='300px'))\n",
    "\n",
    "        kwargs['code'] = ui_code\n",
    "\n",
    "        display(ui)\n",
    "        out = HBox([interactive_output(_interactive_mode, kwargs)], layout=Layout(overflow_y='auto'))\n",
    "        display(out)\n",
    "\n",
    "\n",
    "def _interactive_mode(**kwargs):\n",
    "    df = kwargs.pop('df')\n",
    "    code = kwargs.pop('code')\n",
    "    result = query(df, code)\n",
    "    display(result)\n",
    "    return result \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if 'cards' not in globals():\n",
    "#     cards = pd.read_csv('data/cards.csv')\n",
    "# cards.q('toughness ´r >2 & <5')\n",
    "# cards.qi()\n",
    "\n",
    "\n",
    "# df = qp.get_df()\n",
    "# df.q(\n",
    "#     r\"\"\"\n",
    "#     # id ´r ?1  ´n test\n",
    "#     # name ´m ~ x.upper()\n",
    "#     # is any ´r is any\n",
    "\n",
    "#     date of birth / age\n",
    "\n",
    "#     \"\"\",\n",
    "#     diff=None,\n",
    "#     inplace=False,\n",
    "#     verbosity=4,\n",
    "#     )\n",
    "\n",
    "\n",
    "df = qp.get_df()\n",
    "# df.qi()\n",
    "df.q('name ´v sort')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>date of birth</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bp systole</th>\n",
       "      <th>bp diastole</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>dose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30003</td>\n",
       "      <td>IVY GREEN</td>\n",
       "      <td>1955-Jan-09</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-10</td>\n",
       "      <td>130lbs</td>\n",
       "      <td></td>\n",
       "      <td>95</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30 MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>-25</td>\n",
       "      <td>M</td>\n",
       "      <td>170</td>\n",
       "      <td>70.2</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>Normal</td>\n",
       "      <td>No</td>\n",
       "      <td>10kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30005</td>\n",
       "      <td>john Doe</td>\n",
       "      <td>1945 October 11</td>\n",
       "      <td>35</td>\n",
       "      <td>female</td>\n",
       "      <td>200</td>\n",
       "      <td>-65</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30004</td>\n",
       "      <td>JAck Williams</td>\n",
       "      <td>1950 Sep 10</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Mal</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>n</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30001</td>\n",
       "      <td>Grace TAYLOR</td>\n",
       "      <td>28-05-1975</td>\n",
       "      <td>nan</td>\n",
       "      <td>ff</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>1990/09/14</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>175.5cm</td>\n",
       "      <td>68</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "      <td>Highe</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20003</td>\n",
       "      <td>Frank miller</td>\n",
       "      <td>06-30-1983</td>\n",
       "      <td>forty-five</td>\n",
       "      <td>m</td>\n",
       "      <td>185</td>\n",
       "      <td>75kg</td>\n",
       "      <td>125</td>\n",
       "      <td>75</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>Bob Brown</td>\n",
       "      <td>19800406</td>\n",
       "      <td>None</td>\n",
       "      <td>Male</td>\n",
       "      <td>280</td>\n",
       "      <td>na</td>\n",
       "      <td>140</td>\n",
       "      <td>90mmHg</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>No</td>\n",
       "      <td>20mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30002</td>\n",
       "      <td>Harry Clark</td>\n",
       "      <td>1960Mar08</td>\n",
       "      <td>unk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6ft 1in</td>\n",
       "      <td>80.3</td>\n",
       "      <td>122</td>\n",
       "      <td>None</td>\n",
       "      <td>n/a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20002</td>\n",
       "      <td>eva white</td>\n",
       "      <td>05-11-2007</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>135mmhg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>Y</td>\n",
       "      <td>20 Mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>1985.08.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>None</td>\n",
       "      <td>72.5lb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>15 mg once a day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID           name    date of birth         age  gender   height  \\\n",
       "8   30003      IVY GREEN      1955-Jan-09                None      -10   \n",
       "0   10001       John Doe       1995-01-02         -25       M      170   \n",
       "10  30005       john Doe  1945 October 11          35  female      200   \n",
       "9   30004  JAck Williams      1950 Sep 10     unknown     Mal            \n",
       "6   30001   Grace TAYLOR       28-05-1975         nan      ff        1   \n",
       "1   10002     Jane Smith       1990/09/14          30       F  175.5cm   \n",
       "5   20003   Frank miller       06-30-1983  forty-five       m      185   \n",
       "3   20001      Bob Brown         19800406        None    Male      280   \n",
       "7   30002    Harry Clark        1960Mar08         unk     NaN  6ft 1in   \n",
       "4   20002      eva white       05-11-2007        40.0   Other      NaN   \n",
       "2   10003  Alice Johnson       1985.08.23         NaN  Female     None   \n",
       "\n",
       "    weight bp systole bp diastole cholesterol diabetes              dose  \n",
       "8   130lbs                     95        high      NaN             30 MG  \n",
       "0     70.2         20          80      Normal       No              10kg  \n",
       "10     -65         45         NaN      Normal      Yes              40ml  \n",
       "9       82        130           0                    n                35  \n",
       "6     None        NAN         NaN      Normal       NO               NaN  \n",
       "1       68        130          85       Highe      yes               NaN  \n",
       "5     75kg        125          75        High      Yes               25g  \n",
       "3       na        140      90mmHg        GOOD       No              20mg  \n",
       "7     80.3        122        None         n/a     None              None  \n",
       "4             135mmhg         NaN        n.a.        Y             20 Mg  \n",
       "2   72.5lb        NaN         nan         NaN      N/A  15 mg once a day  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>date of birth</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bp systole</th>\n",
       "      <th>bp diastole</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>dose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20002</td>\n",
       "      <td>eva white</td>\n",
       "      <td>05-11-2007</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>135mmhg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>Y</td>\n",
       "      <td>20 Mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20003</td>\n",
       "      <td>Frank miller</td>\n",
       "      <td>06-30-1983</td>\n",
       "      <td>forty-five</td>\n",
       "      <td>m</td>\n",
       "      <td>185</td>\n",
       "      <td>75kg</td>\n",
       "      <td>125</td>\n",
       "      <td>75</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30005</td>\n",
       "      <td>john Doe</td>\n",
       "      <td>1945 October 11</td>\n",
       "      <td>35</td>\n",
       "      <td>female</td>\n",
       "      <td>200</td>\n",
       "      <td>-65</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30004</td>\n",
       "      <td>JAck Williams</td>\n",
       "      <td>1950 Sep 10</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Mal</td>\n",
       "      <td></td>\n",
       "      <td>82</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>n</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30003</td>\n",
       "      <td>IVY GREEN</td>\n",
       "      <td>1955-Jan-09</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>-10</td>\n",
       "      <td>130lbs</td>\n",
       "      <td></td>\n",
       "      <td>95</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30 MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30002</td>\n",
       "      <td>Harry Clark</td>\n",
       "      <td>1960Mar08</td>\n",
       "      <td>unk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6ft 1in</td>\n",
       "      <td>80.3</td>\n",
       "      <td>122</td>\n",
       "      <td>None</td>\n",
       "      <td>n/a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>Bob Brown</td>\n",
       "      <td>19800406</td>\n",
       "      <td>None</td>\n",
       "      <td>Male</td>\n",
       "      <td>280</td>\n",
       "      <td>na</td>\n",
       "      <td>140</td>\n",
       "      <td>90mmHg</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>No</td>\n",
       "      <td>20mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>1985.08.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>None</td>\n",
       "      <td>72.5lb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>15 mg once a day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>1990/09/14</td>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>175.5cm</td>\n",
       "      <td>68</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "      <td>Highe</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>1995-01-02</td>\n",
       "      <td>-25</td>\n",
       "      <td>M</td>\n",
       "      <td>170</td>\n",
       "      <td>70.2</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>Normal</td>\n",
       "      <td>No</td>\n",
       "      <td>10kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30001</td>\n",
       "      <td>Grace TAYLOR</td>\n",
       "      <td>28-05-1975</td>\n",
       "      <td>nan</td>\n",
       "      <td>ff</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID           name    date of birth         age  gender   height  \\\n",
       "4   20002      eva white       05-11-2007        40.0   Other      NaN   \n",
       "5   20003   Frank miller       06-30-1983  forty-five       m      185   \n",
       "10  30005       john Doe  1945 October 11          35  female      200   \n",
       "9   30004  JAck Williams      1950 Sep 10     unknown     Mal            \n",
       "8   30003      IVY GREEN      1955-Jan-09                None      -10   \n",
       "7   30002    Harry Clark        1960Mar08         unk     NaN  6ft 1in   \n",
       "3   20001      Bob Brown         19800406        None    Male      280   \n",
       "2   10003  Alice Johnson       1985.08.23         NaN  Female     None   \n",
       "1   10002     Jane Smith       1990/09/14          30       F  175.5cm   \n",
       "0   10001       John Doe       1995-01-02         -25       M      170   \n",
       "6   30001   Grace TAYLOR       28-05-1975         nan      ff        1   \n",
       "\n",
       "    weight bp systole bp diastole cholesterol diabetes              dose  \n",
       "4             135mmhg         NaN        n.a.        Y             20 Mg  \n",
       "5     75kg        125          75        High      Yes               25g  \n",
       "10     -65         45         NaN      Normal      Yes              40ml  \n",
       "9       82        130           0                    n                35  \n",
       "8   130lbs                     95        high      NaN             30 MG  \n",
       "7     80.3        122        None         n/a     None              None  \n",
       "3       na        140      90mmHg        GOOD       No              20mg  \n",
       "2   72.5lb        NaN         nan         NaN      N/A  15 mg once a day  \n",
       "1       68        130          85       Highe      yes               NaN  \n",
       "0     70.2         20          80      Normal       No              10kg  \n",
       "6     None        NAN         NaN      Normal       NO               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df = qp.get_df()\n",
    "\n",
    "#different ways to sort df:\n",
    "df1 = df.sort_values(by=['height', 'date of birth'], ascending=True)\n",
    "df2 = df.sort_values(by=['date of birth'], ascending=True)\n",
    "\n",
    "display(df1)\n",
    "display(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interactive_output, HBox, VBox, fixed, Layout, interact_manual\n",
    "\n",
    "from qplib.util import log\n",
    "from qplib.types import _int, _float, _num, _bool, _datetime, _date, _na, _nk, _yn, qpDict\n",
    "from qplib.pd_util import _check_df, _diff, _format_df, indexQpExtension, seriesQpExtension, dfQpExtension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Symbol:\n",
    "    def __init__(self, symbol, name, description, unary=None, binary=None, **kwargs):\n",
    "        self.symbol = symbol\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.unary = unary\n",
    "        self.binary = binary\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name} (symbol: \"{self.symbol}\" description: \"{self.description})\"'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.name} (symbol: \"{self.symbol}\" description: \"{self.description})\"'\n",
    "\n",
    "class Symbols:\n",
    "    def __init__(self, name, *symbols):\n",
    "        self.name = name\n",
    "        self.by_name = {symbol.name: symbol for symbol in symbols}\n",
    "        self.by_symbol = {symbol.symbol: symbol for symbol in symbols}\n",
    "        for symbol in symbols:\n",
    "            setattr(self, symbol.name, symbol)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key in self.by_symbol:\n",
    "            return self.by_symbol[key]\n",
    "        elif key in self.by_name:\n",
    "            return self.by_name[key]\n",
    "        else:\n",
    "            log(f'error: symbol \"{key}\" not found in \"{self.name}\"', 'Symbols.__getitem__', 3)\n",
    "            return None\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.by_name.values())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name}:\\n' + '\\n\\t'.join([str(val) for key,val in self.by_name.items()])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.name}:\\n' + '\\n\\t'.join([str(val) for key,val in self.by_name.items()])\n",
    "\n",
    "\n",
    "class ChangeSettings:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.CHANGE_SETTINGS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.operator = OPERATORS.SET_VERBOSITY\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.operators = [OPERATORS.SET_VERBOSITY, OPERATORS.SET_DIFF, OPERATORS.SET_INPLACE]\n",
    "        self.verbosity = verbosity\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'CHANGE_SETTINGS:\\n\\tconnector: {self.connector}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self, verbosity=None):\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "        \n",
    "    def apply(self, query_obj):\n",
    "        operator = self.operator\n",
    "        value = self.value\n",
    "\n",
    "        if operator == OPERATORS.SET_VERBOSITY:\n",
    "            if value in ['0', '1', '2', '3', '4', '5']:\n",
    "                query_obj.verbosity = int(value)\n",
    "                for instruction in query_obj.instructions:\n",
    "                    instruction.verbosity = query_obj.verbosity\n",
    "            else:\n",
    "                log(f'warning: verbosity must be an integer between 0 and 5. \"{value}\" is not valid',\n",
    "                    'df.q()', query_obj.verbosity)\n",
    "        \n",
    "        elif operator == OPERATORS.SET_DIFF:\n",
    "            if value.lower() in ['none', '0']:\n",
    "                query_obj.diff = None\n",
    "            elif value.lower() in ['mix', 'new', 'old', 'new+']:\n",
    "                query_obj.diff = value.lower()\n",
    "            else:\n",
    "                log(f'warning: diff must be one of [None, \"mix\", \"old\", \"new\", \"new+\"]. \"{value}\" is not valid',\n",
    "                    'df.q()', query_obj.verbosity)\n",
    "                \n",
    "        elif operator == OPERATORS.SET_INPLACE:\n",
    "            if value.lower() in ['true', '1', 'yes']:\n",
    "                query_obj.inplace = True\n",
    "                query_obj.df = query_obj.df_og \n",
    "                query_obj.df.qp = query_obj.df_og.qp\n",
    "\n",
    "            elif value.lower() in ['false', '0', 'no']:\n",
    "                query_obj.inplace = False\n",
    "                query_obj.df = None\n",
    "            else:\n",
    "                log(f'warning: inplace must be a boolean. \"{value}\" is not valid',\n",
    "                    'df.q()', query_obj.verbosity)\n",
    "    \n",
    "\n",
    "class SelectCols:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.SELECT_COLS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.negation = NEGATION.FALSE\n",
    "        self.operator = OPERATORS.EQUAL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.negations = [NEGATION.TRUE]\n",
    "        self.operators = [\n",
    "            #binary\n",
    "            OPERATORS.BIGGER_EQUAL, OPERATORS.SMALLER_EQUAL, OPERATORS.BIGGER, OPERATORS.SMALLER,\n",
    "            OPERATORS.STRICT_EQUAL, OPERATORS.EQUAL,\n",
    "            OPERATORS.STRICT_CONTAINS, OPERATORS.CONTAINS,\n",
    "            OPERATORS.MATCHES_REGEX, OPERATORS.CONTAINS_REGEX,\n",
    "            OPERATORS.EVAL,\n",
    "            OPERATORS.LOAD_SELECTION,\n",
    "        \n",
    "            #unary\n",
    "            OPERATORS.IS_ANY,\n",
    "            OPERATORS.IS_UNIQUE,\n",
    "            OPERATORS.IS_NA, OPERATORS.IS_NK,\n",
    "            OPERATORS.IS_STR, OPERATORS.IS_INT, OPERATORS.IS_FLOAT, OPERATORS.IS_NUM, OPERATORS.IS_BOOL,\n",
    "            OPERATORS.IS_DATE, OPERATORS.IS_DATETIME,\n",
    "            OPERATORS.IS_YN, OPERATORS.IS_YES, OPERATORS.IS_NO,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "             \n",
    "    def __repr__(self):\n",
    "        return f'SELECT_COLS:\\n\\tconnector: {self.connector}\\n\\tnegation: {self.negation}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        #parse the expression\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.negation, text = match_symbol(text, self.negation, self.negations, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "\n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            df = query_obj.df_og\n",
    "        else:\n",
    "            df = query_obj.df\n",
    "\n",
    "        cols = df.columns.to_series()\n",
    "\n",
    "        cols_filtered_new = filter_series(query_obj, cols, instruction=self)\n",
    "\n",
    "        if cols_filtered_new.any() == False:\n",
    "            log(f'warning: no columns fulfill the condition in \"{self.text}\"',\n",
    "                'df.q()', self.verbosity)\n",
    "\n",
    "        query_obj.cols_filtered = _update_index(query_obj.cols_filtered, cols_filtered_new, self.connector)\n",
    "\n",
    "\n",
    "class SelectRows:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.SELECT_ROWS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.scope = SCOPE.ANY  #only for rows\n",
    "        self.negation = NEGATION.FALSE\n",
    "        self.operator = OPERATORS.EQUAL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.scopes = [SCOPE.ANY, SCOPE.ALL, SCOPE.INDEX]  #only for rows\n",
    "        self.negations = [NEGATION.TRUE]\n",
    "        self.operators = [\n",
    "            #binary\n",
    "            OPERATORS.BIGGER_EQUAL, OPERATORS.SMALLER_EQUAL, OPERATORS.BIGGER, OPERATORS.SMALLER,\n",
    "            OPERATORS.STRICT_EQUAL, OPERATORS.EQUAL,\n",
    "            OPERATORS.STRICT_CONTAINS, OPERATORS.CONTAINS,\n",
    "            OPERATORS.MATCHES_REGEX, OPERATORS.CONTAINS_REGEX,\n",
    "            OPERATORS.EVAL, OPERATORS.COL_EVAL,  #only for rows\n",
    "            OPERATORS.LOAD_SELECTION,\n",
    "        \n",
    "            #unary\n",
    "            OPERATORS.IS_ANY,\n",
    "            OPERATORS.IS_UNIQUE, OPERATORS.IS_FIRST, OPERATORS.IS_LAST,\n",
    "            OPERATORS.IS_NA, OPERATORS.IS_NK,\n",
    "            OPERATORS.IS_STR, OPERATORS.IS_INT, OPERATORS.IS_FLOAT, OPERATORS.IS_NUM, OPERATORS.IS_BOOL,\n",
    "            OPERATORS.IS_DATE, OPERATORS.IS_DATETIME,\n",
    "            OPERATORS.IS_YN, OPERATORS.IS_YES, OPERATORS.IS_NO,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "             \n",
    "    def __repr__(self):\n",
    "        return f'SELECT_ROWS:\\n\\tconnector: {self.connector}\\n\\tscope: {self.scope}\\n\\tnegation: {self.negation}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        #parse the expression\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.scope, text = match_symbol(text, self.scope, self.scopes, self.verbosity)\n",
    "        self.negation, text = match_symbol(text, self.negation, self.negations, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "\n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            df = query_obj.df_og\n",
    "        else:\n",
    "            df = query_obj.df\n",
    "\n",
    "        #select rows using parsed expression\n",
    "        scope = self.scope\n",
    "        connector = self.connector\n",
    "        verbosity = query_obj.verbosity\n",
    "\n",
    "        rows = df.index.to_series()\n",
    "        cols_filtered = query_obj.cols_filtered\n",
    "\n",
    "        if cols_filtered.any() == False:\n",
    "            log(f'warning: row filter cannot be applied when no columns where selected', 'df.q', verbosity)\n",
    "            return\n",
    "                \n",
    "        if scope == SCOPE.INDEX:\n",
    "            rows_filtered_new = filter_series(query_obj, rows, instruction=self)\n",
    "            query_obj.rows_filtered = _update_index(query_obj.rows_filtered, rows_filtered_new, connector)\n",
    "\n",
    "        else:\n",
    "            rows_filtered_temp = None\n",
    "            for col in df.columns[cols_filtered]:\n",
    "                rows_filtered_new = filter_series(query_obj, df[col], instruction=self)\n",
    "                rows_filtered_temp = _update_index(rows_filtered_temp, rows_filtered_new, scope)\n",
    "            query_obj.rows_filtered = _update_index(query_obj.rows_filtered, rows_filtered_temp, connector)\n",
    "\n",
    "            if rows_filtered_temp.any() == False:\n",
    "                log(f'warning: no rows fulfill the condition in \"{self.text}\"', 'df.q', verbosity)\n",
    "\n",
    "\n",
    "class ModifyVals:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.MODIFY_VALS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.operator = OPERATORS.SET_VAL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.operators = [\n",
    "            OPERATORS.SET_VAL, OPERATORS.ADD_VAL,\n",
    "            OPERATORS.SET_EVAL, OPERATORS.SET_COL_EVAL,\n",
    "            OPERATORS.TO_STR, OPERATORS.TO_INT, OPERATORS.TO_FLOAT, OPERATORS.TO_NUM, OPERATORS.TO_BOOL,\n",
    "            OPERATORS.TO_DATE, OPERATORS.TO_DATETIME, OPERATORS.TO_NA, OPERATORS.TO_NK, OPERATORS.TO_YN,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MODIFY_VALS:\\n\\tconnector: {self.connector}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "        \n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            query_obj.df = query_obj.df_og.copy()  #default is inplace=False\n",
    "            query_obj.df.qp = query_obj.df.qp\n",
    "        \n",
    "        rows = query_obj.rows_filtered\n",
    "        cols = query_obj.cols_filtered\n",
    "\n",
    "        operator = self.operator\n",
    "        value = self.value\n",
    "\n",
    "        #data modification  \n",
    "        if operator == OPERATORS.SET_VAL:\n",
    "            query_obj.df.loc[rows, cols] = value\n",
    "        elif operator == OPERATORS.ADD_VAL:\n",
    "            query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].astype(str) + value\n",
    "        elif operator == OPERATORS.SET_COL_EVAL:\n",
    "            query_obj.df.loc[:, cols] = query_obj.df.loc[:, cols].apply(lambda x: eval(value, {'col': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}), axis=0)\n",
    "\n",
    "\n",
    "        elif pd.__version__ >= '2.1.0':  #map was called applymap before 2.1.0\n",
    "            #data modification\n",
    "            if operator == OPERATORS.SET_EVAL:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(lambda x: eval(value, {'x': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "\n",
    "\n",
    "            #type conversion\n",
    "            elif operator == OPERATORS.TO_STR:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(str)\n",
    "            elif operator == OPERATORS.TO_INT:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_int)\n",
    "            elif operator == OPERATORS.TO_FLOAT:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_float)\n",
    "            elif operator == OPERATORS.TO_NUM:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_num)\n",
    "            elif operator == OPERATORS.TO_BOOL:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_bool)\n",
    "            \n",
    "            elif operator == OPERATORS.TO_DATETIME:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_datetime)\n",
    "            elif operator == OPERATORS.TO_DATE:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_date)\n",
    "\n",
    "            elif operator == OPERATORS.TO_NA:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_na)\n",
    "            elif operator == OPERATORS.TO_NK:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_nk)\n",
    "            elif operator == OPERATORS.TO_YN:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_yn)\n",
    "\n",
    "        else:\n",
    "            #data modification\n",
    "            if operator == OPERATORS.SET_EVAL:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(lambda x: eval(value, {'x': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "\n",
    "            #type conversion\n",
    "            elif operator == OPERATORS.TO_STR:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(str)\n",
    "            elif operator == OPERATORS.TO_INT:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_int)\n",
    "            elif operator == OPERATORS.TO_FLOAT:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_float)\n",
    "            elif operator == OPERATORS.TO_NUM:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_num)\n",
    "            elif operator == OPERATORS.TO_BOOL:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_bool)\n",
    "            \n",
    "            elif operator == OPERATORS.TO_DATETIME:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_datetime)\n",
    "            elif operator == OPERATORS.TO_DATE:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_date)\n",
    "\n",
    "            elif operator == OPERATORS.TO_NA:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_na)\n",
    "            elif operator == OPERATORS.TO_NK:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_nk)\n",
    "            elif operator == OPERATORS.TO_YN:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_yn)\n",
    "\n",
    "\n",
    "class ModifyHeaders:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.MODIFY_HEADERS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.operator = OPERATORS.SET_VAL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.operators = [\n",
    "            OPERATORS.SET_VAL, OPERATORS.ADD_VAL,\n",
    "            OPERATORS.SET_EVAL,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MODIFY_HEADERS:\\n\\tconnector: {self.connector}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "        \n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            query_obj.df = query_obj.df_og.copy()  #default is inplace=False\n",
    "            query_obj.df.qp = query_obj.df.qp\n",
    "        \n",
    "        cols = query_obj.cols_filtered\n",
    "\n",
    "        operator = self.operator\n",
    "        value = self.value\n",
    "\n",
    "\n",
    "        if operator == OPERATORS.SET_VAL:\n",
    "            query_obj.df.rename(columns={col: value for col in query_obj.df.columns[cols]}, inplace=True)\n",
    "            query_obj.cols_filtered.index = query_obj.df.columns\n",
    "        \n",
    "        if pd.__version__ >= '2.1.0':\n",
    "            if operator == OPERATORS.SET_EVAL:\n",
    "                new_headers = query_obj.df.columns.map(lambda x: eval(value, {'header': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "                query_obj.df.columns = new_headers\n",
    "                query_obj.cols_filtered.index = new_headers\n",
    "        else:\n",
    "            if operator == OPERATORS.SET_EVAL:\n",
    "                new_headers = query_obj.df.columns.applymap(lambda x: eval(value, {'header': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "                query_obj.df.columns = new_headers\n",
    "                query_obj.cols_filtered.index = new_headers\n",
    "\n",
    "\n",
    "class NewCol:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.NEW_COL\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.operator = OPERATORS.STR_COL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.operators = [\n",
    "            OPERATORS.STR_COL,\n",
    "            OPERATORS.EVAL_COL,\n",
    "            OPERATORS.SAVE_SELECTION,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'NEW_COL:\\n\\tconnector: {self.connector}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "        \n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            query_obj.df = query_obj.df_og.copy()  #default is inplace=False\n",
    "            query_obj.df.qp = query_obj.df.qp\n",
    "        \n",
    "        if self.operator == OPERATORS.STR_COL:\n",
    "            for i in range(1, 1001):\n",
    "                if i == 1000:\n",
    "                    log(f'warning: could not add new column. too many columns named \"new<x>\"',\n",
    "                        'df.q.new_col', query_obj.verbosity)\n",
    "                    break\n",
    "\n",
    "                header = 'new' + str(i)\n",
    "                if header not in query_obj.df.columns:\n",
    "                    query_obj.df[header] = ''\n",
    "                    query_obj.df.loc[query_obj.rows_filtered, header] = self.value\n",
    "                    query_obj.cols_filtered = pd.Index([True if col == header else False for col in query_obj.df.columns])\n",
    "                    query_obj.cols_filtered.index = query_obj.df.columns\n",
    "                    break\n",
    "        \n",
    "        elif self.operator == OPERATORS.EVAL_COL:\n",
    "            for i in range(1, 1001):\n",
    "                if i == 1000:\n",
    "                    log(f'warning: could not add new column. too many columns named \"new<x>\"',\n",
    "                        'df.q.new_col', query_obj.verbosity)\n",
    "                    break\n",
    "\n",
    "                header = 'new' + str(i)\n",
    "                if header not in query_obj.df.columns:\n",
    "                    query_obj.df[header] = pd.NA\n",
    "                    query_obj.df.loc[query_obj.rows_filtered, header] = eval(self.value, {'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp})\n",
    "                    query_obj.cols_filtered = pd.Index([True if col == header else False for col in query_obj.df.columns])\n",
    "                    query_obj.cols_filtered.index = query_obj.df.columns\n",
    "                    break\n",
    "        \n",
    "\n",
    "        elif self.operator == OPERATORS.SAVE_SELECTION:\n",
    "            if self.value in query_obj.df.columns:\n",
    "                log(f'warning: column \"{self.value}\" already exists in dataframe. selecting existing col and resetting values',\n",
    "                    'df.q.new_col', query_obj.verbosity)\n",
    "                query_obj.df[self.value] = query_obj.rows_filtered\n",
    "                query_obj.cols_filtered = pd.Index([True if col == self.value else False for col in query_obj.df.columns])\n",
    "                query_obj.cols_filtered.index = query_obj.df.columns\n",
    "            else:\n",
    "                query_obj.df[self.value] = query_obj.rows_filtered\n",
    "                query_obj.cols_filtered = pd.Index([True if col == self.value else False for col in query_obj.df.columns])\n",
    "                query_obj.cols_filtered.index = query_obj.df.columns\n",
    "\n",
    "\n",
    "\n",
    "COMMENT = Symbol('#', 'COMMENT', 'comments out the rest of the line')\n",
    "ESCAPE = Symbol('`', 'ESCAPE', 'escape the next character')\n",
    "\n",
    "TYPES = Symbols('TYPES',\n",
    "    Symbol('´s', 'CHANGE_SETTINGS', 'change query settings', instruction=ChangeSettings),\n",
    "    Symbol('´c', 'SELECT_COLS', 'select columns fulfilling a condition', instruction=SelectCols),\n",
    "    Symbol('´r', 'SELECT_ROWS', 'select rows fulfilling a condition', instruction=SelectRows),\n",
    "    Symbol('´v', 'MODIFY_VALS', 'modify the selected values', instruction=ModifyVals),\n",
    "    Symbol('´h', 'MODIFY_HEADERS', 'modify headers of the selected columns', instruction=ModifyHeaders),\n",
    "    Symbol('´n', 'NEW_COL', 'add new column', instruction=NewCol),\n",
    "    )\n",
    "\n",
    "CONNECTORS = Symbols('CONNECTORS',\n",
    "    Symbol('', 'RESET', 'only the current condition must be fulfilled'),\n",
    "    Symbol('&', 'AND', 'this condition and the previous condition/s must be fulfilled'),\n",
    "    Symbol('/', 'OR', 'this condition or the previous condition/s must be fulfilled'),\n",
    "    )\n",
    "\n",
    "SCOPE = Symbols('SCOPE',\n",
    "    Symbol('any', 'ANY', 'any of the currently selected columns must fulfill the condition'),\n",
    "    Symbol('all', 'ALL', 'all of the currently selected columns must fulfill the condition'),\n",
    "    Symbol('idx', 'INDEX', 'the index of the dataframe must fulfill the condition'),\n",
    "    )\n",
    "\n",
    "NEGATION = Symbols('NEGATION',\n",
    "    Symbol('', 'FALSE', 'dont negate the condition'),\n",
    "    Symbol('!', 'TRUE', 'negate the condition'),\n",
    "    )\n",
    "\n",
    "OPERATORS = Symbols('OPERATORS',\n",
    "    #for changing settings\n",
    "    Symbol('verbosity=', 'SET_VERBOSITY', 'change the verbosity level'),\n",
    "    Symbol('diff=', 'SET_DIFF', 'change the diff setting'),\n",
    "    Symbol('inplace=', 'SET_INPLACE', 'change the inplace setting'),\n",
    "\n",
    "\n",
    "    #for filtering\n",
    "    Symbol('>=', 'BIGGER_EQUAL', 'bigger or equal', binary=True),\n",
    "    Symbol('<=', 'SMALLER_EQUAL', 'smaller or equal', binary=True),\n",
    "    Symbol('>', 'BIGGER', 'bigger', binary=True),\n",
    "    Symbol('<', 'SMALLER', 'smaller', binary=True),\n",
    "\n",
    "    Symbol('==', 'STRICT_EQUAL', 'equal to (case sensitive)', binary=True),\n",
    "    Symbol('=', 'EQUAL', 'equal to', binary=True),\n",
    "\n",
    "    Symbol('??', 'STRICT_CONTAINS', 'contains a string (case sensitive)', binary=True),\n",
    "    Symbol('?', 'CONTAINS', 'contains a string (not case sensitive)', binary=True),\n",
    "\n",
    "    Symbol('r=', 'MATCHES_REGEX', 'matches a regex', binary=True),\n",
    "    Symbol('r?', 'CONTAINS_REGEX', 'contains a regex', binary=True),\n",
    "\n",
    "    Symbol('~', 'EVAL', 'select values by evaluating a python expression on each value', binary=True),\n",
    "    Symbol('col~', 'COL_EVAL', 'select rows by evaluating a python expression on a whole column', binary=True),\n",
    "\n",
    "    Symbol('@', 'LOAD_SELECTION', 'load a saved selection from a boolean column', binary=True),\n",
    "\n",
    "    Symbol('is any', 'IS_ANY', 'is any value', unary=True),\n",
    "    Symbol('is str', 'IS_STR', 'is string', unary=True),\n",
    "    Symbol('is int', 'IS_INT', 'is integer', unary=True),\n",
    "    Symbol('is float', 'IS_FLOAT', 'is float', unary=True),\n",
    "    Symbol('is num', 'IS_NUM', 'is number', unary=True),\n",
    "    Symbol('is bool', 'IS_BOOL', 'is boolean', unary=True),\n",
    "    Symbol('is datetime', 'IS_DATETIME', 'is datetime', unary=True),\n",
    "    Symbol('is date', 'IS_DATE', 'is date', unary=True),\n",
    "    Symbol('is na', 'IS_NA', 'is missing value', unary=True),\n",
    "    Symbol('is nk', 'IS_NK', 'is not known value', unary=True),\n",
    "    Symbol('is yn', 'IS_YN', 'is yes or no value', unary=True),\n",
    "    Symbol('is yes', 'IS_YES', 'is yes value', unary=True),\n",
    "    Symbol('is no', 'IS_NO', 'is no value', unary=True),\n",
    "    Symbol('is unique', 'IS_UNIQUE', 'is a unique value', unary=True),\n",
    "    Symbol('is first', 'IS_FIRST', 'is the first value (of multiple values)', unary=True),\n",
    "    Symbol('is last', 'IS_LAST', 'is the last value (of multiple values)', unary=True),\n",
    "\n",
    "\n",
    "    #for modifying values and headers\n",
    "    Symbol('=', 'SET_VAL', 'convert to string'),\n",
    "    Symbol('+=', 'ADD_VAL', 'append to string (coerce to string if needed)'),\n",
    "\n",
    "    Symbol('~', 'SET_EVAL', 'convert by evaluating a python expression for each selected value/header'),\n",
    "    Symbol('col~', 'SET_COL_EVAL', 'convert by evaluating a python expression for each selected column'),\n",
    "\n",
    "    Symbol('to str', 'TO_STR', 'convert to string', unary=True),\n",
    "    Symbol('to int', 'TO_INT', 'convert to integer', unary=True),\n",
    "    Symbol('to float', 'TO_FLOAT', 'convert to float', unary=True),\n",
    "    Symbol('to num', 'TO_NUM', 'convert to number', unary=True),\n",
    "    Symbol('to bool', 'TO_BOOL', 'convert to boolean', unary=True),\n",
    "    Symbol('to datetime', 'TO_DATETIME', 'convert to datetime', unary=True),\n",
    "    Symbol('to date', 'TO_DATE', 'convert to date', unary=True),\n",
    "    Symbol('to na', 'TO_NA', 'convert to missing value', unary=True),\n",
    "    Symbol('to nk', 'TO_NK', 'convert to not known value', unary=True),\n",
    "    Symbol('to yn', 'TO_YN', 'convert to yes or no value', unary=True),\n",
    "\n",
    "\n",
    "    #for adding new columns\n",
    "    Symbol('=', 'STR_COL', 'add new column, fill it with the given string and select it'),\n",
    "    Symbol('~', 'EVAL_COL', 'add new column, fill it by evaluating a python expression and select it'),\n",
    "    Symbol('@', 'SAVE_SELECTION', 'add a new boolean column with the given name and select it. all currently selected rows are set to True, the rest to False'),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(code, verbosity=3):\n",
    "    lines = []\n",
    "    instructions = []\n",
    "\n",
    "    #get lines and instruction blocks\n",
    "    for line_num, line in enumerate(code.split('\\n')):\n",
    "        line = line.strip()\n",
    "        lines.append([line_num, line])\n",
    "        line = line.split(COMMENT.symbol)[0].strip()\n",
    "    \n",
    "        if line == '':\n",
    "            continue\n",
    "\n",
    "\n",
    "        escape = False\n",
    "        chars_in_instruction = 0\n",
    "        instruction_type = TYPES.SELECT_COLS.symbol  #default\n",
    "\n",
    "        for i, char in enumerate(line):\n",
    "            if escape:\n",
    "                instructions[-1].text += char\n",
    "                chars_in_instruction += 1\n",
    "                escape = False\n",
    "                continue\n",
    "            elif char == ESCAPE.symbol:\n",
    "                escape = True\n",
    "                continue\n",
    "\n",
    "            if char == '´':\n",
    "                instruction_type = char + line[i+1]\n",
    "                instructions.append(TYPES[instruction_type].instruction(char, line_num, verbosity))\n",
    "                chars_in_instruction = 1\n",
    "            elif char in [CONNECTORS.AND.symbol, CONNECTORS.OR.symbol]:\n",
    "                if chars_in_instruction >= 3:\n",
    "                    instructions.append(TYPES[instruction_type].instruction(f'{instruction_type} {char}', line_num, verbosity))\n",
    "                    chars_in_instruction = 3\n",
    "                elif i == 0:\n",
    "                    instructions.append(TYPES[instruction_type].instruction(f'{instruction_type} {char}', line_num, verbosity))\n",
    "                    chars_in_instruction = 3\n",
    "                else:\n",
    "                    instructions[-1].text += char\n",
    "                    chars_in_instruction += 1\n",
    "            elif i == 0:\n",
    "                instructions.append(TYPES[instruction_type].instruction(f'{instruction_type} {char}', line_num, verbosity))\n",
    "                chars_in_instruction = 3\n",
    "            elif char == ' ':\n",
    "                instructions[-1].text += char\n",
    "            else:\n",
    "                instructions[-1].text += char\n",
    "                chars_in_instruction += 1\n",
    "\n",
    "    return lines, instructions\n",
    "\n",
    "\n",
    "def match_symbol(string, default, symbols, verbosity):\n",
    "    string = string.strip()\n",
    "\n",
    "    for symbol in symbols:\n",
    "        if string.startswith(symbol.symbol):\n",
    "            log(f'trace: found symbol \"{symbol}\" in string \"{string}\"', 'match_symbol', verbosity)\n",
    "            return symbol, string[len(symbol.symbol):].strip()\n",
    "    \n",
    "    log(f'trace: no symbol found in string \"{string}\". using default \"{default}\"', 'match_symbol', verbosity)\n",
    "    \n",
    "    if default is None:\n",
    "        return None, string\n",
    "    if string.startswith(default.symbol):\n",
    "        string = string[len(default.symbol):].strip()\n",
    "    return default, string\n",
    "\n",
    "\n",
    "def filter_series(query_obj, series, instruction):\n",
    "    negation = instruction.negation\n",
    "    operator = instruction.operator\n",
    "    value = instruction.value\n",
    "    verbosity = instruction.verbosity\n",
    "    df = query_obj.df\n",
    "\n",
    "\n",
    "    #numeric comparison\n",
    "    if operator == OPERATORS.BIGGER_EQUAL:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') >= pd.to_numeric(value)\n",
    "    elif operator == OPERATORS.SMALLER_EQUAL:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') <= pd.to_numeric(value)\n",
    "    elif operator == OPERATORS.BIGGER:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') > pd.to_numeric(value)\n",
    "    elif operator == OPERATORS.SMALLER:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') < pd.to_numeric(value)\n",
    "\n",
    "\n",
    "    #string equality comparison\n",
    "    elif operator == OPERATORS.STRICT_EQUAL:\n",
    "        filtered = series.astype(str) == value\n",
    "    elif operator == OPERATORS.EQUAL:\n",
    "        value_lenient = [value]\n",
    "        try:\n",
    "            value_lenient.append(str(float(value)))\n",
    "            value_lenient.append(str(int(float(value))))\n",
    "        except:\n",
    "            value_lenient.append(value.lower())\n",
    "        filtered = series.astype(str).str.lower().isin(value_lenient)\n",
    "\n",
    "\n",
    "    #substring comparison\n",
    "    elif operator == OPERATORS.STRICT_CONTAINS:\n",
    "        filtered = series.astype(str).str.contains(value, case=True, regex=False)\n",
    "    elif operator == OPERATORS.CONTAINS:\n",
    "        filtered = series.astype(str).str.contains(value, case=False, regex=False)\n",
    "\n",
    "\n",
    "    #regex comparison\n",
    "    elif operator == OPERATORS.MATCHES_REGEX:\n",
    "        filtered = series.astype(str).str.fullmatch(value) \n",
    "    elif operator == OPERATORS.CONTAINS_REGEX:\n",
    "        filtered = series.astype(str).str.contains(value)\n",
    "\n",
    "\n",
    "    #lambda function\n",
    "    elif operator == OPERATORS.EVAL:\n",
    "        filtered = series.apply(lambda x: eval(value, {'x': x, 'col': series, 'df': df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "    elif operator == OPERATORS.COL_EVAL:\n",
    "        filtered = eval(value, {'col': series, 'df': df, 'pd': pd, 'np': np, 'qp': qp})\n",
    "\n",
    "    #load saved selection\n",
    "    elif operator == OPERATORS.LOAD_SELECTION:\n",
    "        if value in df.columns:\n",
    "            filtered = df[value]\n",
    "        else:\n",
    "            log(f'error: column \"{value}\" does not exist in dataframe. cannot load selection',\n",
    "                '_filter()', verbosity)\n",
    "\n",
    "\n",
    "    #type checks\n",
    "    elif operator == OPERATORS.IS_STR:\n",
    "        filtered = series.apply(lambda x: isinstance(x, str))\n",
    "    elif operator == OPERATORS.IS_INT:\n",
    "        filtered = series.apply(lambda x: isinstance(x, int))\n",
    "    elif operator == OPERATORS.IS_FLOAT:\n",
    "        filtered = series.apply(lambda x: isinstance(x, float))\n",
    "    elif operator == OPERATORS.IS_NUM:\n",
    "        filtered = series.apply(lambda x: _num(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_BOOL:\n",
    "        filtered = series.apply(lambda x: isinstance(x, bool))\n",
    "\n",
    "    elif operator == OPERATORS.IS_DATETIME:\n",
    "        filtered = series.apply(lambda x: _datetime(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_DATE:\n",
    "        filtered = series.apply(lambda x: _date(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "    elif operator == OPERATORS.IS_ANY:\n",
    "        filtered = series.apply(lambda x: True)\n",
    "    elif operator == OPERATORS.IS_NA:\n",
    "        filtered = series.apply(lambda x: _na(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_NK:\n",
    "        filtered = series.apply(lambda x: _nk(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_YN:\n",
    "        filtered = series.apply(lambda x: _yn(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_YES:\n",
    "        filtered = series.apply(lambda x: _yn(x, errors='ERROR', yes=1)) == 1\n",
    "    elif operator == OPERATORS.IS_NO:\n",
    "        filtered = series.apply(lambda x: _yn(x, errors='ERROR', no=0)) == 0\n",
    "        \n",
    "    elif operator == OPERATORS.IS_UNIQUE:\n",
    "        filtered = series.duplicated(keep=False) == False\n",
    "    elif operator == OPERATORS.IS_FIRST:\n",
    "        filtered = series.duplicated(keep='first') == False\n",
    "    elif operator == OPERATORS.IS_LAST:\n",
    "        filtered = series.duplicated(keep='last') == False\n",
    "\n",
    "    else:\n",
    "        log(f'error: operator \"{operator}\" is not implemented', '_filter()', verbosity)\n",
    "        filtered = None\n",
    "\n",
    "\n",
    "    if negation == NEGATION.TRUE:\n",
    "        filtered = ~filtered\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def _update_index(values, values_new, connector):\n",
    "    if values is None:\n",
    "        values = values_new\n",
    "    elif connector == CONNECTORS.RESET:\n",
    "        values = values_new\n",
    "    elif connector in [CONNECTORS.AND, SCOPE.ALL]:\n",
    "        values &= values_new\n",
    "    elif connector in [CONNECTORS.OR, SCOPE.ANY]:\n",
    "        values |= values_new\n",
    "    return values\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('q')\n",
    "class DataFrameQuery:\n",
    "    \"\"\"\n",
    "    wip\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        _check_df(df)\n",
    "        self.df_og = df\n",
    "        self.mask = pd.DataFrame(True, index=df.index, columns=df.columns)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "    def __call__(self,\n",
    "            code='',  #code in string form for filtering and modifying data\n",
    "            inplace=False,  #make modifications inplace or just return a new dataframe.\n",
    "            verbosity=3,  #verbosity level for logging. 0: no logging, 1: errors, 2: warnings, 3: info, 4: debug\n",
    "            diff=None,  #[None, 'mix', 'old', 'new', 'new+']\n",
    "            diff_max_cols=200,  #maximum number of columns to display when using diff. None: show all\n",
    "            diff_max_rows=20,  #maximum number of rows to display when using diff. None: show all\n",
    "            ):\n",
    "        \n",
    "        #setup\n",
    "\n",
    "        self.code = code\n",
    "        self.inplace = inplace\n",
    "        self.verbosity = verbosity\n",
    "        self.diff = diff\n",
    "        self.diff_max_cols = diff_max_cols\n",
    "        self.diff_max_rows = diff_max_rows\n",
    "\n",
    "        if inplace is False:\n",
    "            self.df = None\n",
    "        else:\n",
    "            self.df = self.df_og \n",
    "            self.df.qp = self.df_og.qp \n",
    "\n",
    "        self.cols_filtered = pd.Index([True for col in self.df_og.columns])\n",
    "        self.rows_filtered = pd.Index([True for row in self.df_og.index])\n",
    "\n",
    "\n",
    "\n",
    "        #instructions\n",
    "\n",
    "        self.lines, self.instructions = tokenize(self.code, self.verbosity)\n",
    "\n",
    "        for instruction in self.instructions:\n",
    "            instruction.parse()\n",
    "            instruction.apply(self)\n",
    "\n",
    "   \n",
    "        #results\n",
    "        if self.df is None:\n",
    "            df = self.df_og\n",
    "        else:\n",
    "            df = self.df\n",
    "\n",
    "        self.df_filtered = df.loc[self.rows_filtered, self.cols_filtered]\n",
    "        self.df_filtered.qp = df.qp\n",
    "        self.df_filtered.qp.code = self.code\n",
    "    \n",
    "        if self.diff is None:\n",
    "            return self.df_filtered \n",
    "        else:\n",
    "            #show difference before and after filtering\n",
    "\n",
    "            if 'meta' in df.columns and 'meta' not in self.df_filtered.columns:\n",
    "                self.df_filtered.insert(0, 'meta', df.loc[self.rows_filtered, 'meta'])\n",
    "\n",
    "            result = _diff(\n",
    "                self.df_filtered, df, mode=self.diff,\n",
    "                max_cols=self.diff_max_cols, max_rows=self.diff_max_rows,\n",
    "                verbosity=self.verbosity)  \n",
    "            return  result  \n",
    "   \n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('qi')\n",
    "class DataFrameQueryInteractiveMode:\n",
    "    \"\"\"\n",
    "    Wrapper for df.q() for interactive use in Jupyter notebooks.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __call__(self):\n",
    "        kwargs = {'df': fixed(self.df)}\n",
    "\n",
    "        #code input\n",
    "        ui_code = widgets.Textarea(\n",
    "            value='',\n",
    "            placeholder='Enter query code here',\n",
    "            layout=Layout(height='95%')\n",
    "            )\n",
    "\n",
    "\n",
    "        #query builder\n",
    "\n",
    "        instruction = TYPES.SELECT_COLS.instruction()\n",
    "\n",
    "        i_type = widgets.Dropdown(\n",
    "            options=[(s.description, s.symbol) for s in TYPES],\n",
    "            value=instruction.type.symbol,\n",
    "            )\n",
    "        \n",
    "        i_scope = widgets.Dropdown(\n",
    "            disabled=True,\n",
    "            options=[''],\n",
    "            value='',\n",
    "            )\n",
    "\n",
    "        i_negate = widgets.ToggleButtons(\n",
    "            options=[('dont negate condition', ''), ('negate condition', '!')],\n",
    "            value='',\n",
    "            )\n",
    "\n",
    "        i_operator = widgets.Dropdown(\n",
    "            options=[(s.description, s.symbol) for s in instruction.operators],\n",
    "            value=instruction.operator.symbol,\n",
    "            )\n",
    "        \n",
    "        i_value = widgets.Text(\n",
    "            value='',\n",
    "            )\n",
    "        \n",
    "\n",
    "        i_text = widgets.Text(\n",
    "            value=f'\\n{i_type.value} {i_scope.value} {i_negate.value}{i_operator.value} {i_value.value}',\n",
    "            disabled=True,\n",
    "            )\n",
    "        \n",
    "\n",
    "        def update_options(*args):\n",
    "            instruction = TYPES[i_type.value].instruction()\n",
    "\n",
    "            if hasattr(instruction, 'scopes'):\n",
    "                i_scope.disabled = False\n",
    "                i_scope.options = [(s.description, s.symbol) for s in instruction.scopes]\n",
    "            else:\n",
    "                i_scope.disabled = True\n",
    "                i_scope.options = ['']\n",
    "\n",
    "            if hasattr(instruction, 'negations'):\n",
    "                i_negate.disabled = False\n",
    "                i_negate.options = [('dont negate condition', ''), ('negate condition', '!')]\n",
    "            else:\n",
    "                i_negate.disabled = True\n",
    "                i_negate.options = ['', '']\n",
    "\n",
    "            i_operator.options = [(s.description, s.symbol) for s in instruction.operators]\n",
    "            i_operator.value = instruction.operator.symbol\n",
    "\n",
    "        def update_text(*args):\n",
    "            i_text.value = f'{i_type.value} {i_scope.value} {i_negate.value}{i_operator.value} {i_value.value}'\n",
    "\n",
    "        i_type.observe(update_options, 'value')\n",
    "        i_type.observe(update_text, 'value')\n",
    "        i_scope.observe(update_text, 'value')\n",
    "        i_negate.observe(update_text, 'value')\n",
    "        i_operator.observe(update_text, 'value')\n",
    "        i_value.observe(update_text, 'value')\n",
    "\n",
    "        \n",
    "        ui_add_instruction = widgets.Button(\n",
    "            button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='adds the selected instruction to the query code',\n",
    "            icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    "            )\n",
    "\n",
    "        def add_instruction(ui_code, i_text):\n",
    "            if i_text.value.startswith('´c'):\n",
    "                ui_code.value += f'\\n{i_text.value}'\n",
    "            else:\n",
    "                ui_code.value += f'   {i_text.value}'\n",
    "\n",
    "        ui_add_instruction.on_click(lambda b: add_instruction(ui_code, i_text))\n",
    "\n",
    "        kwargs['code'] = ui_code\n",
    "\n",
    "\n",
    "        ui_diff = widgets.ToggleButtons(\n",
    "            options=[None, 'mix', 'old', 'new', 'new+'],\n",
    "            description='show differences mode:',\n",
    "            tooltips=[\n",
    "                'dont show differences, just show the new (filtered) dataframe.',\n",
    "                'show new (filtered) dataframe plus all the removed (filtered) values from the old dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show old (unfiltered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe but also adds metadata columns with the prefix \"#\". If a value changed, the metadata column contains the old value. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['diff'] = ui_diff\n",
    "\n",
    "        ui_verbosity = widgets.ToggleButtons(\n",
    "            options=[0, 1, 2, 3, 4, 5],\n",
    "            value=3,\n",
    "            description='verbosity level:',\n",
    "            tooltips=[\n",
    "                'no logging',\n",
    "                'only errors',\n",
    "                'errors and warnings',\n",
    "                'errors, warnings and info',\n",
    "                'errors, warnings, info and debug',\n",
    "                'errors, warnings, info, debug and trace',\n",
    "                ],\n",
    "            )\n",
    "        \n",
    "        kwargs['verbosity'] = ui_verbosity\n",
    "\n",
    "        ui_inplace = widgets.ToggleButtons(\n",
    "            options=[True, False],\n",
    "            value=False,\n",
    "            description='make modifications inplace:',\n",
    "            tooltips=[\n",
    "                'make modifications inplace, e.g. change the original dataframe.',\n",
    "                'return a new dataframe with the modifications. lower performance.',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['inplace'] = ui_inplace\n",
    "\n",
    "\n",
    "        ui_settings = VBox([\n",
    "            ui_diff,\n",
    "            ui_verbosity,\n",
    "            ui_inplace,\n",
    "            ])\n",
    "        \n",
    "        \n",
    "        #some general info and statistics about the df\n",
    "        ui_details = widgets.HTML(\n",
    "            value=f\"\"\"\n",
    "            <b>shape:</b> {self.df.shape}<br>\n",
    "            <b>memory usage:</b> {self.df.memory_usage().sum()} bytes<br>\n",
    "            <b>unique values:</b> {self.df.nunique().sum()}<br>\n",
    "            <b>missing values:</b> {self.df.isna().sum().sum()}<br>\n",
    "            <b>columns:</b><br> {'<br>'.join([f'{col} ({dtype})' for col, dtype in list(zip(self.df.columns, self.df.dtypes))])}<br>\n",
    "            \"\"\"\n",
    "            )\n",
    "        \n",
    "\n",
    "        ui_info = widgets.Tab(\n",
    "            children=[\n",
    "                ui_settings,\n",
    "                ui_details,\n",
    "                widgets.HTML(value=DataFrameQuery.__doc__),\n",
    "                ],\n",
    "            titles=['settings', 'details', 'readme'],\n",
    "            layout=Layout(width='30%', height='95%')\n",
    "            )\n",
    "        \n",
    "\n",
    "        ui_input = VBox([\n",
    "            widgets.HTML(value='<b>query builder:</b>'),\n",
    "            i_text,\n",
    "            i_type,\n",
    "            i_scope,\n",
    "            i_negate,\n",
    "            i_operator,\n",
    "            i_value,\n",
    "            ui_add_instruction,\n",
    "            ])\n",
    "        \n",
    "        # ui_input = HBox([ui_code, ui_instruction_builder], layout=Layout(width='50%', height='100%'))\n",
    "        ui = HBox([ui_code, ui_input, ui_info], layout=Layout(width='100%', height='300px'))\n",
    "\n",
    "        display(ui)\n",
    "        out = HBox([interactive_output(_interactive_mode, kwargs)], layout=Layout(overflow_y='auto'))\n",
    "        display(out)\n",
    "\n",
    "\n",
    "def _interactive_mode(**kwargs):\n",
    "\n",
    "    df = kwargs.pop('df')\n",
    "\n",
    "    result = df.q(\n",
    "        code=kwargs['code'],\n",
    "        inplace=kwargs['inplace'],\n",
    "        diff=kwargs['diff'],\n",
    "        verbosity=kwargs['verbosity'],\n",
    "        # max_cols=kwargs['max_cols'],\n",
    "        # max_rows=kwargs['max_rows'],\n",
    "        )\n",
    "    \n",
    "    display(result)\n",
    "    return result \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if 'cards' not in globals():\n",
    "#     cards = pd.read_csv('data/cards.csv')\n",
    "# cards.q('toughness ´r >2 & <5')\n",
    "# cards.qi()\n",
    "\n",
    "\n",
    "# df = qp.get_df()\n",
    "# df.q(\n",
    "#     r\"\"\"\n",
    "#     # id ´r ?1  ´n test\n",
    "#     # name ´m ~ x.upper()\n",
    "#     # is any ´r is any\n",
    "\n",
    "#     date of birth / age\n",
    "\n",
    "#     \"\"\",\n",
    "#     diff=None,\n",
    "#     inplace=False,\n",
    "#     verbosity=4,\n",
    "#     )\n",
    "\n",
    "df = qp.get_df()\n",
    "df.qi()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [0,1,2],\n",
    "    'b': [-1, 0, 1],\n",
    "    'c': [0.1, 0.2, 0.3],\n",
    "    })\n",
    "\n",
    "m0 = pd.DataFrame(True, index=df.index, columns=df.columns)\n",
    "\n",
    "m1 = df > 0\n",
    "m2 = df['b'] < 0 \n",
    "m3 = df[1:] > 0\n",
    "\n",
    "# df[m1]\n",
    "# df[m1].dropna(how='all')\n",
    "\n",
    "m1 | m2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cards = pd.read_csv('data/cards.csv').fillna('')\n",
    "c = cards.q('power / toughness ´v to num  ´c is any  ´r is any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.DataFrame(True, index=c.index, columns=c.columns)\n",
    "\n",
    "\n",
    "m1 = c['power'] > 10\n",
    "m2 = c['toughness'] > 10\n",
    "m3 = m1 | m2\n",
    "\n",
    "\n",
    "c1 = c[m1 | m2]\n",
    "\n",
    "\n",
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "mask = pd.DataFrame(True, index=c.index, columns=c.columns)\n",
    "mask['power'] = c['power'] > 10\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qp.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.pd_util import _format_df, get_dfs\n",
    "from qplib.util import log, GREEN, RED, ORANGE, GREEN_LIGHT, RED_LIGHT, ORANGE_LIGHT\n",
    "from qplib.types import _date, _na, qpDict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_new, df_old = get_dfs()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import qplib as qp\n",
    "from qplib import log\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "df_new, df_old = get_dfs()\n",
    "\n",
    "print('df_new:')\n",
    "display(df_new)\n",
    "\n",
    "print('df_old:')\n",
    "display(df_old)\n",
    "\n",
    "print('mode=new:')\n",
    "display(qp.diff(df_new, df_old, mode='new'))\n",
    "\n",
    "print('mode=new+:')\n",
    "display(qp.diff(df_new, df_old, mode='new+'))\n",
    "\n",
    "print('mode=old:')\n",
    "display(qp.diff(df_new, df_old, mode='old'))\n",
    "\n",
    "print('mode=mix:')\n",
    "display(qp.diff(df_new, df_old, mode='mix'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# excel_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.pd_util import _format_df, get_dfs\n",
    "from qplib.util import log, GREEN, RED, ORANGE, GREEN_LIGHT, RED_LIGHT, ORANGE_LIGHT\n",
    "from qplib.types import _date, _na, qpDict\n",
    "\n",
    "\n",
    "\n",
    "def _show_differences(\n",
    "    df_new, df_old, mode='mix',\n",
    "    summary='print',  #print, return, None\n",
    "    max_cols=200, max_rows=20,\n",
    "    newline='<br>', prefix_new='', prefix_old='old: ',\n",
    "    verbosity=3,):\n",
    "    '''\n",
    "    shows differences between dataframes\n",
    "    '''\n",
    "\n",
    "    if not df_new.index.is_unique:\n",
    "        log('error: index of new dataframe is not unique', 'qp.diff()', verbosity)\n",
    "    if not df_old.index.is_unique:\n",
    "        log('error: index of old dataframe is not unique', 'qp.diff()', verbosity)\n",
    "\n",
    "\n",
    "\n",
    "    #prepare dataframes\n",
    "    df_new = _format_df(df_new, fix_headers=False, add_metadata=True, verbosity=verbosity)\n",
    "    df_old = _format_df(df_old, fix_headers=False, add_metadata=True, verbosity=verbosity)\n",
    "\n",
    "\n",
    "\n",
    "    cols_added = df_new.columns.difference(df_old.columns)\n",
    "    cols_removed = df_old.columns.difference(df_new.columns)\n",
    "    cols_shared = df_new.columns.intersection(df_old.columns)\n",
    "\n",
    "    rows_added = df_new.index.difference(df_old.index)\n",
    "    rows_removed = df_old.index.difference(df_new.index)\n",
    "    rows_shared = df_new.index.intersection(df_old.index)\n",
    "\n",
    "    changes_all = {\n",
    "        'cols added': len(cols_added),\n",
    "        'cols removed': len(cols_removed),\n",
    "        'rows added': len(rows_added),\n",
    "        'rows removed': len(rows_removed),\n",
    "        'vals added': 0,\n",
    "        'vals removed': 0,\n",
    "        'vals changed': 0\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    #create dfs showing the highlighted changes dependant on \"show\" settings\n",
    "    if mode in ['new', 'new+']:\n",
    "        df_diff = copy.deepcopy(df_new)\n",
    "        df_diff_style = pd.DataFrame('', index=df_diff.index, columns=df_diff.columns)\n",
    "\n",
    "        #add metadata columns\n",
    "        if mode == 'new+':\n",
    "            cols_new = ['meta']\n",
    "            cols_add = []\n",
    "            for col in df_diff.columns:\n",
    "                if not col.startswith(prefix_old) and col != 'meta':\n",
    "                    cols_new.append(col)\n",
    "                    cols_new.append(prefix_old + col)\n",
    "\n",
    "                    if prefix_old + col not in df_diff.columns:\n",
    "                        cols_add.append(prefix_old + col)\n",
    "\n",
    "            df_diff = pd.concat([df_diff, pd.DataFrame('', index=df_diff.index, columns=cols_add)], axis=1)\n",
    "            df_diff_style = pd.concat([df_diff_style, pd.DataFrame('font-style: italic', index=df_diff.index, columns=cols_add)], axis=1)\n",
    "        \n",
    "            df_diff = df_diff[cols_new]\n",
    "            df_diff_style = df_diff_style[cols_new]\n",
    "\n",
    "\n",
    "        df_diff_style.loc[:, cols_added] = f'background-color: {GREEN}'\n",
    "        df_diff_style.loc[rows_added, :] = f'background-color: {GREEN}'\n",
    "\n",
    "        df_diff.loc[rows_added, 'meta'] += 'added row'\n",
    "\n",
    "\n",
    "\n",
    "    elif mode == 'old':\n",
    "        df_diff = copy.deepcopy(df_old)\n",
    "        df_diff_style = pd.DataFrame('', index=df_diff.index, columns=df_diff.columns)\n",
    "        \n",
    "        df_diff_style.loc[:, cols_removed] = f'background-color: {RED}'\n",
    "        df_diff_style.loc[rows_removed, :] = f'background-color: {RED}'\n",
    "\n",
    "        df_diff.loc[rows_removed, 'meta'] += 'removed row'\n",
    "\n",
    "    elif mode == 'mix':\n",
    "        inds_old = df_old.index.difference(df_new.index)\n",
    "        cols_old = df_old.columns.difference(df_new.columns)\n",
    "\n",
    "        df_diff = pd.concat([df_new, df_old.loc[:, cols_old]], axis=1)\n",
    "        df_diff.loc[inds_old, :] = df_old.loc[inds_old, :]\n",
    "\n",
    "        df_diff_style = pd.DataFrame('', index=df_diff.index, columns=df_diff.columns)\n",
    "\n",
    "        df_diff_style.loc[:, cols_added] = f'background-color: {GREEN}'\n",
    "        df_diff_style.loc[:, cols_removed] = f'background-color: {RED}'\n",
    "        df_diff_style.loc[rows_added, :] = f'background-color: {GREEN}'\n",
    "        df_diff_style.loc[rows_removed, :] = f'background-color: {RED}'\n",
    "\n",
    "        df_diff.loc[rows_added, 'meta'] += 'added row'\n",
    "        df_diff.loc[rows_removed, 'meta'] += 'removed row'\n",
    "\n",
    "    else:\n",
    "        log(f'error: unknown mode: {mode}', 'qp.diff()', verbosity)\n",
    "\n",
    "\n",
    "    #highlight values in shared columns\n",
    "    #column 0 contains metadata and is skipped\n",
    "    cols_shared_no_metadata = [col for col in cols_shared if not col.startswith(prefix_old) and col != 'meta']\n",
    "\n",
    "    df_new_isna = df_new.loc[rows_shared, cols_shared_no_metadata].isna()\n",
    "    df_old_isna = df_old.loc[rows_shared, cols_shared_no_metadata].isna()\n",
    "    df_new_equals_old = df_new.loc[rows_shared, cols_shared_no_metadata] == df_old.loc[rows_shared, cols_shared_no_metadata]\n",
    "\n",
    "    df_added = df_old_isna & ~df_new_isna\n",
    "    df_removed = df_new_isna & ~df_old_isna\n",
    "    df_changed = ~df_new_isna & ~df_old_isna & ~df_new_equals_old\n",
    "\n",
    "    df_diff_style.loc[rows_shared, cols_shared_no_metadata] += df_added.mask(df_added, f'background-color: {GREEN_LIGHT}').where(df_added, '')\n",
    "    df_diff_style.loc[rows_shared, cols_shared_no_metadata] += df_removed.mask(df_removed, f'background-color: {RED_LIGHT}').where(df_removed, '')\n",
    "    df_diff_style.loc[rows_shared, cols_shared_no_metadata] += df_changed.mask(df_changed, f'background-color: {ORANGE_LIGHT}').where(df_changed, '')\n",
    "\n",
    "\n",
    "\n",
    "    df_added_sum = df_added.sum(axis=1)\n",
    "    df_removed_sum = df_removed.sum(axis=1)\n",
    "    df_changed_sum = df_changed.sum(axis=1)\n",
    "\n",
    "    changes_all['vals added'] += int(df_added_sum.sum())\n",
    "    changes_all['vals removed'] += int(df_removed_sum.sum())\n",
    "    changes_all['vals changed'] += int(df_changed_sum.sum())\n",
    "\n",
    "    df_diff.loc[rows_shared, 'meta'] += df_added_sum.apply(lambda x: f'{newline}vals added: {x}' if x > 0 else '')\n",
    "    df_diff.loc[rows_shared, 'meta'] += df_removed_sum.apply(lambda x: f'{newline}vals removed: {x}' if x > 0 else '')\n",
    "    df_diff.loc[rows_shared, 'meta'] += df_changed_sum.apply(lambda x: f'{newline}vals changed: {x}' if x > 0 else '')\n",
    "\n",
    "\n",
    "    if mode == 'new+':\n",
    "        cols_shared_metadata = [prefix_old + col for col in cols_shared_no_metadata]\n",
    "        df_all_modifications = (df_added | df_removed | df_changed)\n",
    "        df_old_changed = df_old.loc[rows_shared, cols_shared_no_metadata].where(df_all_modifications, '')\n",
    "        df_diff.loc[rows_shared, cols_shared_metadata] = df_old_changed.values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if max_cols is not None and max_cols < len(df_diff.columns):\n",
    "        log(f'warning: showing {max_cols} out of {len(df_diff.columns)} columns', 'qp.diff()', verbosity)\n",
    "    if max_rows is not None and max_rows < len(df_diff.index):\n",
    "        log(f'warning: showing {max_rows} out of {len(df_diff.index)} rows', 'qp.diff()', verbosity)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    df_diff = df_diff.iloc[:max_rows, :max_cols]\n",
    "    df_diff_style = df_diff_style.iloc[:max_rows, :max_cols]\n",
    "\n",
    "    #replace \"<\" and \">\" with html entities to prevent them from being interpreted as html tags\n",
    "    cols_no_metadata = [col for col in df_diff.columns if not col.startswith(prefix_old) and col != 'meta']\n",
    "    if pd.__version__ >= '2.1.0':\n",
    "        df_diff.loc[:, cols_no_metadata] = df_diff.loc[:, cols_no_metadata].map(lambda x: _try_replace_gt_lt(x))\n",
    "    else:\n",
    "        df_diff.loc[:, cols_no_metadata] = df_diff.loc[:, cols_no_metadata].applymap(lambda x: _try_replace_gt_lt(x))\n",
    "\n",
    "\n",
    "    result = df_diff.style.apply(lambda x: _apply_style(x, df_diff_style), axis=None)\n",
    "    changes_truncated = {key: val for key,val in changes_all.items() if val > 0}\n",
    "\n",
    "    if summary == 'print':\n",
    "        display(changes_truncated)\n",
    "        return result\n",
    "    elif summary == 'return':\n",
    "        return result, changes_truncated\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def _try_replace_gt_lt(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.replace('<', '&lt;').replace('>', '&gt;')\n",
    "    elif isinstance(x, type):\n",
    "        return str(x).replace('<', '&lt;').replace('>', '&gt;')\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def _apply_style(x, df_style):\n",
    "    return df_style\n",
    "\n",
    "\n",
    "def excel_diff(file_new='new', file_old='old', file_diff='diff',\n",
    "    index_col=0, mode='new+',\n",
    "    max_cols=None, max_rows=None, verbosity=3):\n",
    "    '''\n",
    "    shows differences between two excel files.\n",
    "\n",
    "    specs and requs:\n",
    "    - only sheets with the same name are compared\n",
    "    - needs a unique column to use as index, or sequential order of records\n",
    "    - index must be unique\n",
    "    - index must correspond to the same \"item\" in both sheets\n",
    "\n",
    "    if index_col=None:\n",
    "    - uses sequential numbers as index instead of any given column\n",
    "    - uniqueness is guaranteed\n",
    "    - only works if the all sheets have the same \"items\" in the same rows\n",
    "    '''\n",
    "\n",
    "    summary = pd.DataFrame(columns=[\n",
    "        'sheet',\n",
    "        f'is in new file',\n",
    "        f'is in old file',\n",
    "        f'index (first col) is unique in new file',\n",
    "        f'index (first col) is unique in old file',\n",
    "        'cols added',\n",
    "        'cols removed',\n",
    "        'rows added',\n",
    "        'rows removed',\n",
    "        'vals added',\n",
    "        'vals removed',\n",
    "        'vals changed',\n",
    "        ])\n",
    "    results = {}\n",
    "    \n",
    "\n",
    "    #get names of all sheets in the excel files\n",
    "    sheets_new = pd.ExcelFile(file_new).sheet_names\n",
    "    sheets_old = pd.ExcelFile(file_old).sheet_names\n",
    "    \n",
    "    #iterate over all sheets\n",
    "    for sheet in sheets_new:\n",
    "        if sheet in sheets_old:\n",
    "            if index_col is None:\n",
    "                df_new = pd.read_excel(file_new, sheet_name=sheet)\n",
    "                df_old = pd.read_excel(file_old, sheet_name=sheet)\n",
    "            else:\n",
    "                df_new = pd.read_excel(file_new, sheet_name=sheet, index_col=index_col)\n",
    "                df_old = pd.read_excel(file_old, sheet_name=sheet, index_col=index_col)\n",
    "\n",
    "            result, changes = _show_differences(\n",
    "                df_new, df_old, mode=mode, summary='return',\n",
    "                max_cols=max_cols, max_rows=max_rows, verbosity=verbosity\n",
    "                )\n",
    "            \n",
    "            results[sheet] = result\n",
    "        \n",
    "\n",
    "            idx = len(summary)\n",
    "            summary.loc[idx, 'sheet'] = sheet\n",
    "            summary.loc[idx, f'is in new file'] = True\n",
    "            summary.loc[idx, f'is in old file'] = True\n",
    "            summary.loc[idx, f'index (first col) is unique in new file'] = df_new.index.is_unique\n",
    "            summary.loc[idx, f'index (first col) is unique in old file'] = df_old.index.is_unique\n",
    "            for key, val in changes.items():\n",
    "                summary.loc[idx, key] = val\n",
    "            \n",
    "        else:\n",
    "            idx = len(summary)\n",
    "            summary.loc[idx, 'sheet'] = sheet\n",
    "            summary.loc[idx, f'is in new file'] = True\n",
    "            summary.loc[idx, f'is in old file'] = False\n",
    "            summary.loc[idx, f'index (first col) is unique in new file'] = df_new.index.is_unique\n",
    "\n",
    "    if file_diff:\n",
    "        if not file_diff.endswith('.xlsx'):\n",
    "            file_diff += '.xlsx'\n",
    "        \n",
    "        with pd.ExcelWriter(file_diff) as writer:\n",
    "            summary.to_excel(writer, sheet_name='summary', index=False)\n",
    "            if index_col:\n",
    "                index = True\n",
    "            else:\n",
    "                index = False\n",
    "\n",
    "            for sheet, result in results.items():\n",
    "                result.data['meta'] = result.data['meta'].str.replace('<br>', '\\n')\n",
    "                result.to_excel(writer, sheet_name=sheet, index=index)\n",
    "\n",
    "        log(f'info: differences saved to \"{file_diff}\"', 'qp.excel_diff()', verbosity)\n",
    "        \n",
    "    return summary, results\n",
    "\n",
    "\n",
    "\n",
    "# file_new = 'archive/stats_new.xlsx'\n",
    "# file_old = 'archive/stats_old.xlsx'\n",
    "\n",
    "# summary, results = excel_diff('archive/stats_new.xlsx', 'archive/stats_old.xlsx', to_excel=True)\n",
    "\n",
    "# new, old = qp.get_dfs()\n",
    "# display(new, old)\n",
    "# _show_differences(new, old, mode='new+')\n",
    "\n",
    "new = 'archive/NET_BM Study_01_export_2024-04-11.xlsx'\n",
    "old = 'archive/NET_BM Study_01_export_2024-03-15.xlsx'\n",
    "\n",
    "a,b = excel_diff(new, old, file_diff='archive/export_diff.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.types import _date, _na\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ID': [10001, 10002, 10003, 20001, 20002, 20003, 30001, 30002, 30003, 30004, 30005],\n",
    "    'name': ['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Brown', 'eva white', 'Frank miller', 'Grace TAYLOR', 'Harry Clark', 'IVY GREEN', 'JAck Williams', 'john Doe'],\n",
    "    'date of birth': ['1995-01-02', '1990/09/14', '1985.08.23', '19800406', '05-11-2007', '06-30-1983', '28-05-1975', '1960Mar08', '1955-Jan-09', '1950 Sep 10', '1945 October 11'],\n",
    "    'age': [-25, '30', np.nan, None, '40.0', 'forty-five', 'nan', 'unk', '', 'unknown', 35],\n",
    "    'gender': ['M', 'F', 'Female', 'Male', 'Other', 'm', 'ff', 'NaN', None, 'Mal', 'female'],\n",
    "    'height': [170, '175.5cm', None, '280', 'NaN', '185', '1', '6ft 1in', -10, '', 200],\n",
    "    'weight': [70.2, '68', '72.5lb', 'na', '', '75kg', None, '80.3', '130lbs', '82', -65],\n",
    "    'bp systole': ['20', 130, 'NaN', '140', '135mmhg', '125', 'NAN', '122', '', 130, '45'],\n",
    "    'bp diastole': [80, '85', 'nan', '90mmHg', np.nan, '75', 'NaN', None, '95', '0', 'NaN'],\n",
    "    'cholesterol': ['Normal', 'Highe', 'NaN', 'GOOD', 'n.a.', 'High', 'Normal', 'n/a', 'high', '', 'Normal'],\n",
    "    'diabetes': ['No', 'yes', 'N/A', 'No', 'Y', 'Yes', 'NO', None, 'NaN', 'n', 'Yes'],\n",
    "    'dose': ['10kg', 'NaN', '15 mg once a day', '20mg', '20 Mg', '25g', 'NaN', None, '30 MG', '35', '40ml']\n",
    "    })\n",
    "\n",
    "df_new, df_old = qp.get_dfs()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"bashlike\" wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#run tests in folder \"tests\" using pytest and create a test report\n",
    "!pytest tests --html=tests/test_report.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test_sort() missing 2 required positional arguments: 'instructions' and 'expected'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 89\u001b[0m\n\u001b[0;32m     83\u001b[0m     expected_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39mexpected)\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result\u001b[38;5;241m.\u001b[39mequals(expected_df), qp\u001b[38;5;241m.\u001b[39mdiff(result, expected_df, returns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 89\u001b[0m \u001b[43mtest_sort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: test_sort() missing 2 required positional arguments: 'instructions' and 'expected'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import pytest\n",
    "import qplib as qp\n",
    "from qplib import log\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "def get_df_simple():\n",
    "    df = pd.DataFrame({\n",
    "        'a': [-1, 0, 1],\n",
    "        'b': [1, 2, 3]\n",
    "        })\n",
    "    return df\n",
    "\n",
    "def get_df_simple_tagged():\n",
    "    df = pd.DataFrame({\n",
    "        'meta': ['', '', ''],\n",
    "        'a': [-1, 0, 1],\n",
    "        'b': [1, 2, 3]\n",
    "        })\n",
    "    df.index = [0, 1, 2]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_df():\n",
    "    df = pd.DataFrame({\n",
    "        'ID': [10001, 10002, 10003, 20001, 20002, 20003, 30001, 30002, 30003, 30004, 30005],\n",
    "        'name': ['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Brown', 'eva white', 'Frank miller', 'Grace TAYLOR', 'Harry Clark', 'IVY GREEN', 'JAck Williams', 'john Doe'],\n",
    "        'date of birth': ['1995-01-02', '1990/09/14', '1985.08.23', '19800406', '05-11-2007', '06-30-1983', '28-05-1975', '1960Mar08', '1955-Jan-09', '1950 Sep 10', '1945 October 11'],\n",
    "        'age': [-25, '30', np.nan, None, '40.0', 'forty-five', 'nan', 'unk', '', 'unknown', 35],\n",
    "        'gender': ['M', 'F', 'Female', 'Male', 'Other', 'm', 'ff', 'NaN', None, 'Mal', 'female'],\n",
    "        'height': [170, '175.5cm', None, '280', 'NaN', '185', '1', '6ft 1in', -10, '', 200],\n",
    "        'weight': [70.2, '68', '72.5lb', 'na', '', '75kg', None, '80.3', '130lbs', '82', -65],\n",
    "        'bp systole': ['20', 130, 'NaN', '140', '135mmhg', '125', 'NAN', '122', '', 130, '45'],\n",
    "        'bp diastole': [80, '85', 'nan', '90mmHg', np.nan, '75', 'NaN', None, '95', '0', 'NaN'],\n",
    "        'cholesterol': ['Normal', 'Highe', 'NaN', 'GOOD', 'n.a.', 'High', 'Normal', 'n/a', 'high', '', 'Normal'],\n",
    "        'diabetes': ['No', 'yes', 'N/A', 'No', 'Y', 'Yes', 'NO', None, 'NaN', 'n', 'Yes'],\n",
    "        'dose': ['10kg', 'NaN', '15 mg once a day', '20mg', '20 Mg', '25g', 'NaN', None, '30 MG', '35', '40ml']\n",
    "        })\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_df_tagged():\n",
    "    df1 = get_df()\n",
    "    df2 = pd.DataFrame('', index=df1.index, columns=['meta', *df1.columns])\n",
    "    df2.iloc[:, 1:] = df1.loc[:, :]\n",
    "    return df2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_sort():\n",
    "    df = qp.get_df()\n",
    "    df1 = qp.get_df()\n",
    "    result = df.q(\n",
    "        r\"\"\"\n",
    "        id ´v sort  ´c is any\n",
    "        \"\"\")\n",
    "    expected = df1.sort_values(by='ID')\n",
    "    assert result.equals(expected), qp.diff(result, expected, returns='str+')\n",
    "\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"instructions, expected\", [\n",
    "    (\n",
    "        r\"\"\"\n",
    "        id ´v sort  ´c is any\n",
    "        \"\"\",\n",
    "        'ID'\n",
    "    )\n",
    "    ])\n",
    "def test_sort(instructions, expected):\n",
    "    df = qp.get_df()\n",
    "    result = df.q(instructions)\n",
    "    expected_df = df.sort_values(by=expected)\n",
    "    assert result.equals(expected_df), qp.diff(result, expected_df, returns='str+')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "test_sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431a4e8e7e454d57b6404402a2d2fe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Tab(children=(Textarea(value='´s verbosity=3\\n´s diff=None\\n\\n', layout=Layout(height='97%', wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fa52aae7f94ccc9dd58a9ac11b7d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import qplib as qp\n",
    "from qplib import log\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# df1 = qp.get_df()\n",
    "# df2 = pd.DataFrame({\n",
    "#         'ID': [10001, 10002, 10003, 20001, 20002, 20003, 30001, 30002, 30003, 30004, 30005],\n",
    "#         'name': ['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Brown', 'eva white', 'Frank miller', 'Grace TAYLOR', 'Harry Clark', 'IVY GREEN', 'JAck Williams', 'john Doe'],\n",
    "#         'date of birth': ['1995-01-02', '1990/09/14', '1985.08.23', '19800406', '05-11-2007', '06-30-1983', '28-05-1975', '1960Mar08', '1955-Jan-09', '1950 Sep 10', '1945 October 11'],\n",
    "#         'age': [-25, '30', np.nan, None, '40.0', 'forty-five', 'nan', 'unk', '', 'unknown', 35],\n",
    "#         'gender': ['M', 'F', 'Female', 'Male', 'Other', 'm', 'ff', 'NaN', None, 'Mal', 'female'],\n",
    "#         'height': [170, '175.5cm', None, '280', 'NaN', '185', '1', '6ft 1in', -10, '', 200],\n",
    "#         'weight': [70.2, '68', '72.5lb', 'na', '', '75kg', None, '80.3', '130lbs', '82', -65],\n",
    "#         'bp systle': ['20', 130, 'NaN', '140', '135mmhg', '125', 'NAN', '122', '', 130, '45'],\n",
    "#         'bp diastole': [80, '85', 'nan', '90mmHg', np.nan, '75', 'NaN', None, '95', '0', 'NaN'],\n",
    "#         'cholesterol': ['Normal', 'Highe', 'NaN', 'GOOD', 'n.a.', 'High', 'Normal', 'n/a', 'high', '', 'Normal'],\n",
    "#         'diabetes': ['No', 'yes', 'N/A', 'No', 'Y', 'Yes', 'NO', None, 'NaN', 'n', 'Yes'],\n",
    "#         'dose': ['10kg', 'NaN', '15 mg once a day', '20mg', '20 Mg', '25g', 'NaN', None, '30 MG', '35', '40ml']\n",
    "#         })\n",
    "\n",
    "# qp.diff(df1, df2, returns='df')\n",
    "\n",
    "# df1.q()\n",
    "\n",
    "df = qp.get_df()\n",
    "\n",
    "df.qi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_25584\\4120505943.py:13: DtypeWarning: Columns (2,3,7,12,16,20,23,47,52,53,61,62,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cards = pd.read_csv('data/cards.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import qplib as qp\n",
    "from qplib import log\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "cards = pd.read_csv('data/cards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfcc77633e64c0da8c88fadd555b444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Tab(children=(Textarea(value='´s verbosity=3\\n´s diff=None\\n\\n', layout=Layout(height='97%', wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3beeb2db787c4ed096bf1a033009f456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cards.qi()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
