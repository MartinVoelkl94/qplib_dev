{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import pickle\n",
    "import qplib as qp\n",
    "from qplib import log, na, nk, num\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import qplib as qp\n",
    "from qplib import log\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "log('trace: this is a trace message')\n",
    "log('debug: this is a debug message')\n",
    "log('info: this is an info message')\n",
    "log('warning: this is a warning message')\n",
    "log('error: this is an error message')\n",
    "\n",
    "log(str(a))\n",
    "log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd_query  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interactive_output, HBox, VBox, fixed, Layout, interact_manual\n",
    "\n",
    "from qplib.util import log\n",
    "from qplib.types import _int, _float, _num, _bool, _datetime, _date, _na, _nk, _yn, qpDict\n",
    "from qplib.pd_util import _check_df, _diff, _format_df, indexQpExtension, seriesQpExtension, dfQpExtension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if 'cards' not in globals():\n",
    "#     cards = pd.read_csv('data/cards.csv')\n",
    "# cards.q('toughness ´r >2 & <5')\n",
    "# cards.qi()\n",
    "\n",
    "\n",
    "# df = qp.get_df()\n",
    "# df.q(\n",
    "#     r\"\"\"\n",
    "#     # id ´r ?1  ´n test\n",
    "#     # name ´m ~ x.upper()\n",
    "#     # is any ´r is any\n",
    "\n",
    "#     date of birth / age\n",
    "\n",
    "#     \"\"\",\n",
    "#     diff=None,\n",
    "#     inplace=False,\n",
    "#     verbosity=4,\n",
    "#     )\n",
    "\n",
    "df = qp.get_df()\n",
    "df.qi()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "name\n",
    "    ´v ~ x.title()\n",
    "    ´r ?j  ´n contains \"j\"  ´h notes\n",
    "\n",
    "is any ´r is any\n",
    "\"\"\"\n",
    "\n",
    "df['name'] = df['name'].str.title()\n",
    "mask = df['name'].str.lower().str.contains('j')\n",
    "df['notes'] = ''\n",
    "df.loc[mask, 'notes'] = 'contains \"j\"'\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, interactive_output, HBox, VBox, fixed, Layout, interact_manual\n",
    "\n",
    "from qplib.util import log\n",
    "from qplib.types import _int, _float, _num, _bool, _datetime, _date, _na, _nk, _yn, qpDict\n",
    "from qplib.pd_util import _check_df, _diff, _format_df, indexQpExtension, seriesQpExtension, dfQpExtension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Symbol:\n",
    "    def __init__(self, symbol, name, description, unary=None, binary=None, **kwargs):\n",
    "        self.symbol = symbol\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.unary = unary\n",
    "        self.binary = binary\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name} (symbol: \"{self.symbol}\" description: \"{self.description})\"'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.name} (symbol: \"{self.symbol}\" description: \"{self.description})\"'\n",
    "\n",
    "class Symbols:\n",
    "    def __init__(self, name, *symbols):\n",
    "        self.name = name\n",
    "        self.by_name = {symbol.name: symbol for symbol in symbols}\n",
    "        self.by_symbol = {symbol.symbol: symbol for symbol in symbols}\n",
    "        for symbol in symbols:\n",
    "            setattr(self, symbol.name, symbol)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key in self.by_symbol:\n",
    "            return self.by_symbol[key]\n",
    "        elif key in self.by_name:\n",
    "            return self.by_name[key]\n",
    "        else:\n",
    "            log(f'error: symbol \"{key}\" not found in \"{self.name}\"', 'Symbols.__getitem__', 3)\n",
    "            return None\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.by_name.values())\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name}:\\n' + '\\n\\t'.join([str(val) for key,val in self.by_name.items()])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.name}:\\n' + '\\n\\t'.join([str(val) for key,val in self.by_name.items()])\n",
    "\n",
    "\n",
    "class ChangeSettings:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.CHANGE_SETTINGS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.operator = OPERATORS.SET_VERBOSITY\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.operators = [OPERATORS.SET_VERBOSITY, OPERATORS.SET_DIFF, OPERATORS.SET_INPLACE]\n",
    "        self.verbosity = verbosity\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'CHANGE_SETTINGS:\\n\\tconnector: {self.connector}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self, verbosity=None):\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "        \n",
    "    def apply(self, query_obj):\n",
    "        operator = self.operator\n",
    "        value = self.value\n",
    "\n",
    "        if operator == OPERATORS.SET_VERBOSITY:\n",
    "            if value in ['0', '1', '2', '3', '4', '5']:\n",
    "                query_obj.verbosity = int(value)\n",
    "                for instruction in query_obj.instructions:\n",
    "                    instruction.verbosity = query_obj.verbosity\n",
    "            else:\n",
    "                log(f'warning: verbosity must be an integer between 0 and 5. \"{value}\" is not valid',\n",
    "                    'df.q()', query_obj.verbosity)\n",
    "        \n",
    "        elif operator == OPERATORS.SET_DIFF:\n",
    "            if value.lower() in ['none', '0']:\n",
    "                query_obj.diff = None\n",
    "            elif value.lower() in ['mix', 'new', 'old', 'new+']:\n",
    "                query_obj.diff = value.lower()\n",
    "            else:\n",
    "                log(f'warning: diff must be one of [None, \"mix\", \"old\", \"new\", \"new+\"]. \"{value}\" is not valid',\n",
    "                    'df.q()', query_obj.verbosity)\n",
    "                \n",
    "        elif operator == OPERATORS.SET_INPLACE:\n",
    "            if value.lower() in ['true', '1', 'yes']:\n",
    "                query_obj.inplace = True\n",
    "                query_obj.df = query_obj.df_og \n",
    "                query_obj.df.qp = query_obj.df_og.qp\n",
    "\n",
    "            elif value.lower() in ['false', '0', 'no']:\n",
    "                query_obj.inplace = False\n",
    "                query_obj.df = None\n",
    "            else:\n",
    "                log(f'warning: inplace must be a boolean. \"{value}\" is not valid',\n",
    "                    'df.q()', query_obj.verbosity)\n",
    "    \n",
    "\n",
    "class SelectCols:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.SELECT_COLS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.negation = NEGATION.FALSE\n",
    "        self.operator = OPERATORS.EQUAL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.negations = [NEGATION.TRUE]\n",
    "        self.operators = [\n",
    "            #binary\n",
    "            OPERATORS.BIGGER_EQUAL, OPERATORS.SMALLER_EQUAL, OPERATORS.BIGGER, OPERATORS.SMALLER,\n",
    "            OPERATORS.STRICT_EQUAL, OPERATORS.EQUAL,\n",
    "            OPERATORS.STRICT_CONTAINS, OPERATORS.CONTAINS,\n",
    "            OPERATORS.MATCHES_REGEX, OPERATORS.CONTAINS_REGEX,\n",
    "            OPERATORS.EVAL,\n",
    "            OPERATORS.LOAD_SELECTION,\n",
    "        \n",
    "            #unary\n",
    "            OPERATORS.IS_ANY,\n",
    "            OPERATORS.IS_UNIQUE,\n",
    "            OPERATORS.IS_NA, OPERATORS.IS_NK,\n",
    "            OPERATORS.IS_STR, OPERATORS.IS_INT, OPERATORS.IS_FLOAT, OPERATORS.IS_NUM, OPERATORS.IS_BOOL,\n",
    "            OPERATORS.IS_DATE, OPERATORS.IS_DATETIME,\n",
    "            OPERATORS.IS_YN, OPERATORS.IS_YES, OPERATORS.IS_NO,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "             \n",
    "    def __repr__(self):\n",
    "        return f'SELECT_COLS:\\n\\tconnector: {self.connector}\\n\\tnegation: {self.negation}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        #parse the expression\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.negation, text = match_symbol(text, self.negation, self.negations, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "\n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            df = query_obj.df_og\n",
    "        else:\n",
    "            df = query_obj.df\n",
    "\n",
    "        cols = df.columns.to_series()\n",
    "\n",
    "        cols_filtered_new = filter_series(query_obj, cols, instruction=self)\n",
    "\n",
    "        if cols_filtered_new.any() == False:\n",
    "            log(f'warning: no columns fulfill the condition in \"{self.text}\"',\n",
    "                'df.q()', self.verbosity)\n",
    "\n",
    "        query_obj.cols_filtered = _update_index(query_obj.cols_filtered, cols_filtered_new, self.connector)\n",
    "\n",
    "\n",
    "class SelectRows:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.SELECT_ROWS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.scope = SCOPE.ANY  #only for rows\n",
    "        self.negation = NEGATION.FALSE\n",
    "        self.operator = OPERATORS.EQUAL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.scopes = [SCOPE.ANY, SCOPE.ALL, SCOPE.INDEX]  #only for rows\n",
    "        self.negations = [NEGATION.TRUE]\n",
    "        self.operators = [\n",
    "            #binary\n",
    "            OPERATORS.BIGGER_EQUAL, OPERATORS.SMALLER_EQUAL, OPERATORS.BIGGER, OPERATORS.SMALLER,\n",
    "            OPERATORS.STRICT_EQUAL, OPERATORS.EQUAL,\n",
    "            OPERATORS.STRICT_CONTAINS, OPERATORS.CONTAINS,\n",
    "            OPERATORS.MATCHES_REGEX, OPERATORS.CONTAINS_REGEX,\n",
    "            OPERATORS.EVAL, OPERATORS.COL_EVAL,  #only for rows\n",
    "            OPERATORS.LOAD_SELECTION,\n",
    "        \n",
    "            #unary\n",
    "            OPERATORS.IS_ANY,\n",
    "            OPERATORS.IS_UNIQUE, OPERATORS.IS_FIRST, OPERATORS.IS_LAST,\n",
    "            OPERATORS.IS_NA, OPERATORS.IS_NK,\n",
    "            OPERATORS.IS_STR, OPERATORS.IS_INT, OPERATORS.IS_FLOAT, OPERATORS.IS_NUM, OPERATORS.IS_BOOL,\n",
    "            OPERATORS.IS_DATE, OPERATORS.IS_DATETIME,\n",
    "            OPERATORS.IS_YN, OPERATORS.IS_YES, OPERATORS.IS_NO,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "             \n",
    "    def __repr__(self):\n",
    "        return f'SELECT_ROWS:\\n\\tconnector: {self.connector}\\n\\tscope: {self.scope}\\n\\tnegation: {self.negation}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        #parse the expression\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.scope, text = match_symbol(text, self.scope, self.scopes, self.verbosity)\n",
    "        self.negation, text = match_symbol(text, self.negation, self.negations, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "\n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            df = query_obj.df_og\n",
    "        else:\n",
    "            df = query_obj.df\n",
    "\n",
    "        #select rows using parsed expression\n",
    "        scope = self.scope\n",
    "        connector = self.connector\n",
    "        verbosity = query_obj.verbosity\n",
    "\n",
    "        rows = df.index.to_series()\n",
    "        cols_filtered = query_obj.cols_filtered\n",
    "\n",
    "        if cols_filtered.any() == False:\n",
    "            log(f'warning: row filter cannot be applied when no columns where selected', 'df.q', verbosity)\n",
    "            return\n",
    "                \n",
    "        if scope == SCOPE.INDEX:\n",
    "            rows_filtered_new = filter_series(query_obj, rows, instruction=self)\n",
    "            query_obj.rows_filtered = _update_index(query_obj.rows_filtered, rows_filtered_new, connector)\n",
    "\n",
    "        else:\n",
    "            rows_filtered_temp = None\n",
    "            for col in df.columns[cols_filtered]:\n",
    "                rows_filtered_new = filter_series(query_obj, df[col], instruction=self)\n",
    "                rows_filtered_temp = _update_index(rows_filtered_temp, rows_filtered_new, scope)\n",
    "            query_obj.rows_filtered = _update_index(query_obj.rows_filtered, rows_filtered_temp, connector)\n",
    "\n",
    "            if rows_filtered_temp.any() == False:\n",
    "                log(f'warning: no rows fulfill the condition in \"{self.text}\"', 'df.q', verbosity)\n",
    "\n",
    "\n",
    "class ModifyVals:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.MODIFY_VALS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.operator = OPERATORS.SET_VAL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.operators = [\n",
    "            OPERATORS.SET_VAL, OPERATORS.ADD_VAL,\n",
    "            OPERATORS.SET_EVAL, OPERATORS.SET_COL_EVAL,\n",
    "            OPERATORS.TO_STR, OPERATORS.TO_INT, OPERATORS.TO_FLOAT, OPERATORS.TO_NUM, OPERATORS.TO_BOOL,\n",
    "            OPERATORS.TO_DATE, OPERATORS.TO_DATETIME, OPERATORS.TO_NA, OPERATORS.TO_NK, OPERATORS.TO_YN,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MODIFY_VALS:\\n\\tconnector: {self.connector}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "        \n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            query_obj.df = query_obj.df_og.copy()  #default is inplace=False\n",
    "            query_obj.df.qp = query_obj.df.qp\n",
    "        \n",
    "        rows = query_obj.rows_filtered\n",
    "        cols = query_obj.cols_filtered\n",
    "\n",
    "        operator = self.operator\n",
    "        value = self.value\n",
    "\n",
    "        #data modification  \n",
    "        if operator == OPERATORS.SET_VAL:\n",
    "            query_obj.df.loc[rows, cols] = value\n",
    "        elif operator == OPERATORS.ADD_VAL:\n",
    "            query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].astype(str) + value\n",
    "        elif operator == OPERATORS.SET_COL_EVAL:\n",
    "            query_obj.df.loc[:, cols] = query_obj.df.loc[:, cols].apply(lambda x: eval(value, {'col': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}), axis=0)\n",
    "\n",
    "\n",
    "        elif pd.__version__ >= '2.1.0':  #map was called applymap before 2.1.0\n",
    "            #data modification\n",
    "            if operator == OPERATORS.SET_EVAL:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(lambda x: eval(value, {'x': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "\n",
    "\n",
    "            #type conversion\n",
    "            elif operator == OPERATORS.TO_STR:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(str)\n",
    "            elif operator == OPERATORS.TO_INT:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_int)\n",
    "            elif operator == OPERATORS.TO_FLOAT:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_float)\n",
    "            elif operator == OPERATORS.TO_NUM:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_num)\n",
    "            elif operator == OPERATORS.TO_BOOL:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_bool)\n",
    "            \n",
    "            elif operator == OPERATORS.TO_DATETIME:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_datetime)\n",
    "            elif operator == OPERATORS.TO_DATE:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_date)\n",
    "\n",
    "            elif operator == OPERATORS.TO_NA:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_na)\n",
    "            elif operator == OPERATORS.TO_NK:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_nk)\n",
    "            elif operator == OPERATORS.TO_YN:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].map(_yn)\n",
    "\n",
    "        else:\n",
    "            #data modification\n",
    "            if operator == OPERATORS.SET_EVAL:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(lambda x: eval(value, {'x': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "\n",
    "            #type conversion\n",
    "            elif operator == OPERATORS.TO_STR:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(str)\n",
    "            elif operator == OPERATORS.TO_INT:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_int)\n",
    "            elif operator == OPERATORS.TO_FLOAT:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_float)\n",
    "            elif operator == OPERATORS.TO_NUM:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_num)\n",
    "            elif operator == OPERATORS.TO_BOOL:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_bool)\n",
    "            \n",
    "            elif operator == OPERATORS.TO_DATETIME:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_datetime)\n",
    "            elif operator == OPERATORS.TO_DATE:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_date)\n",
    "\n",
    "            elif operator == OPERATORS.TO_NA:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_na)\n",
    "            elif operator == OPERATORS.TO_NK:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_nk)\n",
    "            elif operator == OPERATORS.TO_YN:\n",
    "                query_obj.df.loc[rows, cols] = query_obj.df.loc[rows, cols].applymap(_yn)\n",
    "\n",
    "\n",
    "class ModifyHeaders:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.MODIFY_HEADERS\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.operator = OPERATORS.SET_VAL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.operators = [\n",
    "            OPERATORS.SET_VAL, OPERATORS.ADD_VAL,\n",
    "            OPERATORS.SET_EVAL,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'MODIFY_HEADERS:\\n\\tconnector: {self.connector}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "        \n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            query_obj.df = query_obj.df_og.copy()  #default is inplace=False\n",
    "            query_obj.df.qp = query_obj.df.qp\n",
    "        \n",
    "        cols = query_obj.cols_filtered\n",
    "\n",
    "        operator = self.operator\n",
    "        value = self.value\n",
    "\n",
    "\n",
    "        if operator == OPERATORS.SET_VAL:\n",
    "            query_obj.df.rename(columns={col: value for col in query_obj.df.columns[cols]}, inplace=True)\n",
    "            query_obj.cols_filtered.index = query_obj.df.columns\n",
    "        \n",
    "        if pd.__version__ >= '2.1.0':\n",
    "            if operator == OPERATORS.SET_EVAL:\n",
    "                new_headers = query_obj.df.columns.map(lambda x: eval(value, {'header': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "                query_obj.df.columns = new_headers\n",
    "                query_obj.cols_filtered.index = new_headers\n",
    "        else:\n",
    "            if operator == OPERATORS.SET_EVAL:\n",
    "                new_headers = query_obj.df.columns.applymap(lambda x: eval(value, {'header': x, 'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "                query_obj.df.columns = new_headers\n",
    "                query_obj.cols_filtered.index = new_headers\n",
    "\n",
    "\n",
    "class NewCol:\n",
    "    def __init__(self, text=None, linenum=None, verbosity=3):\n",
    "        self.text = text\n",
    "        self.linenum = linenum\n",
    "\n",
    "        #default values\n",
    "        self.type = TYPES.NEW_COL\n",
    "        self.connector = CONNECTORS.RESET\n",
    "        self.operator = OPERATORS.STR_COL\n",
    "        self.value = ''\n",
    "\n",
    "        #possible values (omitting those without a symbol)\n",
    "        self.connectors = [CONNECTORS.AND, CONNECTORS.OR]\n",
    "        self.operators = [\n",
    "            OPERATORS.STR_COL,\n",
    "            OPERATORS.EVAL_COL,\n",
    "            OPERATORS.SAVE_SELECTION,\n",
    "            ]\n",
    "        self.verbosity = verbosity\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'NEW_COL:\\n\\tconnector: {self.connector}\\n\\toperator: {self.operator}\\n\\tvalue: {self.value}'\n",
    "    \n",
    "    def parse(self):\n",
    "        self.connector, text = match_symbol(self.text[2:], self.connector, self.connectors, self.verbosity)\n",
    "        self.operator, text = match_symbol(text, self.operator, self.operators, self.verbosity)\n",
    "        self.value = text.strip()\n",
    "\n",
    "        if self.operator.unary and len(self.value)>0:\n",
    "            log(f'warning: unary operator \"{self.operator}\" cannot use a value. value \"{self.value}\" will be ignored',\n",
    "                '_parse_expression', self.verbosity)\n",
    "            self.value = ''\n",
    "\n",
    "        log(f'debug: parsed \"{self.text}\" as instruction: {self}',\n",
    "            'df.q()', self.verbosity)\n",
    "        \n",
    "    def apply(self, query_obj):\n",
    "        if query_obj.df is None:\n",
    "            query_obj.df = query_obj.df_og.copy()  #default is inplace=False\n",
    "            query_obj.df.qp = query_obj.df.qp\n",
    "        \n",
    "        if self.operator == OPERATORS.STR_COL:\n",
    "            for i in range(1, 1001):\n",
    "                if i == 1000:\n",
    "                    log(f'warning: could not add new column. too many columns named \"new<x>\"',\n",
    "                        'df.q.new_col', query_obj.verbosity)\n",
    "                    break\n",
    "\n",
    "                header = 'new' + str(i)\n",
    "                if header not in query_obj.df.columns:\n",
    "                    query_obj.df[header] = ''\n",
    "                    query_obj.df.loc[query_obj.rows_filtered, header] = self.value\n",
    "                    query_obj.cols_filtered = pd.Index([True if col == header else False for col in query_obj.df.columns])\n",
    "                    query_obj.cols_filtered.index = query_obj.df.columns\n",
    "                    break\n",
    "        \n",
    "        elif self.operator == OPERATORS.EVAL_COL:\n",
    "            for i in range(1, 1001):\n",
    "                if i == 1000:\n",
    "                    log(f'warning: could not add new column. too many columns named \"new<x>\"',\n",
    "                        'df.q.new_col', query_obj.verbosity)\n",
    "                    break\n",
    "\n",
    "                header = 'new' + str(i)\n",
    "                if header not in query_obj.df.columns:\n",
    "                    query_obj.df[header] = pd.NA\n",
    "                    query_obj.df.loc[query_obj.rows_filtered, header] = eval(self.value, {'df': query_obj.df, 'pd': pd, 'np': np, 'qp': qp})\n",
    "                    query_obj.cols_filtered = pd.Index([True if col == header else False for col in query_obj.df.columns])\n",
    "                    query_obj.cols_filtered.index = query_obj.df.columns\n",
    "                    break\n",
    "        \n",
    "\n",
    "        elif self.operator == OPERATORS.SAVE_SELECTION:\n",
    "            if self.value in query_obj.df.columns:\n",
    "                log(f'warning: column \"{self.value}\" already exists in dataframe. selecting existing col and resetting values',\n",
    "                    'df.q.new_col', query_obj.verbosity)\n",
    "                query_obj.df[self.value] = query_obj.rows_filtered\n",
    "                query_obj.cols_filtered = pd.Index([True if col == self.value else False for col in query_obj.df.columns])\n",
    "                query_obj.cols_filtered.index = query_obj.df.columns\n",
    "            else:\n",
    "                query_obj.df[self.value] = query_obj.rows_filtered\n",
    "                query_obj.cols_filtered = pd.Index([True if col == self.value else False for col in query_obj.df.columns])\n",
    "                query_obj.cols_filtered.index = query_obj.df.columns\n",
    "\n",
    "\n",
    "\n",
    "COMMENT = Symbol('#', 'COMMENT', 'comments out the rest of the line')\n",
    "ESCAPE = Symbol('`', 'ESCAPE', 'escape the next character')\n",
    "\n",
    "TYPES = Symbols('TYPES',\n",
    "    Symbol('´s', 'CHANGE_SETTINGS', 'change query settings', instruction=ChangeSettings),\n",
    "    Symbol('´c', 'SELECT_COLS', 'select columns fulfilling a condition', instruction=SelectCols),\n",
    "    Symbol('´r', 'SELECT_ROWS', 'select rows fulfilling a condition', instruction=SelectRows),\n",
    "    Symbol('´v', 'MODIFY_VALS', 'modify the selected values', instruction=ModifyVals),\n",
    "    Symbol('´h', 'MODIFY_HEADERS', 'modify headers of the selected columns', instruction=ModifyHeaders),\n",
    "    Symbol('´n', 'NEW_COL', 'add new column', instruction=NewCol),\n",
    "    )\n",
    "\n",
    "CONNECTORS = Symbols('CONNECTORS',\n",
    "    Symbol('', 'RESET', 'only the current condition must be fulfilled'),\n",
    "    Symbol('&', 'AND', 'this condition and the previous condition/s must be fulfilled'),\n",
    "    Symbol('/', 'OR', 'this condition or the previous condition/s must be fulfilled'),\n",
    "    )\n",
    "\n",
    "SCOPE = Symbols('SCOPE',\n",
    "    Symbol('any', 'ANY', 'any of the currently selected columns must fulfill the condition'),\n",
    "    Symbol('all', 'ALL', 'all of the currently selected columns must fulfill the condition'),\n",
    "    Symbol('idx', 'INDEX', 'the index of the dataframe must fulfill the condition'),\n",
    "    )\n",
    "\n",
    "NEGATION = Symbols('NEGATION',\n",
    "    Symbol('', 'FALSE', 'dont negate the condition'),\n",
    "    Symbol('!', 'TRUE', 'negate the condition'),\n",
    "    )\n",
    "\n",
    "OPERATORS = Symbols('OPERATORS',\n",
    "    #for changing settings\n",
    "    Symbol('verbosity=', 'SET_VERBOSITY', 'change the verbosity level'),\n",
    "    Symbol('diff=', 'SET_DIFF', 'change the diff setting'),\n",
    "    Symbol('inplace=', 'SET_INPLACE', 'change the inplace setting'),\n",
    "\n",
    "\n",
    "    #for filtering\n",
    "    Symbol('>=', 'BIGGER_EQUAL', 'bigger or equal', binary=True),\n",
    "    Symbol('<=', 'SMALLER_EQUAL', 'smaller or equal', binary=True),\n",
    "    Symbol('>', 'BIGGER', 'bigger', binary=True),\n",
    "    Symbol('<', 'SMALLER', 'smaller', binary=True),\n",
    "\n",
    "    Symbol('==', 'STRICT_EQUAL', 'equal to (case sensitive)', binary=True),\n",
    "    Symbol('=', 'EQUAL', 'equal to', binary=True),\n",
    "\n",
    "    Symbol('??', 'STRICT_CONTAINS', 'contains a string (case sensitive)', binary=True),\n",
    "    Symbol('?', 'CONTAINS', 'contains a string (not case sensitive)', binary=True),\n",
    "\n",
    "    Symbol('r=', 'MATCHES_REGEX', 'matches a regex', binary=True),\n",
    "    Symbol('r?', 'CONTAINS_REGEX', 'contains a regex', binary=True),\n",
    "\n",
    "    Symbol('~', 'EVAL', 'select values by evaluating a python expression on each value', binary=True),\n",
    "    Symbol('col~', 'COL_EVAL', 'select rows by evaluating a python expression on a whole column', binary=True),\n",
    "\n",
    "    Symbol('@', 'LOAD_SELECTION', 'load a saved selection from a boolean column', binary=True),\n",
    "\n",
    "    Symbol('is any', 'IS_ANY', 'is any value', unary=True),\n",
    "    Symbol('is str', 'IS_STR', 'is string', unary=True),\n",
    "    Symbol('is int', 'IS_INT', 'is integer', unary=True),\n",
    "    Symbol('is float', 'IS_FLOAT', 'is float', unary=True),\n",
    "    Symbol('is num', 'IS_NUM', 'is number', unary=True),\n",
    "    Symbol('is bool', 'IS_BOOL', 'is boolean', unary=True),\n",
    "    Symbol('is datetime', 'IS_DATETIME', 'is datetime', unary=True),\n",
    "    Symbol('is date', 'IS_DATE', 'is date', unary=True),\n",
    "    Symbol('is na', 'IS_NA', 'is missing value', unary=True),\n",
    "    Symbol('is nk', 'IS_NK', 'is not known value', unary=True),\n",
    "    Symbol('is yn', 'IS_YN', 'is yes or no value', unary=True),\n",
    "    Symbol('is yes', 'IS_YES', 'is yes value', unary=True),\n",
    "    Symbol('is no', 'IS_NO', 'is no value', unary=True),\n",
    "    Symbol('is unique', 'IS_UNIQUE', 'is a unique value', unary=True),\n",
    "    Symbol('is first', 'IS_FIRST', 'is the first value (of multiple values)', unary=True),\n",
    "    Symbol('is last', 'IS_LAST', 'is the last value (of multiple values)', unary=True),\n",
    "\n",
    "\n",
    "    #for modifying values and headers\n",
    "    Symbol('=', 'SET_VAL', 'convert to string'),\n",
    "    Symbol('+=', 'ADD_VAL', 'append to string (coerce to string if needed)'),\n",
    "\n",
    "    Symbol('~', 'SET_EVAL', 'convert by evaluating a python expression for each selected value/header'),\n",
    "    Symbol('col~', 'SET_COL_EVAL', 'convert by evaluating a python expression for each selected column'),\n",
    "\n",
    "    Symbol('to str', 'TO_STR', 'convert to string', unary=True),\n",
    "    Symbol('to int', 'TO_INT', 'convert to integer', unary=True),\n",
    "    Symbol('to float', 'TO_FLOAT', 'convert to float', unary=True),\n",
    "    Symbol('to num', 'TO_NUM', 'convert to number', unary=True),\n",
    "    Symbol('to bool', 'TO_BOOL', 'convert to boolean', unary=True),\n",
    "    Symbol('to datetime', 'TO_DATETIME', 'convert to datetime', unary=True),\n",
    "    Symbol('to date', 'TO_DATE', 'convert to date', unary=True),\n",
    "    Symbol('to na', 'TO_NA', 'convert to missing value', unary=True),\n",
    "    Symbol('to nk', 'TO_NK', 'convert to not known value', unary=True),\n",
    "    Symbol('to yn', 'TO_YN', 'convert to yes or no value', unary=True),\n",
    "\n",
    "\n",
    "    #for adding new columns\n",
    "    Symbol('=', 'STR_COL', 'add new column, fill it with the given string and select it'),\n",
    "    Symbol('~', 'EVAL_COL', 'add new column, fill it by evaluating a python expression and select it'),\n",
    "    Symbol('@', 'SAVE_SELECTION', 'add a new boolean column with the given name and select it. all currently selected rows are set to True, the rest to False'),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(code, verbosity=3):\n",
    "    lines = []\n",
    "    instructions = []\n",
    "\n",
    "    #get lines and instruction blocks\n",
    "    for line_num, line in enumerate(code.split('\\n')):\n",
    "        line = line.strip()\n",
    "        lines.append([line_num, line])\n",
    "        line = line.split(COMMENT.symbol)[0].strip()\n",
    "    \n",
    "        if line == '':\n",
    "            continue\n",
    "\n",
    "\n",
    "        escape = False\n",
    "        chars_in_instruction = 0\n",
    "        instruction_type = TYPES.SELECT_COLS.symbol  #default\n",
    "\n",
    "        for i, char in enumerate(line):\n",
    "            if escape:\n",
    "                instructions[-1].text += char\n",
    "                chars_in_instruction += 1\n",
    "                escape = False\n",
    "                continue\n",
    "            elif char == ESCAPE.symbol:\n",
    "                escape = True\n",
    "                continue\n",
    "\n",
    "            if char == '´':\n",
    "                instruction_type = char + line[i+1]\n",
    "                instructions.append(TYPES[instruction_type].instruction(char, line_num, verbosity))\n",
    "                chars_in_instruction = 1\n",
    "            elif char in [CONNECTORS.AND.symbol, CONNECTORS.OR.symbol]:\n",
    "                if chars_in_instruction >= 3:\n",
    "                    instructions.append(TYPES[instruction_type].instruction(f'{instruction_type} {char}', line_num, verbosity))\n",
    "                    chars_in_instruction = 3\n",
    "                elif i == 0:\n",
    "                    instructions.append(TYPES[instruction_type].instruction(f'{instruction_type} {char}', line_num, verbosity))\n",
    "                    chars_in_instruction = 3\n",
    "                else:\n",
    "                    instructions[-1].text += char\n",
    "                    chars_in_instruction += 1\n",
    "            elif i == 0:\n",
    "                instructions.append(TYPES[instruction_type].instruction(f'{instruction_type} {char}', line_num, verbosity))\n",
    "                chars_in_instruction = 3\n",
    "            elif char == ' ':\n",
    "                instructions[-1].text += char\n",
    "            else:\n",
    "                instructions[-1].text += char\n",
    "                chars_in_instruction += 1\n",
    "\n",
    "    return lines, instructions\n",
    "\n",
    "\n",
    "def match_symbol(string, default, symbols, verbosity):\n",
    "    string = string.strip()\n",
    "\n",
    "    for symbol in symbols:\n",
    "        if string.startswith(symbol.symbol):\n",
    "            log(f'trace: found symbol \"{symbol}\" in string \"{string}\"', 'match_symbol', verbosity)\n",
    "            return symbol, string[len(symbol.symbol):].strip()\n",
    "    \n",
    "    log(f'trace: no symbol found in string \"{string}\". using default \"{default}\"', 'match_symbol', verbosity)\n",
    "    \n",
    "    if default is None:\n",
    "        return None, string\n",
    "    if string.startswith(default.symbol):\n",
    "        string = string[len(default.symbol):].strip()\n",
    "    return default, string\n",
    "\n",
    "\n",
    "def filter_series(query_obj, series, instruction):\n",
    "    negation = instruction.negation\n",
    "    operator = instruction.operator\n",
    "    value = instruction.value\n",
    "    verbosity = instruction.verbosity\n",
    "    df = query_obj.df\n",
    "\n",
    "\n",
    "    #numeric comparison\n",
    "    if operator == OPERATORS.BIGGER_EQUAL:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') >= pd.to_numeric(value)\n",
    "    elif operator == OPERATORS.SMALLER_EQUAL:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') <= pd.to_numeric(value)\n",
    "    elif operator == OPERATORS.BIGGER:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') > pd.to_numeric(value)\n",
    "    elif operator == OPERATORS.SMALLER:\n",
    "        filtered = pd.to_numeric(series, errors='coerce') < pd.to_numeric(value)\n",
    "\n",
    "\n",
    "    #string equality comparison\n",
    "    elif operator == OPERATORS.STRICT_EQUAL:\n",
    "        filtered = series.astype(str) == value\n",
    "    elif operator == OPERATORS.EQUAL:\n",
    "        value_lenient = [value]\n",
    "        try:\n",
    "            value_lenient.append(str(float(value)))\n",
    "            value_lenient.append(str(int(float(value))))\n",
    "        except:\n",
    "            value_lenient.append(value.lower())\n",
    "        filtered = series.astype(str).str.lower().isin(value_lenient)\n",
    "\n",
    "\n",
    "    #substring comparison\n",
    "    elif operator == OPERATORS.STRICT_CONTAINS:\n",
    "        filtered = series.astype(str).str.contains(value, case=True, regex=False)\n",
    "    elif operator == OPERATORS.CONTAINS:\n",
    "        filtered = series.astype(str).str.contains(value, case=False, regex=False)\n",
    "\n",
    "\n",
    "    #regex comparison\n",
    "    elif operator == OPERATORS.MATCHES_REGEX:\n",
    "        filtered = series.astype(str).str.fullmatch(value) \n",
    "    elif operator == OPERATORS.CONTAINS_REGEX:\n",
    "        filtered = series.astype(str).str.contains(value)\n",
    "\n",
    "\n",
    "    #lambda function\n",
    "    elif operator == OPERATORS.EVAL:\n",
    "        filtered = series.apply(lambda x: eval(value, {'x': x, 'col': series, 'df': df, 'pd': pd, 'np': np, 'qp': qp}))\n",
    "    elif operator == OPERATORS.COL_EVAL:\n",
    "        filtered = eval(value, {'col': series, 'df': df, 'pd': pd, 'np': np, 'qp': qp})\n",
    "\n",
    "    #load saved selection\n",
    "    elif operator == OPERATORS.LOAD_SELECTION:\n",
    "        if value in df.columns:\n",
    "            filtered = df[value]\n",
    "        else:\n",
    "            log(f'error: column \"{value}\" does not exist in dataframe. cannot load selection',\n",
    "                '_filter()', verbosity)\n",
    "\n",
    "\n",
    "    #type checks\n",
    "    elif operator == OPERATORS.IS_STR:\n",
    "        filtered = series.apply(lambda x: isinstance(x, str))\n",
    "    elif operator == OPERATORS.IS_INT:\n",
    "        filtered = series.apply(lambda x: isinstance(x, int))\n",
    "    elif operator == OPERATORS.IS_FLOAT:\n",
    "        filtered = series.apply(lambda x: isinstance(x, float))\n",
    "    elif operator == OPERATORS.IS_NUM:\n",
    "        filtered = series.apply(lambda x: _num(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_BOOL:\n",
    "        filtered = series.apply(lambda x: isinstance(x, bool))\n",
    "\n",
    "    elif operator == OPERATORS.IS_DATETIME:\n",
    "        filtered = series.apply(lambda x: _datetime(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_DATE:\n",
    "        filtered = series.apply(lambda x: _date(x, errors='ERROR')) != 'ERROR'\n",
    "\n",
    "    elif operator == OPERATORS.IS_ANY:\n",
    "        filtered = series.apply(lambda x: True)\n",
    "    elif operator == OPERATORS.IS_NA:\n",
    "        filtered = series.apply(lambda x: _na(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_NK:\n",
    "        filtered = series.apply(lambda x: _nk(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_YN:\n",
    "        filtered = series.apply(lambda x: _yn(x, errors='ERROR')) != 'ERROR'\n",
    "    elif operator == OPERATORS.IS_YES:\n",
    "        filtered = series.apply(lambda x: _yn(x, errors='ERROR', yes=1)) == 1\n",
    "    elif operator == OPERATORS.IS_NO:\n",
    "        filtered = series.apply(lambda x: _yn(x, errors='ERROR', no=0)) == 0\n",
    "        \n",
    "    elif operator == OPERATORS.IS_UNIQUE:\n",
    "        filtered = series.duplicated(keep=False) == False\n",
    "    elif operator == OPERATORS.IS_FIRST:\n",
    "        filtered = series.duplicated(keep='first') == False\n",
    "    elif operator == OPERATORS.IS_LAST:\n",
    "        filtered = series.duplicated(keep='last') == False\n",
    "\n",
    "    else:\n",
    "        log(f'error: operator \"{operator}\" is not implemented', '_filter()', verbosity)\n",
    "        filtered = None\n",
    "\n",
    "\n",
    "    if negation == NEGATION.TRUE:\n",
    "        filtered = ~filtered\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def _update_index(values, values_new, connector):\n",
    "    if values is None:\n",
    "        values = values_new\n",
    "    elif connector == CONNECTORS.RESET:\n",
    "        values = values_new\n",
    "    elif connector in [CONNECTORS.AND, SCOPE.ALL]:\n",
    "        values &= values_new\n",
    "    elif connector in [CONNECTORS.OR, SCOPE.ANY]:\n",
    "        values |= values_new\n",
    "    return values\n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('q')\n",
    "class DataFrameQuery:\n",
    "    \"\"\"\n",
    "    wip\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        _check_df(df)\n",
    "        self.df_og = df\n",
    "        self.mask = pd.DataFrame(True, index=df.index, columns=df.columns)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'docstring of dataframe accessor pd_object.q():' + self.__doc__\n",
    "    \n",
    "    def __call__(self,\n",
    "            code='',  #code in string form for filtering and modifying data\n",
    "            inplace=False,  #make modifications inplace or just return a new dataframe.\n",
    "            verbosity=3,  #verbosity level for logging. 0: no logging, 1: errors, 2: warnings, 3: info, 4: debug\n",
    "            diff=None,  #[None, 'mix', 'old', 'new', 'new+']\n",
    "            diff_max_cols=200,  #maximum number of columns to display when using diff. None: show all\n",
    "            diff_max_rows=20,  #maximum number of rows to display when using diff. None: show all\n",
    "            ):\n",
    "        \n",
    "        #setup\n",
    "\n",
    "        self.code = code\n",
    "        self.inplace = inplace\n",
    "        self.verbosity = verbosity\n",
    "        self.diff = diff\n",
    "        self.diff_max_cols = diff_max_cols\n",
    "        self.diff_max_rows = diff_max_rows\n",
    "\n",
    "        if inplace is False:\n",
    "            self.df = None\n",
    "        else:\n",
    "            self.df = self.df_og \n",
    "            self.df.qp = self.df_og.qp \n",
    "\n",
    "        self.cols_filtered = pd.Index([True for col in self.df_og.columns])\n",
    "        self.rows_filtered = pd.Index([True for row in self.df_og.index])\n",
    "\n",
    "\n",
    "\n",
    "        #instructions\n",
    "\n",
    "        self.lines, self.instructions = tokenize(self.code, self.verbosity)\n",
    "\n",
    "        for instruction in self.instructions:\n",
    "            instruction.parse()\n",
    "            instruction.apply(self)\n",
    "\n",
    "   \n",
    "        #results\n",
    "        if self.df is None:\n",
    "            df = self.df_og\n",
    "        else:\n",
    "            df = self.df\n",
    "\n",
    "        self.df_filtered = df.loc[self.rows_filtered, self.cols_filtered]\n",
    "        self.df_filtered.qp = df.qp\n",
    "        self.df_filtered.qp.code = self.code\n",
    "    \n",
    "        if self.diff is None:\n",
    "            return self.df_filtered \n",
    "        else:\n",
    "            #show difference before and after filtering\n",
    "\n",
    "            if 'meta' in df.columns and 'meta' not in self.df_filtered.columns:\n",
    "                self.df_filtered.insert(0, 'meta', df.loc[self.rows_filtered, 'meta'])\n",
    "\n",
    "            result = _diff(\n",
    "                self.df_filtered, df, mode=self.diff,\n",
    "                max_cols=self.diff_max_cols, max_rows=self.diff_max_rows,\n",
    "                verbosity=self.verbosity)  \n",
    "            return  result  \n",
    "   \n",
    "\n",
    "\n",
    "@pd.api.extensions.register_dataframe_accessor('qi')\n",
    "class DataFrameQueryInteractiveMode:\n",
    "    \"\"\"\n",
    "    Wrapper for df.q() for interactive use in Jupyter notebooks.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def __call__(self):\n",
    "        kwargs = {'df': fixed(self.df)}\n",
    "\n",
    "        #code input\n",
    "        ui_code = widgets.Textarea(\n",
    "            value='',\n",
    "            placeholder='Enter query code here',\n",
    "            layout=Layout(height='95%')\n",
    "            )\n",
    "\n",
    "\n",
    "        #query builder\n",
    "\n",
    "        instruction = TYPES.SELECT_COLS.instruction()\n",
    "\n",
    "        i_type = widgets.Dropdown(\n",
    "            options=[(s.description, s.symbol) for s in TYPES],\n",
    "            value=instruction.type.symbol,\n",
    "            )\n",
    "        \n",
    "        i_scope = widgets.Dropdown(\n",
    "            disabled=True,\n",
    "            options=[''],\n",
    "            value='',\n",
    "            )\n",
    "\n",
    "        i_negate = widgets.ToggleButtons(\n",
    "            options=[('dont negate condition', ''), ('negate condition', '!')],\n",
    "            value='',\n",
    "            )\n",
    "\n",
    "        i_operator = widgets.Dropdown(\n",
    "            options=[(s.description, s.symbol) for s in instruction.operators],\n",
    "            value=instruction.operator.symbol,\n",
    "            )\n",
    "        \n",
    "        i_value = widgets.Text(\n",
    "            value='',\n",
    "            )\n",
    "        \n",
    "\n",
    "        i_text = widgets.Text(\n",
    "            value=f'\\n{i_type.value} {i_scope.value} {i_negate.value}{i_operator.value} {i_value.value}',\n",
    "            disabled=True,\n",
    "            )\n",
    "        \n",
    "\n",
    "        def update_options(*args):\n",
    "            instruction = TYPES[i_type.value].instruction()\n",
    "\n",
    "            if hasattr(instruction, 'scopes'):\n",
    "                i_scope.disabled = False\n",
    "                i_scope.options = [(s.description, s.symbol) for s in instruction.scopes]\n",
    "            else:\n",
    "                i_scope.disabled = True\n",
    "                i_scope.options = ['']\n",
    "\n",
    "            if hasattr(instruction, 'negations'):\n",
    "                i_negate.disabled = False\n",
    "                i_negate.options = [('dont negate condition', ''), ('negate condition', '!')]\n",
    "            else:\n",
    "                i_negate.disabled = True\n",
    "                i_negate.options = ['', '']\n",
    "\n",
    "            i_operator.options = [(s.description, s.symbol) for s in instruction.operators]\n",
    "            i_operator.value = instruction.operator.symbol\n",
    "\n",
    "        def update_text(*args):\n",
    "            i_text.value = f'{i_type.value} {i_scope.value} {i_negate.value}{i_operator.value} {i_value.value}'\n",
    "\n",
    "        i_type.observe(update_options, 'value')\n",
    "        i_type.observe(update_text, 'value')\n",
    "        i_scope.observe(update_text, 'value')\n",
    "        i_negate.observe(update_text, 'value')\n",
    "        i_operator.observe(update_text, 'value')\n",
    "        i_value.observe(update_text, 'value')\n",
    "\n",
    "        \n",
    "        ui_add_instruction = widgets.Button(\n",
    "            button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='adds the selected instruction to the query code',\n",
    "            icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    "            )\n",
    "\n",
    "        def add_instruction(ui_code, i_text):\n",
    "            if i_text.value.startswith('´c'):\n",
    "                ui_code.value += f'\\n{i_text.value}'\n",
    "            else:\n",
    "                ui_code.value += f'   {i_text.value}'\n",
    "\n",
    "        ui_add_instruction.on_click(lambda b: add_instruction(ui_code, i_text))\n",
    "\n",
    "        kwargs['code'] = ui_code\n",
    "\n",
    "\n",
    "        ui_diff = widgets.ToggleButtons(\n",
    "            options=[None, 'mix', 'old', 'new', 'new+'],\n",
    "            description='show differences mode:',\n",
    "            tooltips=[\n",
    "                'dont show differences, just show the new (filtered) dataframe.',\n",
    "                'show new (filtered) dataframe plus all the removed (filtered) values from the old dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show old (unfiltered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                'show new (filtered) dataframe but also adds metadata columns with the prefix \"#\". If a value changed, the metadata column contains the old value. values affected by the filters are marked green (newly added), yellow (modified), red (deleted)',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['diff'] = ui_diff\n",
    "\n",
    "        ui_verbosity = widgets.ToggleButtons(\n",
    "            options=[0, 1, 2, 3, 4, 5],\n",
    "            value=3,\n",
    "            description='verbosity level:',\n",
    "            tooltips=[\n",
    "                'no logging',\n",
    "                'only errors',\n",
    "                'errors and warnings',\n",
    "                'errors, warnings and info',\n",
    "                'errors, warnings, info and debug',\n",
    "                'errors, warnings, info, debug and trace',\n",
    "                ],\n",
    "            )\n",
    "        \n",
    "        kwargs['verbosity'] = ui_verbosity\n",
    "\n",
    "        ui_inplace = widgets.ToggleButtons(\n",
    "            options=[True, False],\n",
    "            value=False,\n",
    "            description='make modifications inplace:',\n",
    "            tooltips=[\n",
    "                'make modifications inplace, e.g. change the original dataframe.',\n",
    "                'return a new dataframe with the modifications. lower performance.',\n",
    "                ],\n",
    "            )\n",
    "        kwargs['inplace'] = ui_inplace\n",
    "\n",
    "\n",
    "        ui_settings = VBox([\n",
    "            ui_diff,\n",
    "            ui_verbosity,\n",
    "            ui_inplace,\n",
    "            ])\n",
    "        \n",
    "        \n",
    "        #some general info and statistics about the df\n",
    "        ui_details = widgets.HTML(\n",
    "            value=f\"\"\"\n",
    "            <b>shape:</b> {self.df.shape}<br>\n",
    "            <b>memory usage:</b> {self.df.memory_usage().sum()} bytes<br>\n",
    "            <b>unique values:</b> {self.df.nunique().sum()}<br>\n",
    "            <b>missing values:</b> {self.df.isna().sum().sum()}<br>\n",
    "            <b>columns:</b><br> {'<br>'.join([f'{col} ({dtype})' for col, dtype in list(zip(self.df.columns, self.df.dtypes))])}<br>\n",
    "            \"\"\"\n",
    "            )\n",
    "        \n",
    "\n",
    "        ui_info = widgets.Tab(\n",
    "            children=[\n",
    "                ui_settings,\n",
    "                ui_details,\n",
    "                widgets.HTML(value=DataFrameQuery.__doc__),\n",
    "                ],\n",
    "            titles=['settings', 'details', 'readme'],\n",
    "            layout=Layout(width='30%', height='95%')\n",
    "            )\n",
    "        \n",
    "\n",
    "        ui_input = VBox([\n",
    "            widgets.HTML(value='<b>query builder:</b>'),\n",
    "            i_text,\n",
    "            i_type,\n",
    "            i_scope,\n",
    "            i_negate,\n",
    "            i_operator,\n",
    "            i_value,\n",
    "            ui_add_instruction,\n",
    "            ])\n",
    "        \n",
    "        # ui_input = HBox([ui_code, ui_instruction_builder], layout=Layout(width='50%', height='100%'))\n",
    "        ui = HBox([ui_code, ui_input, ui_info], layout=Layout(width='100%', height='300px'))\n",
    "\n",
    "        display(ui)\n",
    "        out = HBox([interactive_output(_interactive_mode, kwargs)], layout=Layout(overflow_y='auto'))\n",
    "        display(out)\n",
    "\n",
    "\n",
    "def _interactive_mode(**kwargs):\n",
    "\n",
    "    df = kwargs.pop('df')\n",
    "\n",
    "    result = df.q(\n",
    "        code=kwargs['code'],\n",
    "        inplace=kwargs['inplace'],\n",
    "        diff=kwargs['diff'],\n",
    "        verbosity=kwargs['verbosity'],\n",
    "        # max_cols=kwargs['max_cols'],\n",
    "        # max_rows=kwargs['max_rows'],\n",
    "        )\n",
    "    \n",
    "    display(result)\n",
    "    return result \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if 'cards' not in globals():\n",
    "#     cards = pd.read_csv('data/cards.csv')\n",
    "# cards.q('toughness ´r >2 & <5')\n",
    "# cards.qi()\n",
    "\n",
    "\n",
    "# df = qp.get_df()\n",
    "# df.q(\n",
    "#     r\"\"\"\n",
    "#     # id ´r ?1  ´n test\n",
    "#     # name ´m ~ x.upper()\n",
    "#     # is any ´r is any\n",
    "\n",
    "#     date of birth / age\n",
    "\n",
    "#     \"\"\",\n",
    "#     diff=None,\n",
    "#     inplace=False,\n",
    "#     verbosity=4,\n",
    "#     )\n",
    "\n",
    "df = qp.get_df()\n",
    "df.qi()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [0,1,2],\n",
    "    'b': [-1, 0, 1],\n",
    "    'c': [0.1, 0.2, 0.3],\n",
    "    })\n",
    "\n",
    "m0 = pd.DataFrame(True, index=df.index, columns=df.columns)\n",
    "\n",
    "m1 = df > 0\n",
    "m2 = df['b'] < 0 \n",
    "m3 = df[1:] > 0\n",
    "\n",
    "# df[m1]\n",
    "# df[m1].dropna(how='all')\n",
    "\n",
    "m1 | m2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cards = pd.read_csv('data/cards.csv').fillna('')\n",
    "c = cards.q('power / toughness ´v to num  ´c is any  ´r is any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.DataFrame(True, index=c.index, columns=c.columns)\n",
    "\n",
    "\n",
    "m1 = c['power'] > 10\n",
    "m2 = c['toughness'] > 10\n",
    "m3 = m1 | m2\n",
    "\n",
    "\n",
    "c1 = c[m1 | m2]\n",
    "\n",
    "\n",
    "import cProfile, pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "mask = pd.DataFrame(True, index=c.index, columns=c.columns)\n",
    "mask['power'] = c['power'] > 10\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "stats.print_stats(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qp.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.pd_util import _format_df, get_dfs\n",
    "from qplib.util import log, GREEN, RED, ORANGE, GREEN_LIGHT, RED_LIGHT, ORANGE_LIGHT\n",
    "from qplib.types import _date, _na, qpDict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_new, df_old = get_dfs()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import qplib as qp\n",
    "from qplib import log\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "df_new, df_old = get_dfs()\n",
    "\n",
    "print('df_new:')\n",
    "display(df_new)\n",
    "\n",
    "print('df_old:')\n",
    "display(df_old)\n",
    "\n",
    "print('mode=new:')\n",
    "display(qp.diff(df_new, df_old, mode='new'))\n",
    "\n",
    "print('mode=new+:')\n",
    "display(qp.diff(df_new, df_old, mode='new+'))\n",
    "\n",
    "print('mode=old:')\n",
    "display(qp.diff(df_new, df_old, mode='old'))\n",
    "\n",
    "print('mode=mix:')\n",
    "display(qp.diff(df_new, df_old, mode='mix'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# excel_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.pd_util import _format_df, get_dfs\n",
    "from qplib.util import log, GREEN, RED, ORANGE, GREEN_LIGHT, RED_LIGHT, ORANGE_LIGHT\n",
    "from qplib.types import _date, _na, qpDict\n",
    "\n",
    "\n",
    "\n",
    "def _show_differences(\n",
    "    df_new, df_old, mode='mix',\n",
    "    summary='print',  #print, return, None\n",
    "    max_cols=200, max_rows=20,\n",
    "    newline='<br>', prefix_new='', prefix_old='old: ',\n",
    "    verbosity=3,):\n",
    "    '''\n",
    "    shows differences between dataframes\n",
    "    '''\n",
    "\n",
    "    if not df_new.index.is_unique:\n",
    "        log('error: index of new dataframe is not unique', 'qp.diff()', verbosity)\n",
    "    if not df_old.index.is_unique:\n",
    "        log('error: index of old dataframe is not unique', 'qp.diff()', verbosity)\n",
    "\n",
    "\n",
    "\n",
    "    #prepare dataframes\n",
    "    df_new = _format_df(df_new, fix_headers=False, add_metadata=True, verbosity=verbosity)\n",
    "    df_old = _format_df(df_old, fix_headers=False, add_metadata=True, verbosity=verbosity)\n",
    "\n",
    "\n",
    "\n",
    "    cols_added = df_new.columns.difference(df_old.columns)\n",
    "    cols_removed = df_old.columns.difference(df_new.columns)\n",
    "    cols_shared = df_new.columns.intersection(df_old.columns)\n",
    "\n",
    "    rows_added = df_new.index.difference(df_old.index)\n",
    "    rows_removed = df_old.index.difference(df_new.index)\n",
    "    rows_shared = df_new.index.intersection(df_old.index)\n",
    "\n",
    "    changes_all = {\n",
    "        'cols added': len(cols_added),\n",
    "        'cols removed': len(cols_removed),\n",
    "        'rows added': len(rows_added),\n",
    "        'rows removed': len(rows_removed),\n",
    "        'vals added': 0,\n",
    "        'vals removed': 0,\n",
    "        'vals changed': 0\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    #create dfs showing the highlighted changes dependant on \"show\" settings\n",
    "    if mode in ['new', 'new+']:\n",
    "        df_diff = copy.deepcopy(df_new)\n",
    "        df_diff_style = pd.DataFrame('', index=df_diff.index, columns=df_diff.columns)\n",
    "\n",
    "        #add metadata columns\n",
    "        if mode == 'new+':\n",
    "            cols_new = ['meta']\n",
    "            cols_add = []\n",
    "            for col in df_diff.columns:\n",
    "                if not col.startswith(prefix_old) and col != 'meta':\n",
    "                    cols_new.append(col)\n",
    "                    cols_new.append(prefix_old + col)\n",
    "\n",
    "                    if prefix_old + col not in df_diff.columns:\n",
    "                        cols_add.append(prefix_old + col)\n",
    "\n",
    "            df_diff = pd.concat([df_diff, pd.DataFrame('', index=df_diff.index, columns=cols_add)], axis=1)\n",
    "            df_diff_style = pd.concat([df_diff_style, pd.DataFrame('font-style: italic', index=df_diff.index, columns=cols_add)], axis=1)\n",
    "        \n",
    "            df_diff = df_diff[cols_new]\n",
    "            df_diff_style = df_diff_style[cols_new]\n",
    "\n",
    "\n",
    "        df_diff_style.loc[:, cols_added] = f'background-color: {GREEN}'\n",
    "        df_diff_style.loc[rows_added, :] = f'background-color: {GREEN}'\n",
    "\n",
    "        df_diff.loc[rows_added, 'meta'] += 'added row'\n",
    "\n",
    "\n",
    "\n",
    "    elif mode == 'old':\n",
    "        df_diff = copy.deepcopy(df_old)\n",
    "        df_diff_style = pd.DataFrame('', index=df_diff.index, columns=df_diff.columns)\n",
    "        \n",
    "        df_diff_style.loc[:, cols_removed] = f'background-color: {RED}'\n",
    "        df_diff_style.loc[rows_removed, :] = f'background-color: {RED}'\n",
    "\n",
    "        df_diff.loc[rows_removed, 'meta'] += 'removed row'\n",
    "\n",
    "    elif mode == 'mix':\n",
    "        inds_old = df_old.index.difference(df_new.index)\n",
    "        cols_old = df_old.columns.difference(df_new.columns)\n",
    "\n",
    "        df_diff = pd.concat([df_new, df_old.loc[:, cols_old]], axis=1)\n",
    "        df_diff.loc[inds_old, :] = df_old.loc[inds_old, :]\n",
    "\n",
    "        df_diff_style = pd.DataFrame('', index=df_diff.index, columns=df_diff.columns)\n",
    "\n",
    "        df_diff_style.loc[:, cols_added] = f'background-color: {GREEN}'\n",
    "        df_diff_style.loc[:, cols_removed] = f'background-color: {RED}'\n",
    "        df_diff_style.loc[rows_added, :] = f'background-color: {GREEN}'\n",
    "        df_diff_style.loc[rows_removed, :] = f'background-color: {RED}'\n",
    "\n",
    "        df_diff.loc[rows_added, 'meta'] += 'added row'\n",
    "        df_diff.loc[rows_removed, 'meta'] += 'removed row'\n",
    "\n",
    "    else:\n",
    "        log(f'error: unknown mode: {mode}', 'qp.diff()', verbosity)\n",
    "\n",
    "\n",
    "    #highlight values in shared columns\n",
    "    #column 0 contains metadata and is skipped\n",
    "    cols_shared_no_metadata = [col for col in cols_shared if not col.startswith(prefix_old) and col != 'meta']\n",
    "\n",
    "    df_new_isna = df_new.loc[rows_shared, cols_shared_no_metadata].isna()\n",
    "    df_old_isna = df_old.loc[rows_shared, cols_shared_no_metadata].isna()\n",
    "    df_new_equals_old = df_new.loc[rows_shared, cols_shared_no_metadata] == df_old.loc[rows_shared, cols_shared_no_metadata]\n",
    "\n",
    "    df_added = df_old_isna & ~df_new_isna\n",
    "    df_removed = df_new_isna & ~df_old_isna\n",
    "    df_changed = ~df_new_isna & ~df_old_isna & ~df_new_equals_old\n",
    "\n",
    "    df_diff_style.loc[rows_shared, cols_shared_no_metadata] += df_added.mask(df_added, f'background-color: {GREEN_LIGHT}').where(df_added, '')\n",
    "    df_diff_style.loc[rows_shared, cols_shared_no_metadata] += df_removed.mask(df_removed, f'background-color: {RED_LIGHT}').where(df_removed, '')\n",
    "    df_diff_style.loc[rows_shared, cols_shared_no_metadata] += df_changed.mask(df_changed, f'background-color: {ORANGE_LIGHT}').where(df_changed, '')\n",
    "\n",
    "\n",
    "\n",
    "    df_added_sum = df_added.sum(axis=1)\n",
    "    df_removed_sum = df_removed.sum(axis=1)\n",
    "    df_changed_sum = df_changed.sum(axis=1)\n",
    "\n",
    "    changes_all['vals added'] += int(df_added_sum.sum())\n",
    "    changes_all['vals removed'] += int(df_removed_sum.sum())\n",
    "    changes_all['vals changed'] += int(df_changed_sum.sum())\n",
    "\n",
    "    df_diff.loc[rows_shared, 'meta'] += df_added_sum.apply(lambda x: f'{newline}vals added: {x}' if x > 0 else '')\n",
    "    df_diff.loc[rows_shared, 'meta'] += df_removed_sum.apply(lambda x: f'{newline}vals removed: {x}' if x > 0 else '')\n",
    "    df_diff.loc[rows_shared, 'meta'] += df_changed_sum.apply(lambda x: f'{newline}vals changed: {x}' if x > 0 else '')\n",
    "\n",
    "\n",
    "    if mode == 'new+':\n",
    "        cols_shared_metadata = [prefix_old + col for col in cols_shared_no_metadata]\n",
    "        df_all_modifications = (df_added | df_removed | df_changed)\n",
    "        df_old_changed = df_old.loc[rows_shared, cols_shared_no_metadata].where(df_all_modifications, '')\n",
    "        df_diff.loc[rows_shared, cols_shared_metadata] = df_old_changed.values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if max_cols is not None and max_cols < len(df_diff.columns):\n",
    "        log(f'warning: showing {max_cols} out of {len(df_diff.columns)} columns', 'qp.diff()', verbosity)\n",
    "    if max_rows is not None and max_rows < len(df_diff.index):\n",
    "        log(f'warning: showing {max_rows} out of {len(df_diff.index)} rows', 'qp.diff()', verbosity)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    df_diff = df_diff.iloc[:max_rows, :max_cols]\n",
    "    df_diff_style = df_diff_style.iloc[:max_rows, :max_cols]\n",
    "\n",
    "    #replace \"<\" and \">\" with html entities to prevent them from being interpreted as html tags\n",
    "    cols_no_metadata = [col for col in df_diff.columns if not col.startswith(prefix_old) and col != 'meta']\n",
    "    if pd.__version__ >= '2.1.0':\n",
    "        df_diff.loc[:, cols_no_metadata] = df_diff.loc[:, cols_no_metadata].map(lambda x: _try_replace_gt_lt(x))\n",
    "    else:\n",
    "        df_diff.loc[:, cols_no_metadata] = df_diff.loc[:, cols_no_metadata].applymap(lambda x: _try_replace_gt_lt(x))\n",
    "\n",
    "\n",
    "    result = df_diff.style.apply(lambda x: _apply_style(x, df_diff_style), axis=None)\n",
    "    changes_truncated = {key: val for key,val in changes_all.items() if val > 0}\n",
    "\n",
    "    if summary == 'print':\n",
    "        display(changes_truncated)\n",
    "        return result\n",
    "    elif summary == 'return':\n",
    "        return result, changes_truncated\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def _try_replace_gt_lt(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.replace('<', '&lt;').replace('>', '&gt;')\n",
    "    elif isinstance(x, type):\n",
    "        return str(x).replace('<', '&lt;').replace('>', '&gt;')\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def _apply_style(x, df_style):\n",
    "    return df_style\n",
    "\n",
    "\n",
    "def excel_diff(file_new='new', file_old='old', file_diff='diff',\n",
    "    index_col=0, mode='new+',\n",
    "    max_cols=None, max_rows=None, verbosity=3):\n",
    "    '''\n",
    "    shows differences between two excel files.\n",
    "\n",
    "    specs and requs:\n",
    "    - only sheets with the same name are compared\n",
    "    - needs a unique column to use as index, or sequential order of records\n",
    "    - index must be unique\n",
    "    - index must correspond to the same \"item\" in both sheets\n",
    "\n",
    "    if index_col=None:\n",
    "    - uses sequential numbers as index instead of any given column\n",
    "    - uniqueness is guaranteed\n",
    "    - only works if the all sheets have the same \"items\" in the same rows\n",
    "    '''\n",
    "\n",
    "    summary = pd.DataFrame(columns=[\n",
    "        'sheet',\n",
    "        f'is in new file',\n",
    "        f'is in old file',\n",
    "        f'index (first col) is unique in new file',\n",
    "        f'index (first col) is unique in old file',\n",
    "        'cols added',\n",
    "        'cols removed',\n",
    "        'rows added',\n",
    "        'rows removed',\n",
    "        'vals added',\n",
    "        'vals removed',\n",
    "        'vals changed',\n",
    "        ])\n",
    "    results = {}\n",
    "    \n",
    "\n",
    "    #get names of all sheets in the excel files\n",
    "    sheets_new = pd.ExcelFile(file_new).sheet_names\n",
    "    sheets_old = pd.ExcelFile(file_old).sheet_names\n",
    "    \n",
    "    #iterate over all sheets\n",
    "    for sheet in sheets_new:\n",
    "        if sheet in sheets_old:\n",
    "            if index_col is None:\n",
    "                df_new = pd.read_excel(file_new, sheet_name=sheet)\n",
    "                df_old = pd.read_excel(file_old, sheet_name=sheet)\n",
    "            else:\n",
    "                df_new = pd.read_excel(file_new, sheet_name=sheet, index_col=index_col)\n",
    "                df_old = pd.read_excel(file_old, sheet_name=sheet, index_col=index_col)\n",
    "\n",
    "            result, changes = _show_differences(\n",
    "                df_new, df_old, mode=mode, summary='return',\n",
    "                max_cols=max_cols, max_rows=max_rows, verbosity=verbosity\n",
    "                )\n",
    "            \n",
    "            results[sheet] = result\n",
    "        \n",
    "\n",
    "            idx = len(summary)\n",
    "            summary.loc[idx, 'sheet'] = sheet\n",
    "            summary.loc[idx, f'is in new file'] = True\n",
    "            summary.loc[idx, f'is in old file'] = True\n",
    "            summary.loc[idx, f'index (first col) is unique in new file'] = df_new.index.is_unique\n",
    "            summary.loc[idx, f'index (first col) is unique in old file'] = df_old.index.is_unique\n",
    "            for key, val in changes.items():\n",
    "                summary.loc[idx, key] = val\n",
    "            \n",
    "        else:\n",
    "            idx = len(summary)\n",
    "            summary.loc[idx, 'sheet'] = sheet\n",
    "            summary.loc[idx, f'is in new file'] = True\n",
    "            summary.loc[idx, f'is in old file'] = False\n",
    "            summary.loc[idx, f'index (first col) is unique in new file'] = df_new.index.is_unique\n",
    "\n",
    "    if file_diff:\n",
    "        if not file_diff.endswith('.xlsx'):\n",
    "            file_diff += '.xlsx'\n",
    "        \n",
    "        with pd.ExcelWriter(file_diff) as writer:\n",
    "            summary.to_excel(writer, sheet_name='summary', index=False)\n",
    "            if index_col:\n",
    "                index = True\n",
    "            else:\n",
    "                index = False\n",
    "\n",
    "            for sheet, result in results.items():\n",
    "                result.data['meta'] = result.data['meta'].str.replace('<br>', '\\n')\n",
    "                result.to_excel(writer, sheet_name=sheet, index=index)\n",
    "\n",
    "        log(f'info: differences saved to \"{file_diff}\"', 'qp.excel_diff()', verbosity)\n",
    "        \n",
    "    return summary, results\n",
    "\n",
    "\n",
    "\n",
    "# file_new = 'archive/stats_new.xlsx'\n",
    "# file_old = 'archive/stats_old.xlsx'\n",
    "\n",
    "# summary, results = excel_diff('archive/stats_new.xlsx', 'archive/stats_old.xlsx', to_excel=True)\n",
    "\n",
    "# new, old = qp.get_dfs()\n",
    "# display(new, old)\n",
    "# _show_differences(new, old, mode='new+')\n",
    "\n",
    "new = 'archive/NET_BM Study_01_export_2024-04-11.xlsx'\n",
    "old = 'archive/NET_BM Study_01_export_2024-03-15.xlsx'\n",
    "\n",
    "a,b = excel_diff(new, old, file_diff='archive/export_diff.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import datetime\n",
    "import qplib as qp\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, widgets\n",
    "from pandas.api.extensions import register_dataframe_accessor\n",
    "\n",
    "from qplib.util import log, qpDict\n",
    "from qplib.types import _date, _na\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ID': [10001, 10002, 10003, 20001, 20002, 20003, 30001, 30002, 30003, 30004, 30005],\n",
    "    'name': ['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Brown', 'eva white', 'Frank miller', 'Grace TAYLOR', 'Harry Clark', 'IVY GREEN', 'JAck Williams', 'john Doe'],\n",
    "    'date of birth': ['1995-01-02', '1990/09/14', '1985.08.23', '19800406', '05-11-2007', '06-30-1983', '28-05-1975', '1960Mar08', '1955-Jan-09', '1950 Sep 10', '1945 October 11'],\n",
    "    'age': [-25, '30', np.nan, None, '40.0', 'forty-five', 'nan', 'unk', '', 'unknown', 35],\n",
    "    'gender': ['M', 'F', 'Female', 'Male', 'Other', 'm', 'ff', 'NaN', None, 'Mal', 'female'],\n",
    "    'height': [170, '175.5cm', None, '280', 'NaN', '185', '1', '6ft 1in', -10, '', 200],\n",
    "    'weight': [70.2, '68', '72.5lb', 'na', '', '75kg', None, '80.3', '130lbs', '82', -65],\n",
    "    'bp systole': ['20', 130, 'NaN', '140', '135mmhg', '125', 'NAN', '122', '', 130, '45'],\n",
    "    'bp diastole': [80, '85', 'nan', '90mmHg', np.nan, '75', 'NaN', None, '95', '0', 'NaN'],\n",
    "    'cholesterol': ['Normal', 'Highe', 'NaN', 'GOOD', 'n.a.', 'High', 'Normal', 'n/a', 'high', '', 'Normal'],\n",
    "    'diabetes': ['No', 'yes', 'N/A', 'No', 'Y', 'Yes', 'NO', None, 'NaN', 'n', 'Yes'],\n",
    "    'dose': ['10kg', 'NaN', '15 mg once a day', '20mg', '20 Mg', '25g', 'NaN', None, '30 MG', '35', '40ml']\n",
    "    })\n",
    "\n",
    "df_new, df_old = qp.get_dfs()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"bashlike\" wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#run tests in folder \"tests\" using pytest and create a test report\n",
    "!pytest tests --html=tests/test_report.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import qplib as qp\n",
    "from qplib import log\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "def get_df_simple():\n",
    "    df = pd.DataFrame({\n",
    "        'a': [-1, 0, 1],\n",
    "        'b': [1, 2, 3]\n",
    "        })\n",
    "    return df\n",
    "\n",
    "def get_df_simple_tagged():\n",
    "    df = pd.DataFrame({\n",
    "        'meta': ['', '', ''],\n",
    "        'a': [-1, 0, 1],\n",
    "        'b': [1, 2, 3]\n",
    "        })\n",
    "    df.index = [0, 1, 2]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_df():\n",
    "    df = pd.DataFrame({\n",
    "        'ID': [10001, 10002, 10003, 20001, 20002, 20003, 30001, 30002, 30003, 30004, 30005],\n",
    "        'name': ['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Brown', 'eva white', 'Frank miller', 'Grace TAYLOR', 'Harry Clark', 'IVY GREEN', 'JAck Williams', 'john Doe'],\n",
    "        'date of birth': ['1995-01-02', '1990/09/14', '1985.08.23', '19800406', '05-11-2007', '06-30-1983', '28-05-1975', '1960Mar08', '1955-Jan-09', '1950 Sep 10', '1945 October 11'],\n",
    "        'age': [-25, '30', np.nan, None, '40.0', 'forty-five', 'nan', 'unk', '', 'unknown', 35],\n",
    "        'gender': ['M', 'F', 'Female', 'Male', 'Other', 'm', 'ff', 'NaN', None, 'Mal', 'female'],\n",
    "        'height': [170, '175.5cm', None, '280', 'NaN', '185', '1', '6ft 1in', -10, '', 200],\n",
    "        'weight': [70.2, '68', '72.5lb', 'na', '', '75kg', None, '80.3', '130lbs', '82', -65],\n",
    "        'bp systole': ['20', 130, 'NaN', '140', '135mmhg', '125', 'NAN', '122', '', 130, '45'],\n",
    "        'bp diastole': [80, '85', 'nan', '90mmHg', np.nan, '75', 'NaN', None, '95', '0', 'NaN'],\n",
    "        'cholesterol': ['Normal', 'Highe', 'NaN', 'GOOD', 'n.a.', 'High', 'Normal', 'n/a', 'high', '', 'Normal'],\n",
    "        'diabetes': ['No', 'yes', 'N/A', 'No', 'Y', 'Yes', 'NO', None, 'NaN', 'n', 'Yes'],\n",
    "        'dose': ['10kg', 'NaN', '15 mg once a day', '20mg', '20 Mg', '25g', 'NaN', None, '30 MG', '35', '40ml']\n",
    "        })\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_df_tagged():\n",
    "    df1 = get_df()\n",
    "    df2 = pd.DataFrame('', index=df1.index, columns=['meta', *df1.columns])\n",
    "    df2.iloc[:, 1:] = df1.loc[:, :]\n",
    "    return df2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58afc15387e412f9c2da85dc9141b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Tab(children=(Textarea(value='´s verbosity=3\\n´s diff=None\\n\\n', layout=Layout(height='97%', wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de5e7a9f300490899ed0abaaf639df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import datetime\n",
    "import qplib as qp\n",
    "from qplib import log\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# df1 = qp.get_df()\n",
    "# df2 = pd.DataFrame({\n",
    "#         'ID': [10001, 10002, 10003, 20001, 20002, 20003, 30001, 30002, 30003, 30004, 30005],\n",
    "#         'name': ['John Doe', 'Jane Smith', 'Alice Johnson', 'Bob Brown', 'eva white', 'Frank miller', 'Grace TAYLOR', 'Harry Clark', 'IVY GREEN', 'JAck Williams', 'john Doe'],\n",
    "#         'date of birth': ['1995-01-02', '1990/09/14', '1985.08.23', '19800406', '05-11-2007', '06-30-1983', '28-05-1975', '1960Mar08', '1955-Jan-09', '1950 Sep 10', '1945 October 11'],\n",
    "#         'age': [-25, '30', np.nan, None, '40.0', 'forty-five', 'nan', 'unk', '', 'unknown', 35],\n",
    "#         'gender': ['M', 'F', 'Female', 'Male', 'Other', 'm', 'ff', 'NaN', None, 'Mal', 'female'],\n",
    "#         'height': [170, '175.5cm', None, '280', 'NaN', '185', '1', '6ft 1in', -10, '', 200],\n",
    "#         'weight': [70.2, '68', '72.5lb', 'na', '', '75kg', None, '80.3', '130lbs', '82', -65],\n",
    "#         'bp systle': ['20', 130, 'NaN', '140', '135mmhg', '125', 'NAN', '122', '', 130, '45'],\n",
    "#         'bp diastole': [80, '85', 'nan', '90mmHg', np.nan, '75', 'NaN', None, '95', '0', 'NaN'],\n",
    "#         'cholesterol': ['Normal', 'Highe', 'NaN', 'GOOD', 'n.a.', 'High', 'Normal', 'n/a', 'high', '', 'Normal'],\n",
    "#         'diabetes': ['No', 'yes', 'N/A', 'No', 'Y', 'Yes', 'NO', None, 'NaN', 'n', 'Yes'],\n",
    "#         'dose': ['10kg', 'NaN', '15 mg once a day', '20mg', '20 Mg', '25g', 'NaN', None, '30 MG', '35', '40ml']\n",
    "#         })\n",
    "\n",
    "# qp.diff(df1, df2, returns='df')\n",
    "\n",
    "# df1.q()\n",
    "\n",
    "df = qp.get_df()\n",
    "\n",
    "df.qi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_34740\\1457612455.py:933: UserWarning: registration of accessor <class '__main__.DataFrameQuery'> under name 'q' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('q')\n",
      "C:\\Users\\MartinVölkl-GouyaIns\\AppData\\Local\\Temp\\ipykernel_34740\\1457612455.py:950: UserWarning: registration of accessor <class '__main__.DataFrameQueryInteractiveMode'> under name 'qi' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  @pd.api.extensions.register_dataframe_accessor('qi')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ffc30_row0_col0, #T_ffc30_row0_col1, #T_ffc30_row0_col2, #T_ffc30_row0_col3 {\n",
       "  background-color: #c0e7b0;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ffc30\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ffc30_level0_row0\" class=\"row_heading level0 row0\" >869</th>\n",
       "      <td id=\"T_ffc30_row0_col0\" class=\"data row0 col0\" >df was checked. no problems found</td>\n",
       "      <td id=\"T_ffc30_row0_col1\" class=\"data row0 col1\" >qp.pd_util._check_df</td>\n",
       "      <td id=\"T_ffc30_row0_col2\" class=\"data row0 col2\" >info</td>\n",
       "      <td id=\"T_ffc30_row0_col3\" class=\"data row0 col3\" >2024-09-13 17:37:56.279351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x297622ef200>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_03b38_row0_col0, #T_03b38_row0_col1, #T_03b38_row0_col2, #T_03b38_row0_col3 {\n",
       "  background-color: #f7d67c;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_03b38\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_03b38_level0_row0\" class=\"row_heading level0 row0\" >888</th>\n",
       "      <td id=\"T_03b38_row0_col0\" class=\"data row0 col0\" >no columns fulfill the condition in \"´c &weight \" and the previous conditions</td>\n",
       "      <td id=\"T_03b38_row0_col1\" class=\"data row0 col1\" >qp.qlang._select_cols</td>\n",
       "      <td id=\"T_03b38_row0_col2\" class=\"data row0 col2\" >Warning</td>\n",
       "      <td id=\"T_03b38_row0_col3\" class=\"data row0 col3\" >2024-09-13 17:37:56.387659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x297622eeb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a01c2_row0_col0, #T_a01c2_row0_col1, #T_a01c2_row0_col2, #T_a01c2_row0_col3 {\n",
       "  background-color: #f7d67c;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a01c2\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a01c2_level0_row0\" class=\"row_heading level0 row0\" >893</th>\n",
       "      <td id=\"T_a01c2_row0_col0\" class=\"data row0 col0\" >row filter cannot be applied when no columns where selected</td>\n",
       "      <td id=\"T_a01c2_row0_col1\" class=\"data row0 col1\" >qp.qlang._select_rows</td>\n",
       "      <td id=\"T_a01c2_row0_col2\" class=\"data row0 col2\" >Warning</td>\n",
       "      <td id=\"T_a01c2_row0_col3\" class=\"data row0 col3\" >2024-09-13 17:37:56.430448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2975fcdbe30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5e679_row0_col0, #T_5e679_row0_col1, #T_5e679_row0_col2, #T_5e679_row0_col3 {\n",
       "  background-color: #f7d67c;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5e679\">\n",
       "  <thead>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5e679_level0_row0\" class=\"row_heading level0 row0\" >914</th>\n",
       "      <td id=\"T_5e679_row0_col0\" class=\"data row0 col0\" >no rows fulfill the condition in \"SELECT_ROWS (symbol: \"´r\" description: \"select rows fulfilling a condition)\"\"</td>\n",
       "      <td id=\"T_5e679_row0_col1\" class=\"data row0 col1\" >qp.qlang._select_rows</td>\n",
       "      <td id=\"T_5e679_row0_col2\" class=\"data row0 col2\" >Warning</td>\n",
       "      <td id=\"T_5e679_row0_col3\" class=\"data row0 col3\" >2024-09-13 17:37:56.531031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2976212a930>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [weight, diabetes]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
